{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b23894c-d552-4f3a-a65b-9f12b9d6be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import random\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d140e389-cf16-40eb-b078-6a1d0da9e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "config = {\n",
    "    'epochs': 150,\n",
    "    'batch_size' : 32,\n",
    "    'context' : 48,\n",
    "    'learning_rate' : 0.01,\n",
    "    'architecture' : 'very-low-cutoff'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bf0a6-3b35-4b0e-97e3-3a2e992101a2",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a61495c-d324-4401-b3ac-b8100dbf5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 128, partition = \"train\"):\n",
    "        \"\"\"\n",
    "        :param data_path: the root path of phonemes\n",
    "        :param am_path: the path of am (.csv)\n",
    "        :param gender: female or male\n",
    "        :param phoneme_idx: the phoneme index\n",
    "        :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "        :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "        :param partition: train / val1 / val2 / test\n",
    "        \"\"\"\n",
    "\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        # get phoneme list\n",
    "        self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "        phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "        random.shuffle(phoneme_list)\n",
    "        length = len(phoneme_list)\n",
    "        if partition == \"train\":\n",
    "            self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "        elif partition == \"val1\":\n",
    "            self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "        elif partition == \"val2\":\n",
    "            self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "        elif partition == \"test\":\n",
    "            self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "            \n",
    "        # if partition == \"train\":\n",
    "        #     self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "        # elif partition == \"val1\":\n",
    "        #     self.phoneme_list = phoneme_list[int(0.7 * length):]\n",
    "\n",
    "\n",
    "        self.length = len(self.phoneme_list)\n",
    "\n",
    "        # get_am data\n",
    "        am_data = pd.read_csv(am_path)\n",
    "        self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return spec\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        item_filename = self.phoneme_list[ind]\n",
    "        item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "        phoneme = np.load(item_full_path)\n",
    "\n",
    "        person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "        try:\n",
    "            target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "        except:\n",
    "            print(\"person id =\", person_id)\n",
    "            target_am = 0.\n",
    "\n",
    "        # padding\n",
    "        phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "        # apply mel transform\n",
    "        phoneme = self.spectro_gram(phoneme)\n",
    "\n",
    "        std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "        phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "\n",
    "        if len(phoneme[0]) < MAX_LEN:\n",
    "            phoneme = np.pad(phoneme, ((0, 0), (0, MAX_LEN - len(phoneme[0]))), 'constant', constant_values=(0, 0))\n",
    "            phoneme = torch.from_numpy(phoneme)\n",
    "        else:\n",
    "            phoneme = phoneme[:, :MAX_LEN]\n",
    "        # phoneme = torch.from_numpy(phoneme)\n",
    "        ##################################################################\n",
    "        phoneme.unsqueeze_(0)\n",
    "        ##################################################################\n",
    "        target_am = torch.tensor(target_am).to(torch.float32)\n",
    "        \n",
    "        return phoneme, target_am\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870d26e7-ad98-479d-8fcf-f21613bfae08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "#     def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 44100 * 2, partition = \"train\"):\n",
    "#         \"\"\"\n",
    "#         :param data_path: the root path of phonemes\n",
    "#         :param am_path: the path of am (.csv)\n",
    "#         :param gender: female or male\n",
    "#         :param phoneme_idx: the phoneme index\n",
    "#         :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "#         :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "#         :param partition: train / val1 / val2 / test\n",
    "#         \"\"\"\n",
    "\n",
    "#         self.MAX_LEN = MAX_LEN\n",
    "#         # get phoneme list\n",
    "#         self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "#         phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "#         length = len(phoneme_list)\n",
    "#         if partition == \"train\":\n",
    "#             self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "#         elif partition == \"val1\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "#         elif partition == \"val2\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "#         elif partition == \"test\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "\n",
    "#         self.length = len(self.phoneme_list)\n",
    "\n",
    "#         # get_am data\n",
    "#         am_data = pd.read_csv(am_path)\n",
    "#         self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.length\n",
    "\n",
    "#     def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "#         top_db = 80\n",
    "\n",
    "#         # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "#         spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "#         # Convert to decibels\n",
    "#         spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "#         return spec\n",
    "\n",
    "#     def padding(self, phoneme):\n",
    "#         if len(phoneme) < self.MAX_LEN:\n",
    "#             pad_begin_len = random.randint(0, self.MAX_LEN - len(phoneme))\n",
    "#             pad_end_len = self.MAX_LEN - len(phoneme) - pad_begin_len\n",
    "\n",
    "#             # Pad with 0s\n",
    "#             pad_begin = np.zeros(pad_begin_len)\n",
    "#             pad_end = np.zeros(pad_end_len)\n",
    "\n",
    "#             phoneme = np.concatenate((pad_begin, phoneme, pad_end), 0)\n",
    "#         else:\n",
    "#             phoneme = phoneme[:self.MAX_LEN]\n",
    "#         return phoneme\n",
    "\n",
    "#     def __getitem__(self, ind):\n",
    "#         item_filename = self.phoneme_list[ind]\n",
    "#         item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "#         phoneme = np.load(item_full_path)\n",
    "\n",
    "#         person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "#         try:\n",
    "#             target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "#         except:\n",
    "#             print(\"person id =\", person_id)\n",
    "#             target_am = 0.\n",
    "\n",
    "#         # padding\n",
    "#         phoneme = self.padding(phoneme)\n",
    "#         phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "#         # apply mel transform\n",
    "#         phoneme = self.spectro_gram(phoneme)\n",
    "        \n",
    "#         ################################### Normalization ######################################\n",
    "#         std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "#         phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "#         # print(phoneme)\n",
    "#         # ####################### convert phoneme from float32 to float64 ##################\n",
    "#         # phoneme = phoneme.to(torch.float64)\n",
    "#         # ##################################################################################\n",
    "\n",
    "#         target_am = torch.tensor(target_am)\n",
    "        \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         target_am = target_am.to(torch.float32)\n",
    "#         # print(target_am)\n",
    "#         ####################################################################################\n",
    "        \n",
    "#         # jia yi ge gui yi hua (phoneme)\n",
    "        \n",
    "#         return phoneme, target_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad957703-795b-42ee-b460-4e2bb8c7d9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# default_root_path = \"./penstate_data/extract_phoneme\"\n",
    "default_root_path = \"./penstate_data/extract_phoneme_processed\"\n",
    "\n",
    "# am_path = \"./penstate_data/AMs_unnormalized.csv\"\n",
    "am_path = \"./penstate_data/AMs_final.csv\"\n",
    "\n",
    "############## Female ##################\n",
    "gender = \"female\"\n",
    "phoneme_idx = 10\n",
    "am_idx = 89\n",
    "\n",
    "# gender = \"female\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 13\n",
    "\n",
    "# gender = \"female\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 42\n",
    "\n",
    "# gender = \"female\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 7\n",
    "\n",
    "############## Male ##################\n",
    "# gender = \"male\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 89\n",
    "\n",
    "# gender = \"male\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 51\n",
    "\n",
    "# gender = \"male\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 4\n",
    "\n",
    "# gender = \"male\"\n",
    "# phoneme_idx = 10\n",
    "# am_idx = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405ad57-2941-43a0-9658-5949746b872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female am_idx: 89 13 88 51 14\n",
    "# phoneme_idx: # 7 (É™) 4 (n) 31 (r) 17 (I)               6 (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abfa6fc-9b28-47d5-bf96-376c4e1ba1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  32\n",
      "Train dataset samples = 3067, batches = 96\n",
      "Validation dataset samples = 438, batches = 14\n",
      "Test dataset samples = 438, batches = 14\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 32 # TODO: may be too small\n",
    "batch_size = 64\n",
    "batch_size = config['batch_size']\n",
    "train_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"train\")\n",
    "\n",
    "######################################################################################################################################\n",
    "val_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val1\")\n",
    "test_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val1\")\n",
    "######################################################################################################################################\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, num_workers=0,\n",
    "                                               batch_size=batch_size, shuffle=True)\n",
    "\n",
    "######################################################################################################################################\n",
    "val_loader = torch.utils.data.DataLoader(val_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "######################################################################################################################################\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d51fd85-087d-45c7-bb32-446af925c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,89,-0.12617458403110504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_am = None\n",
    "for i, data in enumerate(train_loader):\n",
    "    phoneme, target_am = data\n",
    "    # sns.heatmap(phoneme[0], cmap=\"rainbow\")\n",
    "    # plt.show()\n",
    "    if all_am is None:\n",
    "        all_am = target_am\n",
    "    else:\n",
    "        all_am = torch.cat([all_am, target_am])\n",
    "    # print(phoneme.shape, target_am.shape)\n",
    "    # break\n",
    "with open(gender + \"_am.txt\", \"a+\") as f:\n",
    "    f.write(f'{phoneme_idx},{am_idx},{all_am.mean().item()}\\n')\n",
    "print(f'{phoneme_idx},{am_idx},{all_am.mean().item()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c74d99-578e-4710-b5c7-cd3783489de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  32\n",
      "Train dataset samples = 3067, batches = 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     phoneme, target_am = data\n",
    "#     print(phoneme.shape, target_am.shape)\n",
    "#     ##########################################\n",
    "#     # print(phoneme.dtype, target_am.dtype)\n",
    "#     ##########################################\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db9324-d5e9-4cc3-880d-fe3ed5d1b216",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaeef63d-9e83-41cc-84cb-0eba41760795",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Model 1: CNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f9842b8-efda-47d9-a471-ec6fd119027f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# class CNNNetwork(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv2=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv3=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv4=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.flatten=nn.Flatten()\n",
    "#         self.linear1=nn.Linear(in_features=128*15,out_features=512)\n",
    "#         self.linear2=nn.Linear(in_features=512,out_features=128)\n",
    "#         self.linear3=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.linear4=nn.Linear(in_features=1024,out_features=256)\n",
    "#         # self.linear5=nn.Linear(in_features=256,out_features=128)\n",
    "#         # self.linear6=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.output=nn.Sigmoid()\n",
    "#         self.pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.output = nn.Tanh()\n",
    "    \n",
    "#     def forward(self,input_data):\n",
    "#         # add one dimension\n",
    "#         # input_data.unsqueeze_(1)\n",
    "#         x=self.conv1(input_data)\n",
    "#         x=self.conv2(x)\n",
    "#         x=self.conv3(x)\n",
    "#         x=self.conv4(x)\n",
    "        \n",
    "#         # x = self.pooling(x)\n",
    "#         # print(\"After conv: \", x.shape)\n",
    "#         x=self.flatten(x)\n",
    "#         # print(\"After flatten: \", x.shape)\n",
    "#         x=self.linear1(x)\n",
    "#         # print(\"After linear: \",x.shape)\n",
    "#         x=self.linear2(x)\n",
    "#         # x=self.linear3(x)\n",
    "#         # x=self.linear4(x)\n",
    "#         # x=self.linear5(x)\n",
    "        \n",
    "#         logits=self.linear3(x)\n",
    "#         output=self.output(logits)\n",
    "#         # print(output)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01da6240-e6aa-4d15-89b0-9bd20f1a8e6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# model = CNNNetwork().to(device)\n",
    "# phoneme, AM = next(iter(train_loader))\n",
    "# # # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66850381-d103-4d15-af6f-fd6ffa15f202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 2: Resnet50"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c474433b-e056-46cf-90dc-53cfb0390fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# model = models.resnet50(weights=None).to(device) # may be too weak\n",
    "model = models.resnet152(weights=None).to(device) # may be too weak\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1).to(device)\n",
    "# print(model.conv1)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4188befc-952c-4043-9f78-a8089619cef9",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f71bdff-0166-458e-8a3c-ec1e9cb55490",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 3: DenseNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73567992-a037-4fa1-8775-35713728d1c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = models.densenet121(weights=None).to(device) # may be too weak\n",
    "\n",
    "# num_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_features, 1).to(device)\n",
    "# print(model)\n",
    "model.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.classifier = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f42bab4-e0bf-45af-bada-91f5b88bd061",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5468244a-796c-4801-92ca-f8449391a81b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 4: EfficientNetV2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a736d83-f333-470c-a3a2-bdf832bc0c7a",
   "metadata": {},
   "source": [
    "MAE: 0.69??"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09b63a5c-5655-40ed-b2ee-67ade5e2e498",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = models.efficientnet_v2_s(weights=None).to(device) # may be too weak\n",
    "# print(model)\n",
    "model.features[0][0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f79e62c3-692a-42a3-80b6-6dd716095e4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b3b1605-c19f-4d44-a731-ac8680c40b87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 5: MobileNetV3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c606133-c5bb-4a6a-8c65-a968b1ab2ea2",
   "metadata": {},
   "source": [
    "##### MAE: 0.68??"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec4d7ae2-c804-467c-89f5-325cf820b47e",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = models.mobilenet_v3_large(weights=None).to(device)\n",
    "# print(model)\n",
    "model.features[0][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[3] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5401a006-a2b5-4eab-b17d-653ba234377b",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1616fa20-d08e-488d-96a4-79391030cc19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 6: ShuffleNetV2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c15b6f1-f9b1-4632-86f8-218df6a4da3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = models.shufflenet_v2_x1_0(weights=None).to(device)\n",
    "# print(model)\n",
    "model.conv1[0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.fc = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70832dae-ebe2-44be-b63f-ec74b54381c5",
   "metadata": {},
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3da36707-c2f5-4ad5-8181-32e648ff15d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 7: SqueezeNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3ed1ab2-498e-4b32-bbf6-fa5a7290787c",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = models.squeezenet1_1(weights=None).to(device)\n",
    "# print(model)\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "model.classifier[1] = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "caa74b5f-7077-4003-a37f-780e22bbbafb",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ec3e0-2820-47fc-85d0-2542b1b372e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 8: MnasNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd549074-a6a7-450d-a7be-97dd639f07b9",
   "metadata": {},
   "source": [
    "##### MAE=0.68 ok???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdff1e5c-80fc-4826-af6f-695f4b056073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNASNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (8): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
      "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
      "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (0): _InvertedResidual(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.mnasnet1_0(weights=None).to(device)\n",
    "# print(model)\n",
    "model.layers[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd8e0ff-fc4d-4a69-a75b-8a1a2be686ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4455c-36c8-4867-930d-8cf1957d7557",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 9: Wide ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46827b9f-e1cd-431f-9863-c8c815921792",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = models.mnasnet1_0(weights=None).to(device)\n",
    "# # print(model)\n",
    "# model.layers[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "# model.classifier[1] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# # print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58bcf8c1-e9a7-4619-b299-258cd29d394d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "# phoneme, AM = next(iter(train_loader))\n",
    "# # # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# # summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a5bd7-2d59-4282-8ebc-2683628cdce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aff3c7e-600a-4f48-a73e-3477e6d08404",
   "metadata": {},
   "source": [
    "# Train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d6978e0-43a9-4a1b-9f05-7fca1d25be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "563a8ca6-0732-4409-a74c-1e2ef43191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() #Defining Loss function \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate']) #Defining Optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.0001, last_epoch=-1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,40,45,50,60,65,70,90,110,150,170,180], gamma=0.5) # add learning rate scheduler\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * config['epochs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75674d65-bd4f-412b-8aa0-2d951cae0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 #Monitoring Loss\n",
    "    \n",
    "    #########################################################\n",
    "    # AM_true_list = []\n",
    "    # AM_pred_list = []\n",
    "    #########################################################\n",
    "    \n",
    "    for iter, (phoneme, AM) in enumerate(dataloader):\n",
    "        scheduler.step()\n",
    "        ### Move Data to Device (Ideally GPU)\n",
    "        phoneme = phoneme.to(device)\n",
    "        AM = AM.to(device)\n",
    "\n",
    "        ### Forward Propagation\n",
    "        preds_AM = model(phoneme)\n",
    "\n",
    "        ### Loss Calculation\n",
    "        # print(AM.shape)\n",
    "        preds_AM = torch.squeeze(preds_AM)\n",
    "        # print(preds_AM)\n",
    "        # print(preds_AM.shape)model = models.shufflenet_v2_x1_0(weights=None).to(device)\n",
    "        loss = criterion(preds_AM, AM)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        #########################################################\n",
    "        ### Store Pred and True Labels\n",
    "        # AM_pred_list.extend(preds_AM.cpu().tolist())\n",
    "        # AM_true_list.extend(AM.cpu().tolist())\n",
    "        #########################################################\n",
    "\n",
    "        ### Initialize Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Backward Propagation\n",
    "        loss.backward()\n",
    "\n",
    "        ### Gradient Descent\n",
    "        optimizer.step()\n",
    "        # if iter % 20 == 0:\n",
    "        #     print(\"iter =\", iter, \"loss =\",loss.item())\n",
    "    train_loss /= len(dataloader)\n",
    "    print(\"Learning rate = \", scheduler.get_last_lr()[0])\n",
    "    print(\"Train loss = \", train_loss)\n",
    "    \n",
    "    #########################################################\n",
    "    # print(AM_pred_list)\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    # accuracy = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    # print(\"Train MSE accuracy: \", accuracy)\n",
    "    #########################################################\n",
    "    \n",
    "    # scheduler.step() # add schedule learning rate\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a1518e3-0b07-4b4d-a192-54e5bc0a7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "\n",
    "    model.eval() # set model in evaluation mode\n",
    "\n",
    "    AM_true_list = []\n",
    "    AM_pred_list = []\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        phoneme, AM = data\n",
    "        ### Move data to device (ideally GPU)\n",
    "        phoneme, AM = phoneme.to(device), AM.to(device) \n",
    "\n",
    "        with torch.inference_mode(): # makes sure that there are no gradients computed as we are not training the model now\n",
    "            ### Forward Propagation\n",
    "            ### Get Predictions\n",
    "            predicted_AM = model(phoneme)\n",
    "            # print(predicted_AM)\n",
    "        \n",
    "        ### Store Pred and True Labels\n",
    "        AM_pred_list.extend(predicted_AM.cpu().tolist())\n",
    "        AM_true_list.extend(AM.cpu().tolist())\n",
    "        \n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "    \n",
    "        del phoneme, AM, predicted_AM\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ###############################################################################################\n",
    "    # print(AM_pred_list[1000:3100])\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    ###############################################################################################\n",
    "    \n",
    "    # print(\"Number of equals between two list: \", sum(a == b for a,b in zip(AM_pred_list, AM_true_list)))\n",
    "    \n",
    "    ### Calculate Accuracy\n",
    "    MSE = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    r2_score_acc = r2_score(AM_pred_list, AM_true_list)\n",
    "    MAE = mean_absolute_error(AM_pred_list, AM_true_list)\n",
    "    print(\"Validation r2_score: \", r2_score_acc)\n",
    "    print(\"Validation MAE: \", MAE)\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce9f12-c7c9-4328-b4e2-b921edd4747c",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90eda49-e81d-42a2-af9b-f6f18ef88248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  0.00999890341737423\n",
      "Train loss =  2.114860268930594\n",
      "Validation r2_score:  -28402565.0283373\n",
      "Validation MAE:  0.879159502259277\n",
      "\tTrain Loss:  2.114860268930594\n",
      "\tValidation MSE:  1.1896642361967569\n",
      "\n",
      "Epoch 2/150\n",
      "Learning rate =  0.0099956141504943\n",
      "Train loss =  1.015468344092369\n",
      "Validation r2_score:  -11551319533.334398\n",
      "Validation MAE:  0.7816657140403434\n",
      "\tTrain Loss:  1.015468344092369\n",
      "\tValidation MSE:  0.9764082295172313\n",
      "\n",
      "Epoch 3/150\n",
      "Learning rate =  0.009990133642141364\n",
      "Train loss =  1.0059166469921668\n",
      "Validation r2_score:  -538330983293.9275\n",
      "Validation MAE:  0.7827127919140054\n",
      "\tTrain Loss:  1.0059166469921668\n",
      "\tValidation MSE:  0.9791264501167312\n",
      "\n",
      "Epoch 4/150\n",
      "Learning rate =  0.009982464296247528\n",
      "Train loss =  1.0306617757305503\n",
      "Validation r2_score:  -621402379742.7112\n",
      "Validation MAE:  0.7823639948034795\n",
      "\tTrain Loss:  1.0306617757305503\n",
      "\tValidation MSE:  0.978065718202774\n",
      "\n",
      "Epoch 5/150\n",
      "Learning rate =  0.009972609476841367\n",
      "Train loss =  0.9646691760669152\n",
      "Validation r2_score:  -1229275315383.445\n",
      "Validation MAE:  0.7821346458263448\n",
      "\tTrain Loss:  0.9646691760669152\n",
      "\tValidation MSE:  0.9773382830743778\n",
      "\n",
      "Epoch 6/150\n",
      "Learning rate =  0.009960573506572392\n",
      "Train loss =  0.966144148260355\n",
      "Validation r2_score:  -3448261636819.788\n",
      "Validation MAE:  0.7816709963999238\n",
      "\tTrain Loss:  0.966144148260355\n",
      "\tValidation MSE:  0.9764132229394957\n",
      "\n",
      "Epoch 7/150\n",
      "Learning rate =  0.009946361664814943\n",
      "Train loss =  0.9647868691633145\n",
      "Validation r2_score:  -14199550150982.953\n",
      "Validation MAE:  0.7816633523083568\n",
      "\tTrain Loss:  0.9647868691633145\n",
      "\tValidation MSE:  0.9764058721551723\n",
      "\n",
      "Epoch 8/150\n",
      "Learning rate =  0.009929980185352521\n",
      "Train loss =  0.9492443303267161\n",
      "Validation r2_score:  -8374928177705.556\n",
      "Validation MAE:  0.782242963778931\n",
      "\tTrain Loss:  0.9492443303267161\n",
      "\tValidation MSE:  0.9776566713838946\n",
      "\n",
      "Epoch 9/150\n",
      "Learning rate =  0.00991143625364345\n",
      "Train loss =  0.9464543331414461\n",
      "Validation r2_score:  -4843185838535.341\n",
      "Validation MAE:  0.7828976507357122\n",
      "\tTrain Loss:  0.9464543331414461\n",
      "\tValidation MSE:  0.9796837063344592\n",
      "\n",
      "Epoch 10/150\n",
      "Learning rate =  0.009890738003669023\n",
      "Train loss =  0.9323634393513203\n",
      "Validation r2_score:  -18165812259891.426\n",
      "Validation MAE:  0.7816029770047825\n",
      "\tTrain Loss:  0.9323634393513203\n",
      "\tValidation MSE:  0.9763696804456564\n",
      "\n",
      "Epoch 11/150\n",
      "Learning rate =  0.009867894514365788\n",
      "Train loss =  0.9233143848056594\n",
      "Validation r2_score:  -3763704302745.5327\n",
      "Validation MAE:  0.7822907167103048\n",
      "\tTrain Loss:  0.9233143848056594\n",
      "\tValidation MSE:  0.9778113855112983\n",
      "\n",
      "Epoch 12/150\n",
      "Learning rate =  0.009842915805643138\n",
      "Train loss =  0.9186401283368468\n",
      "Validation r2_score:  -2077297186706.8438\n",
      "Validation MAE:  0.7862092120722829\n",
      "\tTrain Loss:  0.9186401283368468\n",
      "\tValidation MSE:  0.9898771244568545\n",
      "\n",
      "Epoch 13/150\n",
      "Learning rate =  0.009815812833988278\n",
      "Train loss =  0.9060880265509089\n",
      "Validation r2_score:  -1371576628816.189\n",
      "Validation MAE:  0.7882476271684048\n",
      "\tTrain Loss:  0.9060880265509089\n",
      "\tValidation MSE:  0.9944861620961435\n",
      "\n",
      "Epoch 14/150\n",
      "Learning rate =  0.00978659748766033\n",
      "Train loss =  0.9030745138103763\n",
      "Validation r2_score:  -249655263128.04657\n",
      "Validation MAE:  0.7817736543097308\n",
      "\tTrain Loss:  0.9030745138103763\n",
      "\tValidation MSE:  0.9765723511096387\n",
      "\n",
      "Epoch 15/150\n",
      "Learning rate =  0.009755282581475757\n",
      "Train loss =  0.8799416764328877\n",
      "Validation r2_score:  -464323830015.5589\n",
      "Validation MAE:  0.7816105967203631\n",
      "\tTrain Loss:  0.8799416764328877\n",
      "\tValidation MSE:  0.9763720151140532\n",
      "\n",
      "Epoch 16/150\n",
      "Learning rate =  0.009721881851187407\n",
      "Train loss =  0.901162072395285\n",
      "Validation r2_score:  -150420352034.33313\n",
      "Validation MAE:  0.7864861254538856\n",
      "\tTrain Loss:  0.901162072395285\n",
      "\tValidation MSE:  0.9905581689271923\n",
      "\n",
      "Epoch 17/150\n",
      "Learning rate =  0.009686409947459456\n",
      "Train loss =  0.9157482786104083\n",
      "Validation r2_score:  -72184230198.24356\n",
      "Validation MAE:  0.7823978142730985\n",
      "\tTrain Loss:  0.9157482786104083\n",
      "\tValidation MSE:  0.978190569565619\n",
      "\n",
      "Epoch 18/150\n",
      "Learning rate =  0.009648882429441261\n",
      "Train loss =  0.8971599079668522\n",
      "Validation r2_score:  -43973361776.843155\n",
      "Validation MAE:  0.7863030655901735\n",
      "\tTrain Loss:  0.8971599079668522\n",
      "\tValidation MSE:  0.9901071270830718\n",
      "\n",
      "Epoch 19/150\n",
      "Learning rate =  0.009609315757942513\n",
      "Train loss =  0.8784481612965465\n",
      "Validation r2_score:  -13016793065.654257\n",
      "Validation MAE:  0.7817217633633164\n",
      "\tTrain Loss:  0.8784481612965465\n",
      "\tValidation MSE:  0.9764771703410328\n",
      "\n",
      "Epoch 20/150\n",
      "Learning rate =  0.009567727288213021\n",
      "Train loss =  0.9027193328365684\n",
      "Validation r2_score:  -10693713420.34087\n",
      "Validation MAE:  0.782249041632579\n",
      "\tTrain Loss:  0.9027193328365684\n",
      "\tValidation MSE:  0.979206403329172\n",
      "\n",
      "Epoch 21/150\n",
      "Learning rate =  0.009524135262330116\n",
      "Train loss =  0.8904849151149392\n",
      "Validation r2_score:  -2408004928.1676416\n",
      "Validation MAE:  0.7834127430105582\n",
      "\tTrain Loss:  0.8904849151149392\n",
      "\tValidation MSE:  0.9814746014593122\n",
      "\n",
      "Epoch 22/150\n",
      "Learning rate =  0.009478558801197077\n",
      "Train loss =  0.871499697988232\n",
      "Validation r2_score:  -230154894.9075834\n",
      "Validation MAE:  0.7820324236564296\n",
      "\tTrain Loss:  0.871499697988232\n",
      "\tValidation MSE:  0.9770788575599466\n",
      "\n",
      "Epoch 23/150\n",
      "Learning rate =  0.009431017896156078\n",
      "Train loss =  0.8686348448197047\n",
      "Validation r2_score:  -104843369.25656573\n",
      "Validation MAE:  0.7821709628479522\n",
      "\tTrain Loss:  0.8686348448197047\n",
      "\tValidation MSE:  0.9774528557598039\n",
      "\n",
      "Epoch 24/150\n",
      "Learning rate =  0.009381533400219324\n",
      "Train loss =  0.8725384743884206\n",
      "Validation r2_score:  -109289483.08545788\n",
      "Validation MAE:  0.7816221676081139\n",
      "\tTrain Loss:  0.8725384743884206\n",
      "\tValidation MSE:  0.977185495088082\n",
      "\n",
      "Epoch 25/150\n",
      "Learning rate =  0.00933012701892221\n",
      "Train loss =  0.8627254022285342\n",
      "Validation r2_score:  -26856003.400492545\n",
      "Validation MAE:  0.7816108093340774\n",
      "\tTrain Loss:  0.8627254022285342\n",
      "\tValidation MSE:  0.9763320455225906\n",
      "\n",
      "Epoch 26/150\n",
      "Learning rate =  0.009276821300802549\n",
      "Train loss =  0.8419913621619344\n",
      "Validation r2_score:  -21324275.331477653\n",
      "Validation MAE:  0.7814293606499142\n",
      "\tTrain Loss:  0.8419913621619344\n",
      "\tValidation MSE:  0.9763847353106923\n",
      "\n",
      "Epoch 27/150\n",
      "Learning rate =  0.009221639627510093\n",
      "Train loss =  0.8263483553503951\n",
      "Validation r2_score:  -2140435.5380956135\n",
      "Validation MAE:  0.781768398010172\n",
      "\tTrain Loss:  0.8263483553503951\n",
      "\tValidation MSE:  0.9778951490741205\n",
      "\n",
      "Epoch 28/150\n",
      "Learning rate =  0.009164606203550502\n",
      "Train loss =  0.8191953438023726\n",
      "Validation r2_score:  -1533199.6777791618\n",
      "Validation MAE:  0.7826088704078429\n",
      "\tTrain Loss:  0.8191953438023726\n",
      "\tValidation MSE:  0.9789464084549554\n",
      "\n",
      "Epoch 29/150\n",
      "Learning rate =  0.009105746045668526\n",
      "Train loss =  0.7980472535515825\n",
      "Validation r2_score:  -290361.33481476805\n",
      "Validation MAE:  0.7825984919617021\n",
      "\tTrain Loss:  0.7980472535515825\n",
      "\tValidation MSE:  0.9790292470455261\n",
      "\n",
      "Epoch 30/150\n",
      "Learning rate =  0.009045084971874747\n",
      "Train loss =  0.8215648327022791\n",
      "Validation r2_score:  -405854.4415526825\n",
      "Validation MAE:  0.7813980472545229\n",
      "\tTrain Loss:  0.8215648327022791\n",
      "\tValidation MSE:  0.9767469275855973\n",
      "\n",
      "Epoch 31/150\n",
      "Learning rate =  0.00898264959012099\n",
      "Train loss =  0.8077405902246634\n",
      "Validation r2_score:  -34294.49547974198\n",
      "Validation MAE:  0.7842982622787364\n",
      "\tTrain Loss:  0.8077405902246634\n",
      "\tValidation MSE:  0.9853641571293167\n",
      "\n",
      "Epoch 32/150\n",
      "Learning rate =  0.008918467286629215\n",
      "Train loss =  0.8105537317072352\n",
      "Validation r2_score:  -34582.31117418863\n",
      "Validation MAE:  0.780946521776873\n",
      "\tTrain Loss:  0.8105537317072352\n",
      "\tValidation MSE:  0.974898552020984\n",
      "\n",
      "Epoch 33/150\n",
      "Learning rate =  0.00885256621387896\n",
      "Train loss =  0.7965862937271595\n",
      "Validation r2_score:  -29702.052998866133\n",
      "Validation MAE:  0.7804948474917365\n",
      "\tTrain Loss:  0.7965862937271595\n",
      "\tValidation MSE:  0.9740668662605843\n",
      "\n",
      "Epoch 34/150\n",
      "Learning rate =  0.008784975278258812\n",
      "Train loss =  0.7683133641257882\n",
      "Validation r2_score:  -13234.561954490284\n",
      "Validation MAE:  0.7812083220469752\n",
      "\tTrain Loss:  0.7683133641257882\n",
      "\tValidation MSE:  0.9751181995677136\n",
      "\n",
      "Epoch 35/150\n",
      "Learning rate =  0.008715724127387005\n",
      "Train loss =  0.7903887946158648\n",
      "Validation r2_score:  -5715.37304811304\n",
      "Validation MAE:  0.7805315724411367\n",
      "\tTrain Loss:  0.7903887946158648\n",
      "\tValidation MSE:  0.9742000034772597\n",
      "\n",
      "Epoch 36/150\n",
      "Learning rate =  0.0086448431371071\n",
      "Train loss =  0.7243585431327423\n",
      "Validation r2_score:  -1756.3172513571967\n",
      "Validation MAE:  0.7789513450599654\n",
      "\tTrain Loss:  0.7243585431327423\n",
      "\tValidation MSE:  0.9720023078239405\n",
      "\n",
      "Epoch 37/150\n",
      "Learning rate =  0.008572363398164057\n",
      "Train loss =  0.7283549097677072\n",
      "Validation r2_score:  -661.6980549262956\n",
      "Validation MAE:  0.7771944376086118\n",
      "\tTrain Loss:  0.7283549097677072\n",
      "\tValidation MSE:  0.9662009041740841\n",
      "\n",
      "Epoch 38/150\n",
      "Learning rate =  0.008498316702566866\n",
      "Train loss =  0.7610991957286993\n",
      "Validation r2_score:  -336.6399157214778\n",
      "Validation MAE:  0.7742854054994907\n",
      "\tTrain Loss:  0.7610991957286993\n",
      "\tValidation MSE:  0.9611401243387354\n",
      "\n",
      "Epoch 39/150\n",
      "Learning rate =  0.00842273552964348\n",
      "Train loss =  0.699539971848329\n",
      "Validation r2_score:  -61.075437563489224\n",
      "Validation MAE:  0.7663428800347469\n",
      "\tTrain Loss:  0.699539971848329\n",
      "\tValidation MSE:  0.9383274263484775\n",
      "\n",
      "Epoch 40/150\n",
      "Learning rate =  0.008345653031794334\n",
      "Train loss =  0.6513388563568393\n",
      "Validation r2_score:  -72.68011919786474\n",
      "Validation MAE:  0.770241217815836\n",
      "\tTrain Loss:  0.6513388563568393\n",
      "\tValidation MSE:  0.9600434895810351\n",
      "\n",
      "Epoch 41/150\n",
      "Learning rate =  0.008267103019950567\n",
      "Train loss =  0.6465360568836331\n",
      "Validation r2_score:  -23.769694481955693\n",
      "Validation MAE:  0.7556177184531108\n",
      "\tTrain Loss:  0.6465360568836331\n",
      "\tValidation MSE:  0.9239242160334904\n",
      "\n",
      "Epoch 42/150\n",
      "Learning rate =  0.008187119948743491\n",
      "Train loss =  0.5890699289739132\n",
      "Validation r2_score:  -20.2371901898408\n",
      "Validation MAE:  0.7531740128484737\n",
      "\tTrain Loss:  0.5890699289739132\n",
      "\tValidation MSE:  0.9303101231198624\n",
      "\n",
      "Epoch 43/150\n",
      "Learning rate =  0.008105738901391603\n",
      "Train loss =  0.581224464190503\n",
      "Validation r2_score:  -3.0082753670989497\n",
      "Validation MAE:  0.8240793968511524\n",
      "\tTrain Loss:  0.581224464190503\n",
      "\tValidation MSE:  1.069416300633258\n",
      "\n",
      "Epoch 44/150\n",
      "Learning rate =  0.008022995574311912\n",
      "Train loss =  0.5319200092926621\n",
      "Validation r2_score:  -1.2280706754697857\n",
      "Validation MAE:  0.8254318090148278\n",
      "\tTrain Loss:  0.5319200092926621\n",
      "\tValidation MSE:  1.134963401169093\n",
      "\n",
      "Epoch 45/150\n",
      "Learning rate =  0.007938926261462398\n",
      "Train loss =  0.5212473822757602\n",
      "Validation r2_score:  -0.42819216208428856\n",
      "Validation MAE:  1.1014264405010796\n",
      "\tTrain Loss:  0.5212473822757602\n",
      "\tValidation MSE:  1.9655240291332077\n",
      "\n",
      "Epoch 46/150\n",
      "Learning rate =  0.007853567838422188\n",
      "Train loss =  0.5195370844254891\n",
      "Validation r2_score:  -0.5028846671575646\n",
      "Validation MAE:  0.9571972241317939\n",
      "\tTrain Loss:  0.5195370844254891\n",
      "\tValidation MSE:  1.4971751644160831\n",
      "\n",
      "Epoch 47/150\n",
      "Learning rate =  0.007766957746216742\n",
      "Train loss =  0.47558211954310536\n",
      "Validation r2_score:  -0.1294876424735001\n",
      "Validation MAE:  1.2619338418260326\n",
      "\tTrain Loss:  0.47558211954310536\n",
      "\tValidation MSE:  2.5830966332971315\n",
      "\n",
      "Epoch 48/150\n",
      "Learning rate =  0.007679133974895005\n",
      "Train loss =  0.44670201434443396\n",
      "Validation r2_score:  0.050807670591548115\n",
      "Validation MAE:  1.5727746842155812\n",
      "\tTrain Loss:  0.44670201434443396\n",
      "\tValidation MSE:  5.031528873648877\n",
      "\n",
      "Epoch 49/150\n",
      "Learning rate =  0.007590135046865675\n",
      "Train loss =  0.4198177463064591\n",
      "Validation r2_score:  0.07931850130463147\n",
      "Validation MAE:  2.0190842063841306\n",
      "\tTrain Loss:  0.4198177463064591\n",
      "\tValidation MSE:  6.509647288486463\n",
      "\n",
      "Epoch 50/150\n",
      "Learning rate =  0.007500000000000015\n",
      "Train loss =  0.3654129570350051\n",
      "Validation r2_score:  -0.12517801999252698\n",
      "Validation MAE:  2.0096516347076685\n",
      "\tTrain Loss:  0.3654129570350051\n",
      "\tValidation MSE:  6.944382305190412\n",
      "\n",
      "Epoch 51/150\n",
      "Learning rate =  0.007408768370508594\n",
      "Train loss =  0.3459425838664174\n",
      "Validation r2_score:  0.0472375718653123\n",
      "Validation MAE:  1.4172323865993544\n",
      "\tTrain Loss:  0.3459425838664174\n",
      "\tValidation MSE:  3.2786746963475677\n",
      "\n",
      "Epoch 52/150\n",
      "Learning rate =  0.007316480175599335\n",
      "Train loss =  0.32813522142047685\n",
      "Validation r2_score:  -0.11578976214474279\n",
      "Validation MAE:  2.1680589924714226\n",
      "\tTrain Loss:  0.32813522142047685\n",
      "\tValidation MSE:  7.3644821659981625\n",
      "\n",
      "Epoch 53/150\n",
      "Learning rate =  0.007223175895924661\n",
      "Train loss =  0.3178523805302878\n",
      "Validation r2_score:  0.040861482462208776\n",
      "Validation MAE:  1.9478926807604773\n",
      "\tTrain Loss:  0.3178523805302878\n",
      "\tValidation MSE:  6.123129868668135\n",
      "\n",
      "Epoch 54/150\n",
      "Learning rate =  0.007128896457825389\n",
      "Train loss =  0.26970954208324355\n",
      "Validation r2_score:  -0.05811337880720169\n",
      "Validation MAE:  3.422588407585597\n",
      "\tTrain Loss:  0.26970954208324355\n",
      "\tValidation MSE:  25.58702838632561\n",
      "\n",
      "Epoch 55/150\n",
      "Learning rate =  0.007033683215379032\n",
      "Train loss =  0.24617222137749195\n",
      "Validation r2_score:  -0.035528036954279196\n",
      "Validation MAE:  1.7909939361573517\n",
      "\tTrain Loss:  0.24617222137749195\n",
      "\tValidation MSE:  5.211567625185988\n",
      "\n",
      "Epoch 56/150\n",
      "Learning rate =  0.006937577932260537\n",
      "Train loss =  0.2528451532901575\n",
      "Validation r2_score:  -0.28751746145442736\n",
      "Validation MAE:  2.02992188001581\n",
      "\tTrain Loss:  0.2528451532901575\n",
      "\tValidation MSE:  6.407221867540008\n",
      "\n",
      "Epoch 57/150\n",
      "Learning rate =  0.006840622763423421\n",
      "Train loss =  0.21487150729323426\n",
      "Validation r2_score:  0.12004457977038119\n",
      "Validation MAE:  1.8008208356507454\n",
      "\tTrain Loss:  0.21487150729323426\n",
      "\tValidation MSE:  5.73322584762669\n",
      "\n",
      "Epoch 58/150\n",
      "Learning rate =  0.00674286023660911\n",
      "Train loss =  0.2004418409584711\n",
      "Validation r2_score:  0.13649653984391208\n",
      "Validation MAE:  1.9560438310828476\n",
      "\tTrain Loss:  0.2004418409584711\n",
      "\tValidation MSE:  7.143177892117887\n",
      "\n",
      "Epoch 59/150\n",
      "Learning rate =  0.0066443332336929535\n",
      "Train loss =  0.20377705184121928\n",
      "Validation r2_score:  0.10741056250623782\n",
      "Validation MAE:  1.5597212866132604\n",
      "\tTrain Loss:  0.20377705184121928\n",
      "\tValidation MSE:  5.6564889507044676\n",
      "\n",
      "Epoch 60/150\n",
      "Learning rate =  0.006545084971874777\n",
      "Train loss =  0.18130121294719478\n",
      "Validation r2_score:  0.09586456700085155\n",
      "Validation MAE:  1.6181246192214722\n",
      "\tTrain Loss:  0.18130121294719478\n",
      "\tValidation MSE:  4.658136134078201\n",
      "\n",
      "Epoch 61/150\n",
      "Learning rate =  0.006445158984722396\n",
      "Train loss =  0.17005593880700567\n",
      "Validation r2_score:  0.005856748789637156\n",
      "Validation MAE:  1.6592932871928796\n",
      "\tTrain Loss:  0.17005593880700567\n",
      "\tValidation MSE:  4.788514167501701\n",
      "\n",
      "Epoch 62/150\n",
      "Learning rate =  0.006344599103076369\n",
      "Train loss =  0.17916726615900794\n",
      "Validation r2_score:  0.09684590519717173\n",
      "Validation MAE:  1.5226604561741384\n",
      "\tTrain Loss:  0.17916726615900794\n",
      "\tValidation MSE:  4.618310001121023\n",
      "\n",
      "Epoch 63/150\n",
      "Learning rate =  0.006243449435824313\n",
      "Train loss =  0.1783610616500179\n",
      "Validation r2_score:  0.1336433240461784\n",
      "Validation MAE:  1.8724690374581263\n",
      "\tTrain Loss:  0.1783610616500179\n",
      "\tValidation MSE:  6.947739044281221\n",
      "\n",
      "Epoch 64/150\n",
      "Learning rate =  0.006141754350553322\n",
      "Train loss =  0.1541411424210916\n",
      "Validation r2_score:  -0.014621888559467111\n",
      "Validation MAE:  2.3761137226967515\n",
      "\tTrain Loss:  0.1541411424210916\n",
      "\tValidation MSE:  16.87343310242275\n",
      "\n",
      "Epoch 65/150\n",
      "Learning rate =  0.006039558454088836\n",
      "Train loss =  0.1534154563366125\n",
      "Validation r2_score:  0.12671121941184027\n",
      "Validation MAE:  2.158390312985577\n",
      "\tTrain Loss:  0.1534154563366125\n",
      "\tValidation MSE:  8.066339918991485\n",
      "\n",
      "Epoch 66/150\n",
      "Learning rate =  0.00593690657292866\n",
      "Train loss =  0.15606738805460432\n",
      "Validation r2_score:  0.16836304105805733\n",
      "Validation MAE:  1.7084786788604038\n",
      "\tTrain Loss:  0.15606738805460432\n",
      "\tValidation MSE:  5.748330866344907\n",
      "\n",
      "Epoch 67/150\n",
      "Learning rate =  0.005833843733580546\n",
      "Train loss =  0.1272210372844711\n",
      "Validation r2_score:  0.1574676756977198\n",
      "Validation MAE:  1.790522593817223\n",
      "\tTrain Loss:  0.1272210372844711\n",
      "\tValidation MSE:  5.697125508635354\n",
      "\n",
      "Epoch 68/150\n",
      "Learning rate =  0.005730415142812095\n",
      "Train loss =  0.12772092378387848\n",
      "Validation r2_score:  0.12288617482435316\n",
      "Validation MAE:  1.5834286042471037\n",
      "\tTrain Loss:  0.12772092378387848\n",
      "\tValidation MSE:  5.71182779271151\n",
      "\n",
      "Epoch 69/150\n",
      "Learning rate =  0.005626666167821559\n",
      "Train loss =  0.1313559226303672\n",
      "Validation r2_score:  0.005319561146742591\n",
      "Validation MAE:  1.7369141593351152\n",
      "\tTrain Loss:  0.1313559226303672\n",
      "\tValidation MSE:  5.557614683023947\n",
      "\n",
      "Epoch 70/150\n",
      "Learning rate =  0.005522642316338296\n",
      "Train loss =  0.13751455831031004\n",
      "Validation r2_score:  0.0025852057535268314\n",
      "Validation MAE:  2.3219302146739143\n",
      "\tTrain Loss:  0.13751455831031004\n",
      "\tValidation MSE:  9.20944630945164\n",
      "\n",
      "Epoch 71/150\n",
      "Learning rate =  0.0054183892166616045\n",
      "Train loss =  0.1305880192279195\n",
      "Validation r2_score:  0.08879060636409897\n",
      "Validation MAE:  2.9736617091180944\n",
      "\tTrain Loss:  0.1305880192279195\n",
      "\tValidation MSE:  14.729633181362983\n",
      "\n",
      "Epoch 72/150\n",
      "Learning rate =  0.005313952597646596\n",
      "Train loss =  0.11529795251165827\n",
      "Validation r2_score:  0.17038329905019245\n",
      "Validation MAE:  2.713054653879608\n",
      "\tTrain Loss:  0.11529795251165827\n",
      "\tValidation MSE:  13.21969831672557\n",
      "\n",
      "Epoch 73/150\n",
      "Learning rate =  0.005209378268646026\n",
      "Train loss =  0.10877881400908034\n",
      "Validation r2_score:  0.14098964979314832\n",
      "Validation MAE:  3.1160577462627828\n",
      "\tTrain Loss:  0.10877881400908034\n",
      "\tValidation MSE:  18.424310538713154\n",
      "\n",
      "Epoch 74/150\n",
      "Learning rate =  0.0051047120994168116\n",
      "Train loss =  0.10717765560063224\n",
      "Validation r2_score:  0.17294162807322322\n",
      "Validation MAE:  2.8496551274818467\n",
      "\tTrain Loss:  0.10717765560063224\n",
      "\tValidation MSE:  14.517703527584402\n",
      "\n",
      "Epoch 75/150\n",
      "Learning rate =  0.005000000000000024\n",
      "Train loss =  0.10124282892017315\n",
      "Validation r2_score:  0.13909402153526984\n",
      "Validation MAE:  3.581568609252806\n",
      "\tTrain Loss:  0.10124282892017315\n",
      "\tValidation MSE:  22.09958133677335\n",
      "\n",
      "Epoch 76/150\n",
      "Learning rate =  0.004895287900583241\n",
      "Train loss =  0.10179144163460781\n",
      "Validation r2_score:  0.17917640332189155\n",
      "Validation MAE:  2.9763342259355\n",
      "\tTrain Loss:  0.10179144163460781\n",
      "\tValidation MSE:  15.533015242766552\n",
      "\n",
      "Epoch 77/150\n",
      "Learning rate =  0.00479062173135402\n",
      "Train loss =  0.0932402105924363\n",
      "Validation r2_score:  0.20608145025607505\n",
      "Validation MAE:  2.442628018103527\n",
      "\tTrain Loss:  0.0932402105924363\n",
      "\tValidation MSE:  9.944680182956262\n",
      "\n",
      "Epoch 78/150\n",
      "Learning rate =  0.004686047402353452\n",
      "Train loss =  0.09393188718240708\n",
      "Validation r2_score:  0.23495904982594362\n",
      "Validation MAE:  1.7741297738893451\n",
      "\tTrain Loss:  0.09393188718240708\n",
      "\tValidation MSE:  5.905317997137759\n",
      "\n",
      "Epoch 79/150\n",
      "Learning rate =  0.004581610783338441\n",
      "Train loss =  0.0810534738120623\n",
      "Validation r2_score:  0.20981848870150277\n",
      "Validation MAE:  2.5038079294087963\n",
      "\tTrain Loss:  0.0810534738120623\n",
      "\tValidation MSE:  10.538690410521463\n",
      "\n",
      "Epoch 80/150\n",
      "Learning rate =  0.004477357683661747\n",
      "Train loss =  0.08165428453745942\n",
      "Validation r2_score:  0.17331015101353042\n",
      "Validation MAE:  2.1644175122369753\n",
      "\tTrain Loss:  0.08165428453745942\n",
      "\tValidation MSE:  8.080762623692149\n",
      "\n",
      "Epoch 81/150\n",
      "Learning rate =  0.004373333832178495\n",
      "Train loss =  0.08310264215106145\n",
      "Validation r2_score:  0.21529509530175406\n",
      "Validation MAE:  1.7684303246556514\n",
      "\tTrain Loss:  0.08310264215106145\n",
      "\tValidation MSE:  5.31363642256197\n",
      "\n",
      "Epoch 82/150\n",
      "Learning rate =  0.00426958485718796\n",
      "Train loss =  0.07314339373260736\n",
      "Validation r2_score:  0.15551247028432402\n",
      "Validation MAE:  2.3366354153800932\n",
      "\tTrain Loss:  0.07314339373260736\n",
      "\tValidation MSE:  10.274366308278077\n",
      "\n",
      "Epoch 83/150\n",
      "Learning rate =  0.004166156266419504\n",
      "Train loss =  0.06712058450405796\n",
      "Validation r2_score:  0.22404674873820662\n",
      "Validation MAE:  2.2617965627724272\n",
      "\tTrain Loss:  0.06712058450405796\n",
      "\tValidation MSE:  8.308832329047782\n",
      "\n",
      "Epoch 84/150\n",
      "Learning rate =  0.0040630934270713915\n",
      "Train loss =  0.07017745448198791\n",
      "Validation r2_score:  0.23585090698640898\n",
      "Validation MAE:  1.9482270605967393\n",
      "\tTrain Loss:  0.07017745448198791\n",
      "\tValidation MSE:  6.454381052927954\n",
      "\n",
      "Epoch 85/150\n",
      "Learning rate =  0.003960441545911221\n",
      "Train loss =  0.06742510325663413\n",
      "Validation r2_score:  0.22766205616389867\n",
      "Validation MAE:  2.0907088304847505\n",
      "\tTrain Loss:  0.06742510325663413\n",
      "\tValidation MSE:  7.869191673607817\n",
      "\n",
      "Epoch 86/150\n",
      "Learning rate =  0.0038582456494467366\n",
      "Train loss =  0.06937141941549878\n",
      "Validation r2_score:  0.2408744779265638\n",
      "Validation MAE:  1.8128035597446839\n",
      "\tTrain Loss:  0.06937141941549878\n",
      "\tValidation MSE:  5.822866201850262\n",
      "\n",
      "Epoch 87/150\n",
      "Learning rate =  0.0037565505641757382\n",
      "Train loss =  0.06868191414590304\n",
      "Validation r2_score:  0.2862946035610374\n",
      "Validation MAE:  1.7109345190028222\n",
      "\tTrain Loss:  0.06868191414590304\n",
      "\tValidation MSE:  4.912144183558791\n",
      "\n",
      "Epoch 88/150\n",
      "Learning rate =  0.003655400896923682\n",
      "Train loss =  0.0642610175612693\n",
      "Validation r2_score:  0.23223481070296859\n",
      "Validation MAE:  2.0846465226123536\n",
      "\tTrain Loss:  0.0642610175612693\n",
      "\tValidation MSE:  7.509321461146906\n",
      "\n",
      "Epoch 89/150\n",
      "Learning rate =  0.0035548410152776554\n",
      "Train loss =  0.060834250529296696\n",
      "Validation r2_score:  0.2994252151109682\n",
      "Validation MAE:  1.642573546510313\n",
      "\tTrain Loss:  0.060834250529296696\n",
      "\tValidation MSE:  4.670221089644398\n",
      "\n",
      "Epoch 90/150\n",
      "Learning rate =  0.003454915028125274\n",
      "Train loss =  0.05507626488300351\n",
      "Validation r2_score:  0.2572507490319702\n",
      "Validation MAE:  1.7776038205483928\n",
      "\tTrain Loss:  0.05507626488300351\n",
      "\tValidation MSE:  5.226464657697929\n",
      "\n",
      "Epoch 91/150\n",
      "Learning rate =  0.0033556667663070918\n",
      "Train loss =  0.05889685940928757\n",
      "Validation r2_score:  0.2610569920854432\n",
      "Validation MAE:  1.803878969503843\n",
      "\tTrain Loss:  0.05889685940928757\n",
      "\tValidation MSE:  6.045925554374006\n",
      "\n",
      "Epoch 92/150\n",
      "Learning rate =  0.003257139763390932\n",
      "Train loss =  0.05554855659526462\n",
      "Validation r2_score:  0.34695674577896385\n",
      "Validation MAE:  1.3657265705865549\n",
      "\tTrain Loss:  0.05554855659526462\n",
      "\tValidation MSE:  3.1704072986231417\n",
      "\n",
      "Epoch 93/150\n",
      "Learning rate =  0.0031593772365766178\n",
      "Train loss =  0.061140441976021975\n",
      "Validation r2_score:  0.23886194223295187\n",
      "Validation MAE:  1.6287137037052744\n",
      "\tTrain Loss:  0.061140441976021975\n",
      "\tValidation MSE:  5.154486029776915\n",
      "\n",
      "Epoch 94/150\n",
      "Learning rate =  0.0030624220677394885\n",
      "Train loss =  0.0656131980358623\n",
      "Validation r2_score:  0.31259416835271925\n",
      "Validation MAE:  1.2423740718869885\n",
      "\tTrain Loss:  0.0656131980358623\n",
      "\tValidation MSE:  2.9653079095875903\n",
      "\n",
      "Epoch 95/150\n",
      "Learning rate =  0.0029663167846210006\n",
      "Train loss =  0.06332461310861011\n",
      "Validation r2_score:  0.3724569711395437\n",
      "Validation MAE:  1.2206331553489405\n",
      "\tTrain Loss:  0.06332461310861011\n",
      "\tValidation MSE:  2.4733572667941526\n",
      "\n",
      "Epoch 96/150\n",
      "Learning rate =  0.00287110354217464\n",
      "Train loss =  0.05881374919166168\n",
      "Validation r2_score:  0.3651800558863738\n",
      "Validation MAE:  1.4105815618287254\n",
      "\tTrain Loss:  0.05881374919166168\n",
      "\tValidation MSE:  3.4733713218116096\n",
      "\n",
      "Epoch 97/150\n",
      "Learning rate =  0.0027768241040753683\n",
      "Train loss =  0.05579977934636796\n",
      "Validation r2_score:  0.3360593721631938\n",
      "Validation MAE:  1.3769047348690964\n",
      "\tTrain Loss:  0.05579977934636796\n",
      "\tValidation MSE:  3.106304174518814\n",
      "\n",
      "Epoch 98/150\n",
      "Learning rate =  0.0026835198244006945\n",
      "Train loss =  0.0505683932666822\n",
      "Validation r2_score:  0.2819973778304604\n",
      "Validation MAE:  1.6311180094319724\n",
      "\tTrain Loss:  0.0505683932666822\n",
      "\tValidation MSE:  4.741933569588652\n",
      "\n",
      "Epoch 99/150\n",
      "Learning rate =  0.0025912316294914293\n",
      "Train loss =  0.047944704769179225\n",
      "Validation r2_score:  0.3599425562289532\n",
      "Validation MAE:  1.4667656233456607\n",
      "\tTrain Loss:  0.047944704769179225\n",
      "\tValidation MSE:  3.5529501034376563\n",
      "\n",
      "Epoch 100/150\n",
      "Learning rate =  0.0025000000000000066\n",
      "Train loss =  0.04991724487626925\n",
      "Validation r2_score:  0.43909985963977227\n",
      "Validation MAE:  1.1053866790060047\n",
      "\tTrain Loss:  0.04991724487626925\n",
      "\tValidation MSE:  1.9964418020487655\n",
      "\n",
      "Epoch 101/150\n",
      "Learning rate =  0.002409864953134356\n",
      "Train loss =  0.05047206700934718\n",
      "Validation r2_score:  0.3983960649123194\n",
      "Validation MAE:  1.0970075996130169\n",
      "\tTrain Loss:  0.05047206700934718\n",
      "\tValidation MSE:  2.0518431673232214\n",
      "\n",
      "Epoch 102/150\n",
      "Learning rate =  0.0023208660251050253\n",
      "Train loss =  0.050373166906259335\n",
      "Validation r2_score:  0.3732290581855736\n",
      "Validation MAE:  1.2626469781027987\n",
      "\tTrain Loss:  0.050373166906259335\n",
      "\tValidation MSE:  2.5943827102048322\n",
      "\n",
      "Epoch 103/150\n",
      "Learning rate =  0.0022330422537832862\n",
      "Train loss =  0.046897586047028504\n",
      "Validation r2_score:  0.3611647120269431\n",
      "Validation MAE:  1.096689318157371\n",
      "\tTrain Loss:  0.046897586047028504\n",
      "\tValidation MSE:  2.1772557286400764\n",
      "\n",
      "Epoch 104/150\n",
      "Learning rate =  0.002146432161577847\n",
      "Train loss =  0.04647647525416687\n",
      "Validation r2_score:  0.4339279507472622\n",
      "Validation MAE:  0.9775468225949168\n",
      "\tTrain Loss:  0.04647647525416687\n",
      "\tValidation MSE:  1.6780302358705361\n",
      "\n",
      "Epoch 105/150\n",
      "Learning rate =  0.0020610737385376395\n",
      "Train loss =  0.044108994402146585\n",
      "Validation r2_score:  0.4334695603941572\n",
      "Validation MAE:  0.9703508660725645\n",
      "\tTrain Loss:  0.044108994402146585\n",
      "\tValidation MSE:  1.6859966775543187\n",
      "\n",
      "Epoch 106/150\n",
      "Learning rate =  0.00197700442568813\n",
      "Train loss =  0.037322988151572645\n",
      "Validation r2_score:  0.3968719701436887\n",
      "Validation MAE:  1.0154071388235655\n",
      "\tTrain Loss:  0.037322988151572645\n",
      "\tValidation MSE:  1.8353213733308957\n",
      "\n",
      "Epoch 107/150\n",
      "Learning rate =  0.0018942610986084512\n",
      "Train loss =  0.03662484514643438\n",
      "Validation r2_score:  0.4079869135450037\n",
      "Validation MAE:  0.9789408454719344\n",
      "\tTrain Loss:  0.03662484514643438\n",
      "\tValidation MSE:  1.8623496736142695\n",
      "\n",
      "Epoch 108/150\n",
      "Learning rate =  0.0018128800512565546\n",
      "Train loss =  0.03580931465451916\n",
      "Validation r2_score:  0.4135905686967353\n",
      "Validation MAE:  0.7985226649320025\n",
      "\tTrain Loss:  0.03580931465451916\n",
      "\tValidation MSE:  1.1581821608211686\n",
      "\n",
      "Epoch 109/150\n",
      "Learning rate =  0.0017328969800494748\n",
      "Train loss =  0.036737005963611104\n",
      "Validation r2_score:  0.43279654924679245\n",
      "Validation MAE:  0.8961945088536661\n",
      "\tTrain Loss:  0.036737005963611104\n",
      "\tValidation MSE:  1.5200082052407464\n",
      "\n",
      "Epoch 110/150\n",
      "Learning rate =  0.0016543469682057121\n",
      "Train loss =  0.029509895878921572\n",
      "Validation r2_score:  0.4701236403094995\n",
      "Validation MAE:  0.7588650846644411\n",
      "\tTrain Loss:  0.029509895878921572\n",
      "\tValidation MSE:  1.1588223562863174\n",
      "\n",
      "Epoch 111/150\n",
      "Learning rate =  0.0015772644703565598\n",
      "Train loss =  0.03266404579820422\n",
      "Validation r2_score:  0.46376363468964976\n",
      "Validation MAE:  0.8142803436741616\n",
      "\tTrain Loss:  0.03266404579820422\n",
      "\tValidation MSE:  1.229755281427979\n",
      "\n",
      "Epoch 112/150\n",
      "Learning rate =  0.0015016832974331733\n",
      "Train loss =  0.028874238923890516\n",
      "Validation r2_score:  0.45295597363708673\n",
      "Validation MAE:  0.761946528965552\n",
      "\tTrain Loss:  0.028874238923890516\n",
      "\tValidation MSE:  1.1134790843931714\n",
      "\n",
      "Epoch 113/150\n",
      "Learning rate =  0.0014276366018359855\n",
      "Train loss =  0.025703005623654462\n",
      "Validation r2_score:  0.47304914380940166\n",
      "Validation MAE:  0.835739534161666\n",
      "\tTrain Loss:  0.025703005623654462\n",
      "\tValidation MSE:  1.2961584947055376\n",
      "\n",
      "Epoch 114/150\n",
      "Learning rate =  0.001355156862892943\n",
      "Train loss =  0.02685860848093095\n",
      "Validation r2_score:  0.4736260531408907\n",
      "Validation MAE:  0.7512003900382251\n",
      "\tTrain Loss:  0.02685860848093095\n",
      "\tValidation MSE:  1.095618440687336\n",
      "\n",
      "Epoch 115/150\n",
      "Learning rate =  0.0012842758726130284\n",
      "Train loss =  0.02777872734198657\n",
      "Validation r2_score:  0.5121173220917157\n",
      "Validation MAE:  0.7387910458396432\n",
      "\tTrain Loss:  0.02777872734198657\n",
      "\tValidation MSE:  1.0081324407460115\n",
      "\n",
      "Epoch 116/150\n",
      "Learning rate =  0.0012150247217412196\n",
      "Train loss =  0.024907463307802875\n",
      "Validation r2_score:  0.5140610013397229\n",
      "Validation MAE:  0.704655287000053\n",
      "\tTrain Loss:  0.024907463307802875\n",
      "\tValidation MSE:  0.9437018857220489\n",
      "\n",
      "Epoch 117/150\n",
      "Learning rate =  0.0011474337861210556\n",
      "Train loss =  0.025967564230086282\n",
      "Validation r2_score:  0.5096943734633881\n",
      "Validation MAE:  0.6445538292412506\n",
      "\tTrain Loss:  0.025967564230086282\n",
      "\tValidation MSE:  0.8415641994879892\n",
      "\n",
      "Epoch 118/150\n",
      "Learning rate =  0.001081532713370801\n",
      "Train loss =  0.022623523749643937\n",
      "Validation r2_score:  0.509576752836909\n",
      "Validation MAE:  0.5942144045987928\n",
      "\tTrain Loss:  0.022623523749643937\n",
      "\tValidation MSE:  0.7126629789976877\n",
      "\n",
      "Epoch 119/150\n",
      "Learning rate =  0.0010173504098790198\n",
      "Train loss =  0.02231525030704991\n",
      "Validation r2_score:  0.5150646626165309\n",
      "Validation MAE:  0.6597671998440411\n",
      "\tTrain Loss:  0.02231525030704991\n",
      "\tValidation MSE:  0.8670659374958933\n",
      "\n",
      "Epoch 120/150\n",
      "Learning rate =  0.0009549150281252639\n",
      "Train loss =  0.02210888112313114\n",
      "Validation r2_score:  0.537125196535752\n",
      "Validation MAE:  0.5471740490826034\n",
      "\tTrain Loss:  0.02210888112313114\n",
      "\tValidation MSE:  0.6322328628859765\n",
      "\n",
      "Epoch 121/150\n",
      "Learning rate =  0.0008942539543314802\n",
      "Train loss =  0.019157221026641007\n",
      "Validation r2_score:  0.5359363438717684\n",
      "Validation MAE:  0.6306098858463327\n",
      "\tTrain Loss:  0.019157221026641007\n",
      "\tValidation MSE:  0.8119768669493324\n",
      "\n",
      "Epoch 122/150\n",
      "Learning rate =  0.0008353937964495025\n",
      "Train loss =  0.018889494832061853\n",
      "Validation r2_score:  0.5447384823263091\n",
      "Validation MAE:  0.5704498837981585\n",
      "\tTrain Loss:  0.018889494832061853\n",
      "\tValidation MSE:  0.7047983076889581\n",
      "\n",
      "Epoch 123/150\n",
      "Learning rate =  0.0007783603724899242\n",
      "Train loss =  0.018560699420049787\n",
      "Validation r2_score:  0.5549043914119038\n",
      "Validation MAE:  0.5690815389059595\n",
      "\tTrain Loss:  0.018560699420049787\n",
      "\tValidation MSE:  0.6854387379371767\n",
      "\n",
      "Epoch 124/150\n",
      "Learning rate =  0.0007231786991974678\n",
      "Train loss =  0.01749603850475978\n",
      "Validation r2_score:  0.5632728273950616\n",
      "Validation MAE:  0.5208052222507465\n",
      "\tTrain Loss:  0.01749603850475978\n",
      "\tValidation MSE:  0.5741678172933846\n",
      "\n",
      "Epoch 125/150\n",
      "Learning rate =  0.0006698729810778063\n",
      "Train loss =  0.01665411173113777\n",
      "Validation r2_score:  0.5799389844438401\n",
      "Validation MAE:  0.5047877057626647\n",
      "\tTrain Loss:  0.01665411173113777\n",
      "\tValidation MSE:  0.5390422229195849\n",
      "\n",
      "Epoch 126/150\n",
      "Learning rate =  0.000618466599780682\n",
      "Train loss =  0.016466081445590437\n",
      "Validation r2_score:  0.5591260481071949\n",
      "Validation MAE:  0.4988230595617134\n",
      "\tTrain Loss:  0.016466081445590437\n",
      "\tValidation MSE:  0.5467762542010278\n",
      "\n",
      "Epoch 127/150\n",
      "Learning rate =  0.000568982103843927\n",
      "Train loss =  0.015557648909937901\n",
      "Validation r2_score:  0.5628227207424491\n",
      "Validation MAE:  0.47302726134881123\n",
      "\tTrain Loss:  0.015557648909937901\n",
      "\tValidation MSE:  0.4985109671574389\n",
      "\n",
      "Epoch 128/150\n",
      "Learning rate =  0.0005214411988029368\n",
      "Train loss =  0.015449885909523195\n",
      "Validation r2_score:  0.5680592375037838\n",
      "Validation MAE:  0.4792416354733813\n",
      "\tTrain Loss:  0.015449885909523195\n",
      "\tValidation MSE:  0.5239466796863538\n",
      "\n",
      "Epoch 129/150\n",
      "Learning rate =  0.0004758647376699029\n",
      "Train loss =  0.014347264494669313\n",
      "Validation r2_score:  0.5799558662525309\n",
      "Validation MAE:  0.4591618295185923\n",
      "\tTrain Loss:  0.014347264494669313\n",
      "\tValidation MSE:  0.4861331992039214\n",
      "\n",
      "Epoch 130/150\n",
      "Learning rate =  0.0004322727117869969\n",
      "Train loss =  0.013891415379475802\n",
      "Validation r2_score:  0.5747058189287927\n",
      "Validation MAE:  0.4428158314929442\n",
      "\tTrain Loss:  0.013891415379475802\n",
      "\tValidation MSE:  0.46062144742400213\n",
      "\n",
      "Epoch 131/150\n",
      "Learning rate =  0.0003906842420574988\n",
      "Train loss =  0.013735157929962346\n",
      "Validation r2_score:  0.5649128097972997\n",
      "Validation MAE:  0.41951983777612667\n",
      "\tTrain Loss:  0.013735157929962346\n",
      "\tValidation MSE:  0.4196437322037107\n",
      "\n",
      "Epoch 132/150\n",
      "Learning rate =  0.00035111757055874355\n",
      "Train loss =  0.01263312368731325\n",
      "Validation r2_score:  0.5815394186020906\n",
      "Validation MAE:  0.4209515200550434\n",
      "\tTrain Loss:  0.01263312368731325\n",
      "\tValidation MSE:  0.42860442186215814\n",
      "\n",
      "Epoch 133/150\n",
      "Learning rate =  0.0003135900525405433\n",
      "Train loss =  0.01172845360027471\n",
      "Validation r2_score:  0.5809220734974381\n",
      "Validation MAE:  0.4060016017174348\n",
      "\tTrain Loss:  0.01172845360027471\n",
      "\tValidation MSE:  0.4084016596990825\n",
      "\n",
      "Epoch 134/150\n",
      "Learning rate =  0.00027811814881259527\n",
      "Train loss =  0.012645697725626329\n",
      "Validation r2_score:  0.5603753581909152\n",
      "Validation MAE:  0.3906497981438634\n",
      "\tTrain Loss:  0.012645697725626329\n",
      "\tValidation MSE:  0.38977537880405533\n",
      "\n",
      "Epoch 135/150\n",
      "Learning rate =  0.0002447174185242333\n",
      "Train loss =  0.013551850012542369\n",
      "Validation r2_score:  0.5721873200884318\n",
      "Validation MAE:  0.38908896292506645\n",
      "\tTrain Loss:  0.013551850012542369\n",
      "\tValidation MSE:  0.390153196213218\n",
      "\n",
      "Epoch 136/150\n",
      "Learning rate =  0.0002134025123396641\n",
      "Train loss =  0.013043455367248194\n",
      "Validation r2_score:  0.5755916305384\n",
      "Validation MAE:  0.39211389592574425\n",
      "\tTrain Loss:  0.013043455367248194\n",
      "\tValidation MSE:  0.3989215709511247\n",
      "\n",
      "Epoch 137/150\n",
      "Learning rate =  0.00018418716601170988\n",
      "Train loss =  0.011257117919740267\n",
      "Validation r2_score:  0.5765144870357047\n",
      "Validation MAE:  0.39957462546370975\n",
      "\tTrain Loss:  0.011257117919740267\n",
      "\tValidation MSE:  0.40798629584629037\n",
      "\n",
      "Epoch 138/150\n",
      "Learning rate =  0.00015708419435684557\n",
      "Train loss =  0.011097832658075882\n",
      "Validation r2_score:  0.5673831010662281\n",
      "Validation MAE:  0.38793865980242365\n",
      "\tTrain Loss:  0.011097832658075882\n",
      "\tValidation MSE:  0.39251660871640304\n",
      "\n",
      "Epoch 139/150\n",
      "Learning rate =  0.00013210548563419885\n",
      "Train loss =  0.01101764078339329\n",
      "Validation r2_score:  0.5717105484137335\n",
      "Validation MAE:  0.3729960146688614\n",
      "\tTrain Loss:  0.01101764078339329\n",
      "\tValidation MSE:  0.3764569693940321\n",
      "\n",
      "Epoch 140/150\n",
      "Learning rate =  0.00010926199633097184\n",
      "Train loss =  0.010698246691996852\n",
      "Validation r2_score:  0.5699614502791702\n",
      "Validation MAE:  0.3736408111925309\n",
      "\tTrain Loss:  0.010698246691996852\n",
      "\tValidation MSE:  0.3798535645156569\n",
      "\n",
      "Epoch 141/150\n",
      "Learning rate =  8.856374635655722e-05\n",
      "Train loss =  0.01098112904583104\n",
      "Validation r2_score:  0.5709753902793664\n",
      "Validation MAE:  0.37023273446612043\n",
      "\tTrain Loss:  0.01098112904583104\n",
      "\tValidation MSE:  0.3775762297605446\n",
      "\n",
      "Epoch 142/150\n",
      "Learning rate =  7.001981464747527e-05\n",
      "Train loss =  0.010462773939555822\n",
      "Validation r2_score:  0.562881792649997\n",
      "Validation MAE:  0.35837119121421296\n",
      "\tTrain Loss:  0.010462773939555822\n",
      "\tValidation MSE:  0.3648910970594857\n",
      "\n",
      "Epoch 143/150\n",
      "Learning rate =  5.3638335185058485e-05\n",
      "Train loss =  0.009550938845980758\n",
      "Validation r2_score:  0.5669284722074206\n",
      "Validation MAE:  0.35406165329588485\n",
      "\tTrain Loss:  0.009550938845980758\n",
      "\tValidation MSE:  0.36096147404437035\n",
      "\n",
      "Epoch 144/150\n",
      "Learning rate =  3.9426493427611295e-05\n",
      "Train loss =  0.01006149474172465\n",
      "Validation r2_score:  0.566406411717702\n",
      "Validation MAE:  0.3542412600536367\n",
      "\tTrain Loss:  0.01006149474172465\n",
      "\tValidation MSE:  0.36224239328237867\n",
      "\n",
      "Epoch 145/150\n",
      "Learning rate =  2.7390523158633673e-05\n",
      "Train loss =  0.010121096381529545\n",
      "Validation r2_score:  0.5639236586150419\n",
      "Validation MAE:  0.3481002867877798\n",
      "\tTrain Loss:  0.010121096381529545\n",
      "\tValidation MSE:  0.3564164331686565\n",
      "\n",
      "Epoch 146/150\n",
      "Learning rate =  1.7535703752478253e-05\n",
      "Train loss =  0.009718911179030934\n",
      "Validation r2_score:  0.5644450120076938\n",
      "Validation MAE:  0.3440073608281516\n",
      "\tTrain Loss:  0.009718911179030934\n",
      "\tValidation MSE:  0.35209892599151044\n",
      "\n",
      "Epoch 147/150\n",
      "Learning rate =  9.86635785864226e-06\n",
      "Train loss =  0.009701443477145707\n",
      "Validation r2_score:  0.5618924546190494\n",
      "Validation MAE:  0.34039909288672027\n",
      "\tTrain Loss:  0.009701443477145707\n",
      "\tValidation MSE:  0.34883652573301277\n",
      "\n",
      "Epoch 148/150\n",
      "Learning rate =  4.385849505708107e-06\n",
      "Train loss =  0.009781857928222356\n",
      "Validation r2_score:  0.5596048552195552\n",
      "Validation MAE:  0.3365908634735135\n",
      "\tTrain Loss:  0.009781857928222356\n",
      "\tValidation MSE:  0.3453537326482931\n",
      "\n",
      "Epoch 149/150\n",
      "Learning rate =  1.0965826257725089e-06\n",
      "Train loss =  0.009398050489835441\n",
      "Validation r2_score:  0.5590185079726793\n",
      "Validation MAE:  0.33309377673598745\n",
      "\tTrain Loss:  0.009398050489835441\n",
      "\tValidation MSE:  0.3426000459243606\n",
      "\n",
      "Epoch 150/150\n",
      "Learning rate =  0.0\n",
      "Train loss =  0.009680704482889269\n",
      "Validation r2_score:  0.5577169528673782\n",
      "Validation MAE:  0.33005150517961224\n",
      "\tTrain Loss:  0.009680704482889269\n",
      "\tValidation MSE:  0.34026516661743816\n"
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs to train and evaluate your model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_mse = 1.0 ### Monitor best accuracy in your run\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    MSE = eval(model, val_loader)\n",
    "\n",
    "    print(\"\\tTrain Loss: \", train_loss)\n",
    "    print(\"\\tValidation MSE: \", MSE)\n",
    "\n",
    "    ### Save checkpoint if accuracy is better than your current best\n",
    "    if MSE < best_mse:\n",
    "        best_mse = MSE\n",
    "    ### Save checkpoint with information you want\n",
    "        torch.save({'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': train_loss,\n",
    "              'learning rate': scheduler.get_last_lr()[0],\n",
    "              'mse': MSE}, \n",
    "        './model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785492a-0e14-4148-8878-20ad6b73e85a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bcdd9a-731e-45b8-abd8-7d7e43c8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "  ### What you call for model to perform inference?\n",
    "    model.eval()\n",
    "\n",
    "  ### List to store predicted phonemes of test data\n",
    "    test_predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "  ### Which mode do you need to avoid gradients?\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for i, data in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            phoneme, groundtruth_AM = data\n",
    "            ### Move data to device (ideally GPU)\n",
    "            phoneme, groundtruth_AM = phoneme.to(device), groundtruth_AM.to(device)         \n",
    "          \n",
    "            predicted_AM = model(phoneme)\n",
    "            predicted_AM.squeeze_()\n",
    "            # print(predicted_AM.shape)\n",
    "            # print(groundtruth_AM.shape)\n",
    "\n",
    "          ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
    "            test_predictions.extend(predicted_AM.cpu().tolist())\n",
    "            ground_truth.extend(groundtruth_AM.cpu())\n",
    "    \n",
    "    # print(len(test_predictions))\n",
    "    return test_predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a867d0-7ad4-4856-8675-980cacf391a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 31.17it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, ground_truth = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d42276a-7ccd-458e-bcc5-dbefc769ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2505f8f3-6e26-44f5-964c-610aeae42b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create CSV file with predictions\n",
    "if gender == \"female\":\n",
    "    g_flag = \"F\"\n",
    "else:\n",
    "    g_flag = \"M\"\n",
    "    \n",
    "with open(\"./%s_\"%g_flag + \"phoneme%s\"%phoneme_idx +  \"_AM%s\" + \".csv\"%am_idx, \"w+\") as f:\n",
    "    f.write(\"person, label, prediction\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(\"{},{},{}\\n\".format(i, ground_truth[i], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77424a6-3f16-45d2-a290-a6e90508035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fd8331e-ad70-4eb5-a67b-9f11cb329bcc",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_project",
   "language": "python",
   "name": "torch_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
