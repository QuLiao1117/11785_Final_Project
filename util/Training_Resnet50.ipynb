{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b23894c-d552-4f3a-a65b-9f12b9d6be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import random\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d140e389-cf16-40eb-b078-6a1d0da9e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "config = {\n",
    "    'epochs': 200,\n",
    "    'batch_size' : 32,\n",
    "    'context' : 48,\n",
    "    'learning_rate' : 0.001,\n",
    "    'architecture' : 'very-low-cutoff'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bf0a6-3b35-4b0e-97e3-3a2e992101a2",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a61495c-d324-4401-b3ac-b8100dbf5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 128, partition = \"train\"):\n",
    "        \"\"\"\n",
    "        :param data_path: the root path of phonemes\n",
    "        :param am_path: the path of am (.csv)\n",
    "        :param gender: female or male\n",
    "        :param phoneme_idx: the phoneme index\n",
    "        :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "        :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "        :param partition: train / val1 / val2 / test\n",
    "        \"\"\"\n",
    "\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        # get phoneme list\n",
    "        self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "        phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "        length = len(phoneme_list)\n",
    "        # if partition == \"train\":\n",
    "        #     self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "        # elif partition == \"val1\":\n",
    "        #     self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "        # elif partition == \"val2\":\n",
    "        #     self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "        # elif partition == \"test\":\n",
    "        #     self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "            \n",
    "        if partition == \"train\":\n",
    "            self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "        elif partition == \"val1\":\n",
    "            self.phoneme_list = phoneme_list[int(0.7 * length):]\n",
    "\n",
    "\n",
    "        self.length = len(self.phoneme_list)\n",
    "\n",
    "        # get_am data\n",
    "        am_data = pd.read_csv(am_path)\n",
    "        self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return spec\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        item_filename = self.phoneme_list[ind]\n",
    "        item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "        phoneme = np.load(item_full_path)\n",
    "\n",
    "        person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "        try:\n",
    "            target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "        except:\n",
    "            print(\"person id =\", person_id)\n",
    "            target_am = 0.\n",
    "\n",
    "        # padding\n",
    "        phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "        # apply mel transform\n",
    "        phoneme = self.spectro_gram(phoneme)\n",
    "\n",
    "        std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "        phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "\n",
    "        if len(phoneme[0]) < MAX_LEN:\n",
    "            phoneme = np.pad(phoneme, ((0, 0), (0, MAX_LEN - len(phoneme[0]))), 'symmetric')\n",
    "            phoneme = torch.from_numpy(phoneme)\n",
    "        else:\n",
    "            phoneme = phoneme[:, :MAX_LEN]\n",
    "        # phoneme = torch.from_numpy(phoneme)\n",
    "        ##################################################################\n",
    "        phoneme.unsqueeze_(0)\n",
    "        ##################################################################\n",
    "        target_am = torch.tensor(target_am).to(torch.float32)\n",
    "        \n",
    "        return phoneme, target_am\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870d26e7-ad98-479d-8fcf-f21613bfae08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "#     def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 44100 * 2, partition = \"train\"):\n",
    "#         \"\"\"\n",
    "#         :param data_path: the root path of phonemes\n",
    "#         :param am_path: the path of am (.csv)\n",
    "#         :param gender: female or male\n",
    "#         :param phoneme_idx: the phoneme index\n",
    "#         :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "#         :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "#         :param partition: train / val1 / val2 / test\n",
    "#         \"\"\"\n",
    "\n",
    "#         self.MAX_LEN = MAX_LEN\n",
    "#         # get phoneme list\n",
    "#         self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "#         phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "#         length = len(phoneme_list)\n",
    "#         if partition == \"train\":\n",
    "#             self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "#         elif partition == \"val1\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "#         elif partition == \"val2\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "#         elif partition == \"test\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "\n",
    "#         self.length = len(self.phoneme_list)\n",
    "\n",
    "#         # get_am data\n",
    "#         am_data = pd.read_csv(am_path)\n",
    "#         self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.length\n",
    "\n",
    "#     def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "#         top_db = 80\n",
    "\n",
    "#         # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "#         spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "#         # Convert to decibels\n",
    "#         spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "#         return spec\n",
    "\n",
    "#     def padding(self, phoneme):\n",
    "#         if len(phoneme) < self.MAX_LEN:\n",
    "#             pad_begin_len = random.randint(0, self.MAX_LEN - len(phoneme))\n",
    "#             pad_end_len = self.MAX_LEN - len(phoneme) - pad_begin_len\n",
    "\n",
    "#             # Pad with 0s\n",
    "#             pad_begin = np.zeros(pad_begin_len)\n",
    "#             pad_end = np.zeros(pad_end_len)\n",
    "\n",
    "#             phoneme = np.concatenate((pad_begin, phoneme, pad_end), 0)\n",
    "#         else:\n",
    "#             phoneme = phoneme[:self.MAX_LEN]\n",
    "#         return phoneme\n",
    "\n",
    "#     def __getitem__(self, ind):\n",
    "#         item_filename = self.phoneme_list[ind]\n",
    "#         item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "#         phoneme = np.load(item_full_path)\n",
    "\n",
    "#         person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "#         try:\n",
    "#             target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "#         except:\n",
    "#             print(\"person id =\", person_id)\n",
    "#             target_am = 0.\n",
    "\n",
    "#         # padding\n",
    "#         phoneme = self.padding(phoneme)\n",
    "#         phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "#         # apply mel transform\n",
    "#         phoneme = self.spectro_gram(phoneme)\n",
    "        \n",
    "#         ################################### Normalization ######################################\n",
    "#         std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "#         phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "#         # print(phoneme)\n",
    "#         # ####################### convert phoneme from float32 to float64 ##################\n",
    "#         # phoneme = phoneme.to(torch.float64)\n",
    "#         # ##################################################################################\n",
    "\n",
    "#         target_am = torch.tensor(target_am)\n",
    "        \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         target_am = target_am.to(torch.float32)\n",
    "#         # print(target_am)\n",
    "#         ####################################################################################\n",
    "        \n",
    "#         # jia yi ge gui yi hua (phoneme)\n",
    "        \n",
    "#         return phoneme, target_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad957703-795b-42ee-b460-4e2bb8c7d9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  32\n",
      "Train dataset samples = 3067, batches = 96\n",
      "Validation dataset samples = 1315, batches = 42\n",
      "Test dataset samples = 1315, batches = 42\n"
     ]
    }
   ],
   "source": [
    "# default_root_path = \"./penstate_data/extract_phoneme\"\n",
    "default_root_path = \"./penstate_data/extract_phoneme_processed\"\n",
    "gender = \"female\"\n",
    "phoneme_idx = 10\n",
    "# am_path = \"./penstate_data/AMs_unnormalized.csv\"\n",
    "am_path = \"./penstate_data/AMs_final.csv\"\n",
    "\n",
    "am_idx = 13\n",
    "MAX_LEN = 32 # TODO: may be too small\n",
    "batch_size = 64\n",
    "batch_size = config['batch_size']\n",
    "train_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"train\")\n",
    "\n",
    "######################################################################################################################################\n",
    "val_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val1\")\n",
    "test_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val1\")\n",
    "######################################################################################################################################\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, num_workers=0,\n",
    "                                               batch_size=batch_size, shuffle=True)\n",
    "\n",
    "######################################################################################################################################\n",
    "val_loader = torch.utils.data.DataLoader(val_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "######################################################################################################################################\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c74d99-578e-4710-b5c7-cd3783489de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  32\n",
      "Train dataset samples = 3067, batches = 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     phoneme, target_am = data\n",
    "#     print(phoneme.shape, target_am.shape)\n",
    "#     ##########################################\n",
    "#     # print(phoneme.dtype, target_am.dtype)\n",
    "#     ##########################################\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db9324-d5e9-4cc3-880d-fe3ed5d1b216",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96634bc-059e-4f49-9408-55d2113a5ab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 1: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df81998-fd34-4696-8c19-f6627e698954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CNNNetwork(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv2=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv3=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv4=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.flatten=nn.Flatten()\n",
    "#         self.linear1=nn.Linear(in_features=128*15,out_features=512)\n",
    "#         self.linear2=nn.Linear(in_features=512,out_features=128)\n",
    "#         self.linear3=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.linear4=nn.Linear(in_features=1024,out_features=256)\n",
    "#         # self.linear5=nn.Linear(in_features=256,out_features=128)\n",
    "#         # self.linear6=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.output=nn.Sigmoid()\n",
    "#         self.pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.output = nn.Tanh()\n",
    "    \n",
    "#     def forward(self,input_data):\n",
    "#         # add one dimension\n",
    "#         # input_data.unsqueeze_(1)\n",
    "#         x=self.conv1(input_data)\n",
    "#         x=self.conv2(x)\n",
    "#         x=self.conv3(x)\n",
    "#         x=self.conv4(x)\n",
    "        \n",
    "#         # x = self.pooling(x)\n",
    "#         # print(\"After conv: \", x.shape)\n",
    "#         x=self.flatten(x)\n",
    "#         # print(\"After flatten: \", x.shape)\n",
    "#         x=self.linear1(x)\n",
    "#         # print(\"After linear: \",x.shape)\n",
    "#         x=self.linear2(x)\n",
    "#         # x=self.linear3(x)\n",
    "#         # x=self.linear4(x)\n",
    "#         # x=self.linear5(x)\n",
    "        \n",
    "#         logits=self.linear3(x)\n",
    "#         output=self.output(logits)\n",
    "#         # print(output)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0b7afb-22cd-4583-807d-244775c7eb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CNNNetwork().to(device)\n",
    "# phoneme, AM = next(iter(train_loader))\n",
    "# # # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19e34e-3125-4cd1-a2f7-4195992d4f17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 2: Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b42429-9bf8-470b-a3b9-a93816ada774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = models.resnet50(weights=None).to(device) # may be too weak\n",
    "model = models.resnet152(weights=None).to(device) # may be too weak\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1).to(device)\n",
    "# print(model.conv1)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfee9771-9960-401c-8df9-ad59504ed9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ac52c-a94e-43c3-9e34-fbdf081cd72b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 3: DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed864040-22da-4a81-8bf4-e07b71b9a248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(weights=None).to(device) # may be too weak\n",
    "\n",
    "# num_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_features, 1).to(device)\n",
    "# print(model)\n",
    "model.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.classifier = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2cba2a-8cc3-43d2-8967-6370f23c521b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e5257-749f-40fa-8b36-8e6406092b4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 4: EfficientNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f60c9-0f72-455c-955d-f94da87aec25",
   "metadata": {},
   "source": [
    "MAE: 0.69??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6288a0c7-f633-4bcd-a27b-646c233a5d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.efficientnet_v2_s(weights=None).to(device) # may be too weak\n",
    "# print(model)\n",
    "model.features[0][0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a956bc-3bc5-48e2-b6df-67a070ad0449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 1280, 2, 1]          --\n",
      "|    └─Conv2dNormActivation: 2-1              [-1, 24, 32, 16]          --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 24, 32, 16]          216\n",
      "|    |    └─BatchNorm2d: 3-2                  [-1, 24, 32, 16]          48\n",
      "|    |    └─SiLU: 3-3                         [-1, 24, 32, 16]          --\n",
      "|    └─Sequential: 2-2                        [-1, 24, 32, 16]          --\n",
      "|    |    └─FusedMBConv: 3-4                  [-1, 24, 32, 16]          5,232\n",
      "|    |    └─FusedMBConv: 3-5                  [-1, 24, 32, 16]          5,232\n",
      "|    └─Sequential: 2-3                        [-1, 48, 16, 8]           --\n",
      "|    |    └─FusedMBConv: 3-6                  [-1, 48, 16, 8]           25,632\n",
      "|    |    └─FusedMBConv: 3-7                  [-1, 48, 16, 8]           92,640\n",
      "|    |    └─FusedMBConv: 3-8                  [-1, 48, 16, 8]           92,640\n",
      "|    |    └─FusedMBConv: 3-9                  [-1, 48, 16, 8]           92,640\n",
      "|    └─Sequential: 2-4                        [-1, 64, 8, 4]            --\n",
      "|    |    └─FusedMBConv: 3-10                 [-1, 64, 8, 4]            95,744\n",
      "|    |    └─FusedMBConv: 3-11                 [-1, 64, 8, 4]            164,480\n",
      "|    |    └─FusedMBConv: 3-12                 [-1, 64, 8, 4]            164,480\n",
      "|    |    └─FusedMBConv: 3-13                 [-1, 64, 8, 4]            164,480\n",
      "|    └─Sequential: 2-5                        [-1, 128, 4, 2]           --\n",
      "|    |    └─MBConv: 3-14                      [-1, 128, 4, 2]           61,200\n",
      "|    |    └─MBConv: 3-15                      [-1, 128, 4, 2]           171,296\n",
      "|    |    └─MBConv: 3-16                      [-1, 128, 4, 2]           171,296\n",
      "|    |    └─MBConv: 3-17                      [-1, 128, 4, 2]           171,296\n",
      "|    |    └─MBConv: 3-18                      [-1, 128, 4, 2]           171,296\n",
      "|    |    └─MBConv: 3-19                      [-1, 128, 4, 2]           171,296\n",
      "|    └─Sequential: 2-6                        [-1, 160, 4, 2]           --\n",
      "|    |    └─MBConv: 3-20                      [-1, 160, 4, 2]           281,440\n",
      "|    |    └─MBConv: 3-21                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-22                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-23                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-24                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-25                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-26                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-27                      [-1, 160, 4, 2]           397,800\n",
      "|    |    └─MBConv: 3-28                      [-1, 160, 4, 2]           397,800\n",
      "|    └─Sequential: 2-7                        [-1, 256, 2, 1]           --\n",
      "|    |    └─MBConv: 3-29                      [-1, 256, 2, 1]           490,152\n",
      "|    |    └─MBConv: 3-30                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-31                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-32                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-33                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-34                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-35                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-36                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-37                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-38                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-39                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-40                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-41                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-42                      [-1, 256, 2, 1]           1,005,120\n",
      "|    |    └─MBConv: 3-43                      [-1, 256, 2, 1]           1,005,120\n",
      "|    └─Conv2dNormActivation: 2-8              [-1, 1280, 2, 1]          --\n",
      "|    |    └─Conv2d: 3-44                      [-1, 1280, 2, 1]          327,680\n",
      "|    |    └─BatchNorm2d: 3-45                 [-1, 1280, 2, 1]          2,560\n",
      "|    |    └─SiLU: 3-46                        [-1, 1280, 2, 1]          --\n",
      "├─AdaptiveAvgPool2d: 1-2                      [-1, 1280, 1, 1]          --\n",
      "├─Linear: 1-3                                 [-1, 1]                   1,281\n",
      "===============================================================================================\n",
      "Total params: 20,178,337\n",
      "Trainable params: 20,178,337\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 80.37\n",
      "===============================================================================================\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 76.97\n",
      "Estimated Total Size (MB): 77.45\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Sequential: 1-1                             [-1, 1280, 2, 1]          --\n",
       "|    └─Conv2dNormActivation: 2-1              [-1, 24, 32, 16]          --\n",
       "|    |    └─Conv2d: 3-1                       [-1, 24, 32, 16]          216\n",
       "|    |    └─BatchNorm2d: 3-2                  [-1, 24, 32, 16]          48\n",
       "|    |    └─SiLU: 3-3                         [-1, 24, 32, 16]          --\n",
       "|    └─Sequential: 2-2                        [-1, 24, 32, 16]          --\n",
       "|    |    └─FusedMBConv: 3-4                  [-1, 24, 32, 16]          5,232\n",
       "|    |    └─FusedMBConv: 3-5                  [-1, 24, 32, 16]          5,232\n",
       "|    └─Sequential: 2-3                        [-1, 48, 16, 8]           --\n",
       "|    |    └─FusedMBConv: 3-6                  [-1, 48, 16, 8]           25,632\n",
       "|    |    └─FusedMBConv: 3-7                  [-1, 48, 16, 8]           92,640\n",
       "|    |    └─FusedMBConv: 3-8                  [-1, 48, 16, 8]           92,640\n",
       "|    |    └─FusedMBConv: 3-9                  [-1, 48, 16, 8]           92,640\n",
       "|    └─Sequential: 2-4                        [-1, 64, 8, 4]            --\n",
       "|    |    └─FusedMBConv: 3-10                 [-1, 64, 8, 4]            95,744\n",
       "|    |    └─FusedMBConv: 3-11                 [-1, 64, 8, 4]            164,480\n",
       "|    |    └─FusedMBConv: 3-12                 [-1, 64, 8, 4]            164,480\n",
       "|    |    └─FusedMBConv: 3-13                 [-1, 64, 8, 4]            164,480\n",
       "|    └─Sequential: 2-5                        [-1, 128, 4, 2]           --\n",
       "|    |    └─MBConv: 3-14                      [-1, 128, 4, 2]           61,200\n",
       "|    |    └─MBConv: 3-15                      [-1, 128, 4, 2]           171,296\n",
       "|    |    └─MBConv: 3-16                      [-1, 128, 4, 2]           171,296\n",
       "|    |    └─MBConv: 3-17                      [-1, 128, 4, 2]           171,296\n",
       "|    |    └─MBConv: 3-18                      [-1, 128, 4, 2]           171,296\n",
       "|    |    └─MBConv: 3-19                      [-1, 128, 4, 2]           171,296\n",
       "|    └─Sequential: 2-6                        [-1, 160, 4, 2]           --\n",
       "|    |    └─MBConv: 3-20                      [-1, 160, 4, 2]           281,440\n",
       "|    |    └─MBConv: 3-21                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-22                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-23                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-24                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-25                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-26                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-27                      [-1, 160, 4, 2]           397,800\n",
       "|    |    └─MBConv: 3-28                      [-1, 160, 4, 2]           397,800\n",
       "|    └─Sequential: 2-7                        [-1, 256, 2, 1]           --\n",
       "|    |    └─MBConv: 3-29                      [-1, 256, 2, 1]           490,152\n",
       "|    |    └─MBConv: 3-30                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-31                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-32                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-33                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-34                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-35                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-36                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-37                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-38                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-39                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-40                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-41                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-42                      [-1, 256, 2, 1]           1,005,120\n",
       "|    |    └─MBConv: 3-43                      [-1, 256, 2, 1]           1,005,120\n",
       "|    └─Conv2dNormActivation: 2-8              [-1, 1280, 2, 1]          --\n",
       "|    |    └─Conv2d: 3-44                      [-1, 1280, 2, 1]          327,680\n",
       "|    |    └─BatchNorm2d: 3-45                 [-1, 1280, 2, 1]          2,560\n",
       "|    |    └─SiLU: 3-46                        [-1, 1280, 2, 1]          --\n",
       "├─AdaptiveAvgPool2d: 1-2                      [-1, 1280, 1, 1]          --\n",
       "├─Linear: 1-3                                 [-1, 1]                   1,281\n",
       "===============================================================================================\n",
       "Total params: 20,178,337\n",
       "Trainable params: 20,178,337\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 80.37\n",
       "===============================================================================================\n",
       "Input size (MB): 0.25\n",
       "Forward/backward pass size (MB): 0.23\n",
       "Params size (MB): 76.97\n",
       "Estimated Total Size (MB): 77.45\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02b8c9-e823-4bb1-a18a-e0c849b2c0ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 5: MobileNetV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036a045-9499-45df-bed5-cc32db91e01d",
   "metadata": {},
   "source": [
    "##### MAE: 0.68??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5e785a-43ab-41bb-95d4-b4199ca5c90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_large(weights=None).to(device)\n",
    "# print(model)\n",
    "model.features[0][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[3] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa46405-6104-4f9b-8e6b-f08cf21851a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e109ccd-421c-431b-98a3-a6199c7edb6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 6: ShuffleNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964e02f9-7598-4f40-b585-8670650ba3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.shufflenet_v2_x1_0(weights=None).to(device)\n",
    "# print(model)\n",
    "model.conv1[0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.fc = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bff1dde-75af-42fe-b99b-863748e92181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80f6ef-360c-4710-a9b6-49c7a9b7f21e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 7: SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0931ea-f3b9-4bd8-bd56-7afd46990e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.squeezenet1_1(weights=None).to(device)\n",
    "# print(model)\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "model.classifier[1] = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e56682a-beab-47e5-b1ce-6adacc34e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ec3e0-2820-47fc-85d0-2542b1b372e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 8: MnasNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd549074-a6a7-450d-a7be-97dd639f07b9",
   "metadata": {},
   "source": [
    "##### MAE=0.68 ok???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdff1e5c-80fc-4826-af6f-695f4b056073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mnasnet1_0(weights=None).to(device)\n",
    "# print(model)\n",
    "model.layers[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fd8e0ff-fc4d-4a69-a75b-8a1a2be686ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4455c-36c8-4867-930d-8cf1957d7557",
   "metadata": {},
   "source": [
    "## Model 9: Wide ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46827b9f-e1cd-431f-9863-c8c815921792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mnasnet1_0(weights=None).to(device)\n",
    "# print(model)\n",
    "model.layers[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58bcf8c1-e9a7-4619-b299-258cd29d394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a5bd7-2d59-4282-8ebc-2683628cdce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aff3c7e-600a-4f48-a73e-3477e6d08404",
   "metadata": {},
   "source": [
    "# Train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6978e0-43a9-4a1b-9f05-7fca1d25be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "563a8ca6-0732-4409-a74c-1e2ef43191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() #Defining Loss function \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate']) #Defining Optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.0001, last_epoch=-1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,40,45,50,60,65,70,90,110,150,170,180], gamma=0.5) # add learning rate scheduler\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * config['epochs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75674d65-bd4f-412b-8aa0-2d951cae0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 #Monitoring Loss\n",
    "    \n",
    "    #########################################################\n",
    "    # AM_true_list = []\n",
    "    # AM_pred_list = []\n",
    "    #########################################################\n",
    "    \n",
    "    for iter, (phoneme, AM) in enumerate(dataloader):\n",
    "        scheduler.step()\n",
    "        ### Move Data to Device (Ideally GPU)\n",
    "        phoneme = phoneme.to(device)\n",
    "        AM = AM.to(device)\n",
    "\n",
    "        ### Forward Propagation\n",
    "        preds_AM = model(phoneme)\n",
    "\n",
    "        ### Loss Calculation\n",
    "        # print(AM.shape)\n",
    "        preds_AM = torch.squeeze(preds_AM)\n",
    "        # print(preds_AM)\n",
    "        # print(preds_AM.shape)model = models.shufflenet_v2_x1_0(weights=None).to(device)\n",
    "        loss = criterion(preds_AM, AM)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        #########################################################\n",
    "        ### Store Pred and True Labels\n",
    "        # AM_pred_list.extend(preds_AM.cpu().tolist())\n",
    "        # AM_true_list.extend(AM.cpu().tolist())\n",
    "        #########################################################\n",
    "\n",
    "        ### Initialize Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Backward Propagation\n",
    "        loss.backward()\n",
    "\n",
    "        ### Gradient Descent\n",
    "        optimizer.step()\n",
    "        # if iter % 20 == 0:\n",
    "        #     print(\"iter =\", iter, \"loss =\",loss.item())\n",
    "    train_loss /= len(dataloader)\n",
    "    print(\"Learning rate = \", scheduler.get_last_lr()[0])\n",
    "    print(\"Train loss = \", train_loss)\n",
    "    \n",
    "    #########################################################\n",
    "    # print(AM_pred_list)\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    # accuracy = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    # print(\"Train MSE accuracy: \", accuracy)\n",
    "    #########################################################\n",
    "    \n",
    "    # scheduler.step() # add schedule learning rate\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1518e3-0b07-4b4d-a192-54e5bc0a7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "\n",
    "    model.eval() # set model in evaluation mode\n",
    "\n",
    "    AM_true_list = []\n",
    "    AM_pred_list = []\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        phoneme, AM = data\n",
    "        ### Move data to device (ideally GPU)\n",
    "        phoneme, AM = phoneme.to(device), AM.to(device) \n",
    "\n",
    "        with torch.inference_mode(): # makes sure that there are no gradients computed as we are not training the model now\n",
    "            ### Forward Propagation\n",
    "            ### Get Predictions\n",
    "            predicted_AM = model(phoneme)\n",
    "            # print(predicted_AM)\n",
    "        \n",
    "        ### Store Pred and True Labels\n",
    "        AM_pred_list.extend(predicted_AM.cpu().tolist())\n",
    "        AM_true_list.extend(AM.cpu().tolist())\n",
    "        \n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "    \n",
    "        del phoneme, AM, predicted_AM\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ###############################################################################################\n",
    "    # print(AM_pred_list[1000:3100])\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    ###############################################################################################\n",
    "    \n",
    "    # print(\"Number of equals between two list: \", sum(a == b for a,b in zip(AM_pred_list, AM_true_list)))\n",
    "    \n",
    "    ### Calculate Accuracy\n",
    "    MSE = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    r2_score_acc = r2_score(AM_pred_list, AM_true_list)\n",
    "    MAE = mean_absolute_error(AM_pred_list, AM_true_list)\n",
    "    print(\"Validation r2_score: \", r2_score_acc)\n",
    "    print(\"Validation MAE: \", MAE)\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce9f12-c7c9-4328-b4e2-b921edd4747c",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90eda49-e81d-42a2-af9b-f6f18ef88248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate =  0.0009999383162408297\n",
      "Train loss =  0.9854118501146635\n",
      "Validation r2_score:  -16552928188587.42\n",
      "Validation MAE:  0.7245533061875986\n",
      "\tTrain Loss:  0.9854118501146635\n",
      "\tValidation MSE:  0.8776947049979213\n",
      "\n",
      "Epoch 2/200\n",
      "Learning rate =  0.000999753280182864\n",
      "Train loss =  0.837199755012989\n",
      "Validation r2_score:  -12157393210489.13\n",
      "Validation MAE:  0.724489326079592\n",
      "\tTrain Loss:  0.837199755012989\n",
      "\tValidation MSE:  0.8775509992818765\n",
      "\n",
      "Epoch 3/200\n",
      "Learning rate =  0.0009994449374809815\n",
      "Train loss =  0.795664175413549\n",
      "Validation r2_score:  -5230404930609.74\n",
      "Validation MAE:  0.7189018611318145\n",
      "\tTrain Loss:  0.795664175413549\n",
      "\tValidation MSE:  0.8653446138540797\n",
      "\n",
      "Epoch 4/200\n",
      "Learning rate =  0.0009990133642141313\n",
      "Train loss =  0.7072865863641103\n",
      "Validation r2_score:  -8497947508424.187\n",
      "Validation MAE:  0.7221355557172584\n",
      "\tTrain Loss:  0.7072865863641103\n",
      "\tValidation MSE:  0.8723710063550637\n",
      "\n",
      "Epoch 5/200\n",
      "Learning rate =  0.0009984586668665594\n",
      "Train loss =  0.625629223883152\n",
      "Validation r2_score:  -18461096100425.03\n",
      "Validation MAE:  0.7223336200799949\n",
      "\tTrain Loss:  0.625629223883152\n",
      "\tValidation MSE:  0.8727988497188042\n",
      "\n",
      "Epoch 6/200\n",
      "Learning rate =  0.0009977809823015354\n",
      "Train loss =  0.509821394768854\n",
      "Validation r2_score:  -11869008040660.004\n",
      "Validation MAE:  0.7198544238527578\n",
      "\tTrain Loss:  0.509821394768854\n",
      "\tValidation MSE:  0.8673907442076128\n",
      "\n",
      "Epoch 7/200\n",
      "Learning rate =  0.0009969804777275862\n",
      "Train loss =  0.4101247612076501\n",
      "Validation r2_score:  -10963333605738.871\n",
      "Validation MAE:  0.7169702284222207\n",
      "\tTrain Loss:  0.4101247612076501\n",
      "\tValidation MSE:  0.8612639061751405\n",
      "\n",
      "Epoch 8/200\n",
      "Learning rate =  0.0009960573506572364\n",
      "Train loss =  0.36034099912891787\n",
      "Validation r2_score:  -19456514991578.06\n",
      "Validation MAE:  0.7146427624168391\n",
      "\tTrain Loss:  0.36034099912891787\n",
      "\tValidation MSE:  0.8565147386143037\n",
      "\n",
      "Epoch 9/200\n",
      "Learning rate =  0.000995011828858275\n",
      "Train loss =  0.3210560642182827\n",
      "Validation r2_score:  -8283498907121.712\n",
      "Validation MAE:  0.7180839785052456\n",
      "\tTrain Loss:  0.3210560642182827\n",
      "\tValidation MSE:  0.8636178115006379\n",
      "\n",
      "Epoch 10/200\n",
      "Learning rate =  0.0009938441702975638\n",
      "Train loss =  0.2758135327603668\n",
      "Validation r2_score:  -12077932448239.303\n",
      "Validation MAE:  0.7150550272542374\n",
      "\tTrain Loss:  0.2758135327603668\n",
      "\tValidation MSE:  0.8573389069644155\n",
      "\n",
      "Epoch 11/200\n",
      "Learning rate =  0.0009925546630773804\n",
      "Train loss =  0.2548600096876423\n",
      "Validation r2_score:  -29364899872083.723\n",
      "Validation MAE:  0.7214395425810051\n",
      "\tTrain Loss:  0.2548600096876423\n",
      "\tValidation MSE:  0.8708788287541539\n",
      "\n",
      "Epoch 12/200\n",
      "Learning rate =  0.0009911436253643377\n",
      "Train loss =  0.246314678962032\n",
      "Validation r2_score:  -18900900549997.363\n",
      "Validation MAE:  0.716194182496957\n",
      "\tTrain Loss:  0.246314678962032\n",
      "\tValidation MSE:  0.8596544024350617\n",
      "\n",
      "Epoch 13/200\n",
      "Learning rate =  0.000989611405310877\n",
      "Train loss =  0.19233702844940126\n",
      "Validation r2_score:  -2002347328249.923\n",
      "Validation MAE:  0.7137520042393257\n",
      "\tTrain Loss:  0.19233702844940126\n",
      "\tValidation MSE:  0.8547590658790821\n",
      "\n",
      "Epoch 14/200\n",
      "Learning rate =  0.0009879583809693686\n",
      "Train loss =  0.18239831179380417\n",
      "Validation r2_score:  -17187649680568.842\n",
      "Validation MAE:  0.721361266852785\n",
      "\tTrain Loss:  0.18239831179380417\n",
      "\tValidation MSE:  0.8707041478479358\n",
      "\n",
      "Epoch 15/200\n",
      "Learning rate =  0.000986184960198832\n",
      "Train loss =  0.17334249235379198\n",
      "Validation r2_score:  -8721860428331.8125\n",
      "Validation MAE:  0.715447902567543\n",
      "\tTrain Loss:  0.17334249235379198\n",
      "\tValidation MSE:  0.8581311642578485\n",
      "\n",
      "Epoch 16/200\n",
      "Learning rate =  0.000984291580564311\n",
      "Train loss =  0.1509145157178864\n",
      "Validation r2_score:  -28169823121067.742\n",
      "Validation MAE:  0.7208262040361252\n",
      "\tTrain Loss:  0.1509145157178864\n",
      "\tValidation MSE:  0.869516826108466\n",
      "\n",
      "Epoch 17/200\n",
      "Learning rate =  0.000982278709228894\n",
      "Train loss =  0.13522997502392778\n",
      "Validation r2_score:  -6710137285925.113\n",
      "Validation MAE:  0.7072171823309288\n",
      "\tTrain Loss:  0.13522997502392778\n",
      "\tValidation MSE:  0.8425598955999091\n",
      "\n",
      "Epoch 18/200\n",
      "Learning rate =  0.0009801468428384664\n",
      "Train loss =  0.12301380435625713\n",
      "Validation r2_score:  -6643724343769.159\n",
      "Validation MAE:  0.7131949363028481\n",
      "\tTrain Loss:  0.12301380435625713\n",
      "\tValidation MSE:  0.8536784948648035\n",
      "\n",
      "Epoch 19/200\n",
      "Learning rate =  0.0009778965073991592\n",
      "Train loss =  0.1424594467583423\n",
      "Validation r2_score:  -2920495076065.247\n",
      "Validation MAE:  0.6964239680424276\n",
      "\tTrain Loss:  0.1424594467583423\n",
      "\tValidation MSE:  0.8237190062304409\n",
      "\n",
      "Epoch 20/200\n",
      "Learning rate =  0.0009755282581475712\n",
      "Train loss =  0.14354062588730207\n",
      "Validation r2_score:  -985613218653.4894\n",
      "Validation MAE:  0.6926770692811606\n",
      "\tTrain Loss:  0.14354062588730207\n",
      "\tValidation MSE:  0.816876438622226\n",
      "\n",
      "Epoch 21/200\n",
      "Learning rate =  0.0009730426794137671\n",
      "Train loss =  0.14653565160309276\n",
      "Validation r2_score:  -857963079161.5012\n",
      "Validation MAE:  0.6898086463926296\n",
      "\tTrain Loss:  0.14653565160309276\n",
      "\tValidation MSE:  0.8115267268122406\n",
      "\n",
      "Epoch 22/200\n",
      "Learning rate =  0.0009704403844771071\n",
      "Train loss =  0.16427386028226465\n",
      "Validation r2_score:  -860500846214.6191\n",
      "Validation MAE:  0.6903068717370808\n",
      "\tTrain Loss:  0.16427386028226465\n",
      "\tValidation MSE:  0.8124885338873405\n",
      "\n",
      "Epoch 23/200\n",
      "Learning rate =  0.0009677220154149269\n",
      "Train loss =  0.16075670265126973\n",
      "Validation r2_score:  -172541284654.56766\n",
      "Validation MAE:  0.6891031933303908\n",
      "\tTrain Loss:  0.16075670265126973\n",
      "\tValidation MSE:  0.8107047152940964\n",
      "\n",
      "Epoch 24/200\n",
      "Learning rate =  0.0009648882429441182\n",
      "Train loss =  0.20184768402638534\n",
      "Validation r2_score:  -5988870043271.478\n",
      "Validation MAE:  0.6989120157995038\n",
      "\tTrain Loss:  0.20184768402638534\n",
      "\tValidation MSE:  0.8280660158647071\n",
      "\n",
      "Epoch 25/200\n",
      "Learning rate =  0.000961939766255636\n",
      "Train loss =  0.2311091140533487\n",
      "Validation r2_score:  -490407264164.8851\n",
      "Validation MAE:  0.6888301709461462\n",
      "\tTrain Loss:  0.2311091140533487\n",
      "\tValidation MSE:  0.8107510247424963\n",
      "\n",
      "Epoch 26/200\n",
      "Learning rate =  0.0009588773128419836\n",
      "Train loss =  0.28361949052972096\n",
      "Validation r2_score:  -638968340201.0029\n",
      "Validation MAE:  0.6898590011444269\n",
      "\tTrain Loss:  0.28361949052972096\n",
      "\tValidation MSE:  0.8138221438554849\n",
      "\n",
      "Epoch 27/200\n",
      "Learning rate =  0.0009557016383177155\n",
      "Train loss =  0.3027938789067169\n",
      "Validation r2_score:  -446839929068.738\n",
      "Validation MAE:  0.6981107716707109\n",
      "\tTrain Loss:  0.3027938789067169\n",
      "\tValidation MSE:  0.8268696988659923\n",
      "\n",
      "Epoch 28/200\n",
      "Learning rate =  0.0009524135262330024\n",
      "Train loss =  0.30326992242286605\n",
      "Validation r2_score:  -1364700651913.2488\n",
      "Validation MAE:  0.6905380810777384\n",
      "\tTrain Loss:  0.30326992242286605\n",
      "\tValidation MSE:  0.8152627383644435\n",
      "\n",
      "Epoch 29/200\n",
      "Learning rate =  0.0009490137878803\n",
      "Train loss =  0.2583513418212533\n",
      "Validation r2_score:  -200593927110.2129\n",
      "Validation MAE:  0.6892656764759197\n",
      "\tTrain Loss:  0.2583513418212533\n",
      "\tValidation MSE:  0.812433482411533\n",
      "\n",
      "Epoch 30/200\n",
      "Learning rate =  0.0009455032620941764\n",
      "Train loss =  0.21641038024487594\n",
      "Validation r2_score:  -2920904244958.431\n",
      "Validation MAE:  0.6897573851176427\n",
      "\tTrain Loss:  0.21641038024487594\n",
      "\tValidation MSE:  0.8114402699368806\n",
      "\n",
      "Epoch 31/200\n",
      "Learning rate =  0.0009418828150443393\n",
      "Train loss =  0.16818384341119477\n",
      "Validation r2_score:  -1442233914202.4272\n",
      "Validation MAE:  0.6939283393790854\n",
      "\tTrain Loss:  0.16818384341119477\n",
      "\tValidation MSE:  0.8208302747155529\n",
      "\n",
      "Epoch 32/200\n",
      "Learning rate =  0.0009381533400219241\n",
      "Train loss =  0.14040259225293994\n",
      "Validation r2_score:  -830083628870.4391\n",
      "Validation MAE:  0.6888640787367472\n",
      "\tTrain Loss:  0.14040259225293994\n",
      "\tValidation MSE:  0.8106719046653994\n",
      "\n",
      "Epoch 33/200\n",
      "Learning rate =  0.0009343157572190871\n",
      "Train loss =  0.13181808101944625\n",
      "Validation r2_score:  -496532763332.1008\n",
      "Validation MAE:  0.6889526638397132\n",
      "\tTrain Loss:  0.13181808101944625\n",
      "\tValidation MSE:  0.8106509379964606\n",
      "\n",
      "Epoch 34/200\n",
      "Learning rate =  0.0009303710135019633\n",
      "Train loss =  0.11254307193060716\n",
      "Validation r2_score:  -5049505349344.529\n",
      "Validation MAE:  0.6898863668040064\n",
      "\tTrain Loss:  0.11254307193060716\n",
      "\tValidation MSE:  0.8116662691244165\n",
      "\n",
      "Epoch 35/200\n",
      "Learning rate =  0.0009263200821770378\n",
      "Train loss =  0.1041730142896995\n",
      "Validation r2_score:  -1069424876721.0868\n",
      "Validation MAE:  0.6942690810932293\n",
      "\tTrain Loss:  0.1041730142896995\n",
      "\tValidation MSE:  0.8213569967385663\n",
      "\n",
      "Epoch 36/200\n",
      "Learning rate =  0.0009221639627509992\n",
      "Train loss =  0.09059529196626197\n",
      "Validation r2_score:  -2203170192842.0073\n",
      "Validation MAE:  0.6914911388260216\n",
      "\tTrain Loss:  0.09059529196626197\n",
      "\tValidation MSE:  0.8147532882586733\n",
      "\n",
      "Epoch 37/200\n",
      "Learning rate =  0.0009179036806841272\n",
      "Train loss =  0.08532612995865445\n",
      "Validation r2_score:  -1085653294409.205\n",
      "Validation MAE:  0.6888256286869371\n",
      "\tTrain Loss:  0.08532612995865445\n",
      "\tValidation MSE:  0.8109065202432274\n",
      "\n",
      "Epoch 38/200\n",
      "Learning rate =  0.0009135402871372728\n",
      "Train loss =  0.07719905928631003\n",
      "Validation r2_score:  -390572565257.3388\n",
      "Validation MAE:  0.6900355354390557\n",
      "\tTrain Loss:  0.07719905928631003\n",
      "\tValidation MSE:  0.8119630125085634\n",
      "\n",
      "Epoch 39/200\n",
      "Learning rate =  0.0009090748587125029\n",
      "Train loss =  0.07682892695690195\n",
      "Validation r2_score:  -2929377448477.046\n",
      "Validation MAE:  0.6929671560785956\n",
      "\tTrain Loss:  0.07682892695690195\n",
      "\tValidation MSE:  0.8192382179337367\n",
      "\n",
      "Epoch 40/200\n",
      "Learning rate =  0.0009045084971874649\n",
      "Train loss =  0.08144577646938463\n",
      "Validation r2_score:  -261369214295.85825\n",
      "Validation MAE:  0.7064157088828971\n",
      "\tTrain Loss:  0.08144577646938463\n",
      "\tValidation MSE:  0.8378395565570177\n",
      "\n",
      "Epoch 41/200\n",
      "Learning rate =  0.0008998423292435361\n",
      "Train loss =  0.07995512949613233\n",
      "Validation r2_score:  -475131922459.3245\n",
      "Validation MAE:  0.7002151837069612\n",
      "\tTrain Loss:  0.07995512949613233\n",
      "\tValidation MSE:  0.8297444422405554\n",
      "\n",
      "Epoch 42/200\n",
      "Learning rate =  0.0008950775061878354\n",
      "Train loss =  0.08902951966350277\n",
      "Validation r2_score:  -613704145390.6074\n",
      "Validation MAE:  0.6910270975725619\n",
      "\tTrain Loss:  0.08902951966350277\n",
      "\tValidation MSE:  0.8162383470941627\n",
      "\n",
      "Epoch 43/200\n",
      "Learning rate =  0.0008902152036691555\n",
      "Train loss =  0.1105841832080235\n",
      "Validation r2_score:  -1043497480967.4976\n",
      "Validation MAE:  0.6898542809324912\n",
      "\tTrain Loss:  0.1105841832080235\n",
      "\tValidation MSE:  0.813813073010283\n",
      "\n",
      "Epoch 44/200\n",
      "Learning rate =  0.0008852566213878846\n",
      "Train loss =  0.25422906146074337\n",
      "Validation r2_score:  -467536209088.1032\n",
      "Validation MAE:  0.6942989753608808\n",
      "\tTrain Loss:  0.25422906146074337\n",
      "\tValidation MSE:  0.8214014398317567\n",
      "\n",
      "Epoch 45/200\n",
      "Learning rate =  0.0008802029828000059\n",
      "Train loss =  0.4300744696520269\n",
      "Validation r2_score:  -4016192985687.6577\n",
      "Validation MAE:  0.6900303278061714\n",
      "\tTrain Loss:  0.4300744696520269\n",
      "\tValidation MSE:  0.8141602069164507\n",
      "\n",
      "Epoch 46/200\n",
      "Learning rate =  0.0008750555348152202\n",
      "Train loss =  0.3259896202944219\n",
      "Validation r2_score:  -1103964401037.4207\n",
      "Validation MAE:  0.6917635589200621\n",
      "\tTrain Loss:  0.3259896202944219\n",
      "\tValidation MSE:  0.8173799120817357\n",
      "\n",
      "Epoch 47/200\n",
      "Learning rate =  0.0008698155474892953\n",
      "Train loss =  0.23044258542358875\n",
      "Validation r2_score:  -669884281949.706\n",
      "Validation MAE:  0.6888972848016386\n",
      "\tTrain Loss:  0.23044258542358875\n",
      "\tValidation MSE:  0.8113955658566354\n",
      "\n",
      "Epoch 48/200\n",
      "Learning rate =  0.0008644843137106973\n",
      "Train loss =  0.19989405665546656\n",
      "Validation r2_score:  -588812384896.291\n",
      "Validation MAE:  0.6906810727338714\n",
      "\tTrain Loss:  0.19989405665546656\n",
      "\tValidation MSE:  0.8132765596660279\n",
      "\n",
      "Epoch 49/200\n",
      "Learning rate =  0.0008590631488815858\n",
      "Train loss =  0.14258899927760163\n",
      "Validation r2_score:  -285356655374.6258\n",
      "Validation MAE:  0.6899132271839072\n",
      "\tTrain Loss:  0.14258899927760163\n",
      "\tValidation MSE:  0.8139272713127662\n",
      "\n",
      "Epoch 50/200\n",
      "Learning rate =  0.0008535533905932653\n",
      "Train loss =  0.09575822891201824\n",
      "Validation r2_score:  -237631244522.24713\n",
      "Validation MAE:  0.6888540492467441\n",
      "\tTrain Loss:  0.09575822891201824\n",
      "\tValidation MSE:  0.8111760173253952\n",
      "\n",
      "Epoch 51/200\n",
      "Learning rate =  0.0008479563982961491\n",
      "Train loss =  0.09554087553018083\n",
      "Validation r2_score:  -305377155070.6665\n",
      "Validation MAE:  0.6952048588317497\n",
      "\tTrain Loss:  0.09554087553018083\n",
      "\tValidation MSE:  0.8227936519534023\n",
      "\n",
      "Epoch 52/200\n",
      "Learning rate =  0.0008422735529643364\n",
      "Train loss =  0.08249436516780406\n",
      "Validation r2_score:  -187416623286.86456\n",
      "Validation MAE:  0.7084480363988944\n",
      "\tTrain Loss:  0.08249436516780406\n",
      "\tValidation MSE:  0.8407665189220292\n",
      "\n",
      "Epoch 53/200\n",
      "Learning rate =  0.0008365062567548783\n",
      "Train loss =  0.07793746256114294\n",
      "Validation r2_score:  -296519629620.79974\n",
      "Validation MAE:  0.6934067268944398\n",
      "\tTrain Loss:  0.07793746256114294\n",
      "\tValidation MSE:  0.8199526374427314\n",
      "\n",
      "Epoch 54/200\n",
      "Learning rate =  0.000830655932661817\n",
      "Train loss =  0.07339351302168022\n",
      "Validation r2_score:  -231117204977.57684\n",
      "Validation MAE:  0.6896642883170127\n",
      "\tTrain Loss:  0.07339351302168022\n",
      "\tValidation MSE:  0.8133969423362385\n",
      "\n",
      "Epoch 55/200\n",
      "Learning rate =  0.0008247240241650833\n",
      "Train loss =  0.06723114357252295\n",
      "Validation r2_score:  -153230171456.16068\n",
      "Validation MAE:  0.7066038190567788\n",
      "\tTrain Loss:  0.06723114357252295\n",
      "\tValidation MSE:  0.8381041972621979\n",
      "\n",
      "Epoch 56/200\n",
      "Learning rate =  0.0008187119948743358\n",
      "Train loss =  0.08535713271703571\n",
      "Validation r2_score:  -372659392974.73425\n",
      "Validation MAE:  0.7059744984407276\n",
      "\tTrain Loss:  0.08535713271703571\n",
      "\tValidation MSE:  0.8372238242553419\n",
      "\n",
      "Epoch 57/200\n",
      "Learning rate =  0.0008126213281678432\n",
      "Train loss =  0.1085376258706674\n",
      "Validation r2_score:  -173011761144.0482\n",
      "Validation MAE:  0.6960139975050896\n",
      "\tTrain Loss:  0.1085376258706674\n",
      "\tValidation MSE:  0.8239918900214712\n",
      "\n",
      "Epoch 58/200\n",
      "Learning rate =  0.0008064535268264793\n",
      "Train loss =  0.13452054746448994\n",
      "Validation r2_score:  -327400679234.1066\n",
      "Validation MAE:  0.6992921763202423\n",
      "\tTrain Loss:  0.13452054746448994\n",
      "\tValidation MSE:  0.8284714556494214\n",
      "\n",
      "Epoch 59/200\n",
      "Learning rate =  0.0008002101126629326\n",
      "Train loss =  0.14308438907998303\n",
      "Validation r2_score:  -173772804531.3481\n",
      "Validation MAE:  0.7097916019889225\n",
      "\tTrain Loss:  0.14308438907998303\n",
      "\tValidation MSE:  0.8427838733655397\n",
      "\n",
      "Epoch 60/200\n",
      "Learning rate =  0.000793892626146227\n",
      "Train loss =  0.18234664279346666\n",
      "Validation r2_score:  -96144021412.22775\n",
      "Validation MAE:  0.6895715946409525\n",
      "\tTrain Loss:  0.18234664279346666\n",
      "\tValidation MSE:  0.8131771665139634\n",
      "\n",
      "Epoch 61/200\n",
      "Learning rate =  0.0007875026260216302\n",
      "Train loss =  0.24515741233093044\n",
      "Validation r2_score:  -49219064786.21084\n",
      "Validation MAE:  0.6914774311741835\n",
      "\tTrain Loss:  0.24515741233093044\n",
      "\tValidation MSE:  0.8169237170677257\n",
      "\n",
      "Epoch 62/200\n",
      "Learning rate =  0.0007810416889260567\n",
      "Train loss =  0.2200860322918743\n",
      "Validation r2_score:  -13431340596.514853\n",
      "Validation MAE:  0.7080318916815656\n",
      "\tTrain Loss:  0.2200860322918743\n",
      "\tValidation MSE:  0.8401545616274907\n",
      "\n",
      "Epoch 63/200\n",
      "Learning rate =  0.0007745114089990572\n",
      "Train loss =  0.15832876600325108\n",
      "Validation r2_score:  -5432458496.815089\n",
      "Validation MAE:  0.6888877876966965\n",
      "\tTrain Loss:  0.15832876600325108\n",
      "\tValidation MSE:  0.8113425520686051\n",
      "\n",
      "Epoch 64/200\n",
      "Learning rate =  0.0007679133974894891\n",
      "Train loss =  0.13255911464026818\n",
      "Validation r2_score:  -5993573600.790514\n",
      "Validation MAE:  0.6968902448666753\n",
      "\tTrain Loss:  0.13255911464026818\n",
      "\tValidation MSE:  0.825212070272678\n",
      "\n",
      "Epoch 65/200\n",
      "Learning rate =  0.0007612492823579649\n",
      "Train loss =  0.09408343369917323\n",
      "Validation r2_score:  -13515811556.725363\n",
      "Validation MAE:  0.690714731726073\n",
      "\tTrain Loss:  0.09408343369917323\n",
      "\tValidation MSE:  0.8156814828730351\n",
      "\n",
      "Epoch 66/200\n",
      "Learning rate =  0.0007545207078751765\n",
      "Train loss =  0.07394592188453923\n",
      "Validation r2_score:  -6871319659.306023\n",
      "Validation MAE:  0.729313030979196\n",
      "\tTrain Loss:  0.07394592188453923\n",
      "\tValidation MSE:  0.8732277341298249\n",
      "\n",
      "Epoch 67/200\n",
      "Learning rate =  0.0007477293342161944\n",
      "Train loss =  0.06624930681815992\n",
      "Validation r2_score:  -3887294422.415426\n",
      "Validation MAE:  0.695482297716202\n",
      "\tTrain Loss:  0.06624930681815992\n",
      "\tValidation MSE:  0.8232290428559854\n",
      "\n",
      "Epoch 68/200\n",
      "Learning rate =  0.000740876837050848\n",
      "Train loss =  0.054122724453918636\n",
      "Validation r2_score:  -2737432207.578417\n",
      "Validation MAE:  0.714261789482526\n",
      "\tTrain Loss:  0.054122724453918636\n",
      "\tValidation MSE:  0.849543701191667\n",
      "\n",
      "Epoch 69/200\n",
      "Learning rate =  0.000733964907130278\n",
      "Train loss =  0.0492750815465115\n",
      "Validation r2_score:  -3318372821.54984\n",
      "Validation MAE:  0.7046930119947675\n",
      "\tTrain Loss:  0.0492750815465115\n",
      "\tValidation MSE:  0.8354751332172468\n",
      "\n",
      "Epoch 70/200\n",
      "Learning rate =  0.0007269952498697647\n",
      "Train loss =  0.035987304737015315\n",
      "Validation r2_score:  -2040911304.5754316\n",
      "Validation MAE:  0.7023511763463796\n",
      "\tTrain Loss:  0.035987304737015315\n",
      "\tValidation MSE:  0.8324338726424307\n",
      "\n",
      "Epoch 71/200\n",
      "Learning rate =  0.0007199695849279487\n",
      "Train loss =  0.03306003561980712\n",
      "Validation r2_score:  -1198665348.5602932\n",
      "Validation MAE:  0.7099604667748675\n",
      "\tTrain Loss:  0.03306003561980712\n",
      "\tValidation MSE:  0.8430377563294451\n",
      "\n",
      "Epoch 72/200\n",
      "Learning rate =  0.0007128896457825281\n",
      "Train loss =  0.027203896732923265\n",
      "Validation r2_score:  -1272318672.5748458\n",
      "Validation MAE:  0.6980584506908637\n",
      "\tTrain Loss:  0.027203896732923265\n",
      "\tValidation MSE:  0.8268001398570408\n",
      "\n",
      "Epoch 73/200\n",
      "Learning rate =  0.0007057571793025458\n",
      "Train loss =  0.025218419565741595\n",
      "Validation r2_score:  -1056495895.1334046\n",
      "Validation MAE:  0.7004964808476628\n",
      "\tTrain Loss:  0.025218419565741595\n",
      "\tValidation MSE:  0.8301136164880725\n",
      "\n",
      "Epoch 74/200\n",
      "Learning rate =  0.0006985739453173818\n",
      "Train loss =  0.021749034722840104\n",
      "Validation r2_score:  -968143201.7468225\n",
      "Validation MAE:  0.7087918678546473\n",
      "\tTrain Loss:  0.021749034722840104\n",
      "\tValidation MSE:  0.8412740969437177\n",
      "\n",
      "Epoch 75/200\n",
      "Learning rate =  0.0006913417161825368\n",
      "Train loss =  0.02249370466355079\n",
      "Validation r2_score:  -816577992.3727849\n",
      "Validation MAE:  0.7000305628297787\n",
      "\tTrain Loss:  0.02249370466355079\n",
      "\tValidation MSE:  0.829499855467803\n",
      "\n",
      "Epoch 76/200\n",
      "Learning rate =  0.0006840622763423312\n",
      "Train loss =  0.022993840500324342\n",
      "Validation r2_score:  -928847226.5543641\n",
      "Validation MAE:  0.6936997503764616\n",
      "\tTrain Loss:  0.022993840500324342\n",
      "\tValidation MSE:  0.820444221831546\n",
      "\n",
      "Epoch 77/200\n",
      "Learning rate =  0.0006767374218896213\n",
      "Train loss =  0.023154090585497517\n",
      "Validation r2_score:  -545988300.4143171\n",
      "Validation MAE:  0.7014839889814531\n",
      "\tTrain Loss:  0.023154090585497517\n",
      "\tValidation MSE:  0.8313568305798301\n",
      "\n",
      "Epoch 78/200\n",
      "Learning rate =  0.000669368960122638\n",
      "Train loss =  0.01997013857665782\n",
      "Validation r2_score:  -429348578.6009372\n",
      "Validation MAE:  0.7008005042875561\n",
      "\tTrain Loss:  0.01997013857665782\n",
      "\tValidation MSE:  0.830497930378386\n",
      "\n",
      "Epoch 79/200\n",
      "Learning rate =  0.0006619587090990679\n",
      "Train loss =  0.015948766294362333\n",
      "Validation r2_score:  -536970578.2408686\n",
      "Validation MAE:  0.7060905657496176\n",
      "\tTrain Loss:  0.015948766294362333\n",
      "\tValidation MSE:  0.8373824519657128\n",
      "\n",
      "Epoch 80/200\n",
      "Learning rate =  0.0006545084971874672\n",
      "Train loss =  0.01605238494812511\n",
      "Validation r2_score:  -424927227.25748\n",
      "Validation MAE:  0.696734881167346\n",
      "\tTrain Loss:  0.01605238494812511\n",
      "\tValidation MSE:  0.824991543958002\n",
      "\n",
      "Epoch 81/200\n",
      "Learning rate =  0.0006470201626161454\n",
      "Train loss =  0.016466123406037998\n",
      "Validation r2_score:  -318539724.98523223\n",
      "Validation MAE:  0.6925508906561952\n",
      "\tTrain Loss:  0.016466123406037998\n",
      "\tValidation MSE:  0.8185862742369482\n",
      "\n",
      "Epoch 82/200\n",
      "Learning rate =  0.0006394955530196078\n",
      "Train loss =  0.016169575043022633\n",
      "Validation r2_score:  -235156345.7078403\n",
      "Validation MAE:  0.6898752591158387\n",
      "\tTrain Loss:  0.016169575043022633\n",
      "\tValidation MSE:  0.8138513529614593\n",
      "\n",
      "Epoch 83/200\n",
      "Learning rate =  0.0006319365249826796\n",
      "Train loss =  0.02723316430153015\n",
      "Validation r2_score:  -219977065.24738005\n",
      "Validation MAE:  0.6906462444027907\n",
      "\tTrain Loss:  0.02723316430153015\n",
      "\tValidation MSE:  0.8155157401519996\n",
      "\n",
      "Epoch 84/200\n",
      "Learning rate =  0.0006243449435824198\n",
      "Train loss =  0.02541628830173674\n",
      "Validation r2_score:  -198590287.25708693\n",
      "Validation MAE:  0.6980810590499141\n",
      "\tTrain Loss:  0.02541628830173674\n",
      "\tValidation MSE:  0.8268296018878516\n",
      "\n",
      "Epoch 85/200\n",
      "Learning rate =  0.0006167226819279451\n",
      "Train loss =  0.051350858566972114\n",
      "Validation r2_score:  -100977710.14472102\n",
      "Validation MAE:  0.6902026337971592\n",
      "\tTrain Loss:  0.051350858566972114\n",
      "\tValidation MSE:  0.814514462999269\n",
      "\n",
      "Epoch 86/200\n",
      "Learning rate =  0.0006090716206982638\n",
      "Train loss =  0.26859118898088735\n",
      "Validation r2_score:  -29183581.513643593\n",
      "Validation MAE:  0.690287281299442\n",
      "\tTrain Loss:  0.26859118898088735\n",
      "\tValidation MSE:  0.814690335686965\n",
      "\n",
      "Epoch 87/200\n",
      "Learning rate =  0.0006013936476782479\n",
      "Train loss =  0.369966431055218\n",
      "Validation r2_score:  -14159041.080615506\n",
      "Validation MAE:  0.6933094006796641\n",
      "\tTrain Loss:  0.369966431055218\n",
      "\tValidation MSE:  0.8180690598362755\n",
      "\n",
      "Epoch 88/200\n",
      "Learning rate =  0.0005936906572928537\n",
      "Train loss =  0.22359293155993024\n",
      "Validation r2_score:  -8017126.2195269065\n",
      "Validation MAE:  0.6909679267158867\n",
      "\tTrain Loss:  0.22359293155993024\n",
      "\tValidation MSE:  0.8138730278797469\n",
      "\n",
      "Epoch 89/200\n",
      "Learning rate =  0.0005859645501396962\n",
      "Train loss =  0.13799401310582957\n",
      "Validation r2_score:  -6847258.875422917\n",
      "Validation MAE:  0.689663707885622\n",
      "\tTrain Loss:  0.13799401310582957\n",
      "\tValidation MSE:  0.8133582943069756\n",
      "\n",
      "Epoch 90/200\n",
      "Learning rate =  0.0005782172325201064\n",
      "Train loss =  0.09675981096612911\n",
      "Validation r2_score:  -5053927.842861335\n",
      "Validation MAE:  0.7078242879332585\n",
      "\tTrain Loss:  0.09675981096612911\n",
      "\tValidation MSE:  0.8398255897253931\n",
      "\n",
      "Epoch 91/200\n",
      "Learning rate =  0.0005704506159687828\n",
      "Train loss =  0.061306235167042665\n",
      "Validation r2_score:  -3667405.118889091\n",
      "Validation MAE:  0.6917591974464999\n",
      "\tTrain Loss:  0.061306235167042665\n",
      "\tValidation MSE:  0.8173493772908943\n",
      "\n",
      "Epoch 92/200\n",
      "Learning rate =  0.000562666616782144\n",
      "Train loss =  0.040868693632849805\n",
      "Validation r2_score:  -3327017.902963058\n",
      "Validation MAE:  0.6895591192301576\n",
      "\tTrain Loss:  0.040868693632849805\n",
      "\tValidation MSE:  0.8131205660468028\n",
      "\n",
      "Epoch 93/200\n",
      "Learning rate =  0.0005548671555455142\n",
      "Train loss =  0.03187790147300499\n",
      "Validation r2_score:  -3674293.594347333\n",
      "Validation MAE:  0.6938856217726895\n",
      "\tTrain Loss:  0.03187790147300499\n",
      "\tValidation MSE:  0.8207396036773398\n",
      "\n",
      "Epoch 94/200\n",
      "Learning rate =  0.000547054156659249\n",
      "Train loss =  0.02346022834535688\n",
      "Validation r2_score:  -3683823.719454847\n",
      "Validation MAE:  0.6888679097969609\n",
      "\tTrain Loss:  0.02346022834535688\n",
      "\tValidation MSE:  0.8106773592681561\n",
      "\n",
      "Epoch 95/200\n",
      "Learning rate =  0.000539229547863914\n",
      "Train loss =  0.0190086334720642\n",
      "Validation r2_score:  -3157072.771928125\n",
      "Validation MAE:  0.6888657976848431\n",
      "\tTrain Loss:  0.0190086334720642\n",
      "\tValidation MSE:  0.8107002404898048\n",
      "\n",
      "Epoch 96/200\n",
      "Learning rate =  0.0005313952597646486\n",
      "Train loss =  0.017547522996513482\n",
      "Validation r2_score:  -3169137.897575795\n",
      "Validation MAE:  0.6889207058008973\n",
      "\tTrain Loss:  0.017547522996513482\n",
      "\tValidation MSE:  0.8114607432142473\n",
      "\n",
      "Epoch 97/200\n",
      "Learning rate =  0.0005235532253548127\n",
      "Train loss =  0.01876265855874711\n",
      "Validation r2_score:  -2524822.852722021\n",
      "Validation MAE:  0.688839089138143\n",
      "\tTrain Loss:  0.01876265855874711\n",
      "\tValidation MSE:  0.8110039793796449\n",
      "\n",
      "Epoch 98/200\n",
      "Learning rate =  0.0005157053795390548\n",
      "Train loss =  0.01688870139575253\n",
      "Validation r2_score:  -2088151.3523896274\n",
      "Validation MAE:  0.6891958571814653\n",
      "\tTrain Loss:  0.01688870139575253\n",
      "\tValidation MSE:  0.8122295710620527\n",
      "\n",
      "Epoch 99/200\n",
      "Learning rate =  0.0005078536586559011\n",
      "Train loss =  0.014934744642232545\n",
      "Validation r2_score:  -1880118.5412289242\n",
      "Validation MAE:  0.6888374458403529\n",
      "\tTrain Loss:  0.014934744642232545\n",
      "\tValidation MSE:  0.8110352489582294\n",
      "\n",
      "Epoch 100/200\n",
      "Learning rate =  0.0004999999999999911\n",
      "Train loss =  0.013955064384693591\n",
      "Validation r2_score:  -1362445.4970693889\n",
      "Validation MAE:  0.6888553397666252\n",
      "\tTrain Loss:  0.013955064384693591\n",
      "\tValidation MSE:  0.8111092914719149\n",
      "\n",
      "Epoch 101/200\n",
      "Learning rate =  0.0004921463413440812\n",
      "Train loss =  0.015434466258739121\n",
      "Validation r2_score:  -1246077.0977270915\n",
      "Validation MAE:  0.6899649841519703\n",
      "\tTrain Loss:  0.015434466258739121\n",
      "\tValidation MSE:  0.8118291736592279\n",
      "\n",
      "Epoch 102/200\n",
      "Learning rate =  0.000484294620460927\n",
      "Train loss =  0.012450234658899717\n",
      "Validation r2_score:  -1244584.2678584117\n",
      "Validation MAE:  0.6900909549992235\n",
      "\tTrain Loss:  0.012450234658899717\n",
      "\tValidation MSE:  0.8142565001653956\n",
      "\n",
      "Epoch 103/200\n",
      "Learning rate =  0.00047644677464516984\n",
      "Train loss =  0.012574310356285423\n",
      "Validation r2_score:  -959719.585758445\n",
      "Validation MAE:  0.6888390337942104\n",
      "\tTrain Loss:  0.012574310356285423\n",
      "\tValidation MSE:  0.8110261936716802\n",
      "\n",
      "Epoch 104/200\n",
      "Learning rate =  0.0004686047402353344\n",
      "Train loss =  0.012221931256741906\n",
      "Validation r2_score:  -866556.6846202983\n",
      "Validation MAE:  0.689027933672977\n",
      "\tTrain Loss:  0.012221931256741906\n",
      "\tValidation MSE:  0.8117364548413406\n",
      "\n",
      "Epoch 105/200\n",
      "Learning rate =  0.00046077045213606865\n",
      "Train loss =  0.011934362274284164\n",
      "Validation r2_score:  -673724.2165741315\n",
      "Validation MAE:  0.6888465299508304\n",
      "\tTrain Loss:  0.011934362274284164\n",
      "\tValidation MSE:  0.8107450833786967\n",
      "\n",
      "Epoch 106/200\n"
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs to train and evaluate your model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_mse = 1.0 ### Monitor best accuracy in your run\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    MSE = eval(model, val_loader)\n",
    "\n",
    "    print(\"\\tTrain Loss: \", train_loss)\n",
    "    print(\"\\tValidation MSE: \", MSE)\n",
    "\n",
    "    ### Save checkpoint if accuracy is better than your current best\n",
    "    if MSE < best_mse:\n",
    "        best_mse = MSE\n",
    "    ### Save checkpoint with information you want\n",
    "        torch.save({'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': train_loss,\n",
    "              'learning rate': scheduler.get_last_lr()[0],\n",
    "              'mse': MSE}, \n",
    "        './model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785492a-0e14-4148-8878-20ad6b73e85a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcdd9a-731e-45b8-abd8-7d7e43c8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "  ### What you call for model to perform inference?\n",
    "    model.eval()\n",
    "\n",
    "  ### List to store predicted phonemes of test data\n",
    "    test_predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "  ### Which mode do you need to avoid gradients?\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for i, data in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            phoneme, groundtruth_AM = data\n",
    "            ### Move data to device (ideally GPU)\n",
    "            phoneme, groundtruth_AM = phoneme.to(device), groundtruth_AM.to(device)         \n",
    "          \n",
    "            predicted_AM = model(phoneme)\n",
    "            predicted_AM.squeeze_()\n",
    "            # print(predicted_AM.shape)\n",
    "            # print(groundtruth_AM.shape)\n",
    "\n",
    "          ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
    "            test_predictions.extend(predicted_AM.cpu().tolist())\n",
    "            ground_truth.extend(groundtruth_AM.cpu())\n",
    "    \n",
    "    # print(len(test_predictions))\n",
    "    return test_predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a867d0-7ad4-4856-8675-980cacf391a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, ground_truth = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505f8f3-6e26-44f5-964c-610aeae42b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create CSV file with predictions\n",
    "with open(\"./phoneme%s\"%phoneme_idx +  \"_AM%s.csv\"%am_idx, \"w+\") as f:\n",
    "    f.write(\"person, label, prediction\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(\"{},{},{}\\n\".format(i, ground_truth[i], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77424a6-3f16-45d2-a290-a6e90508035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fd8331e-ad70-4eb5-a67b-9f11cb329bcc",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_project",
   "language": "python",
   "name": "torch_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
