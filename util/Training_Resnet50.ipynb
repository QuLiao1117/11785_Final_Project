{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b23894c-d552-4f3a-a65b-9f12b9d6be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d140e389-cf16-40eb-b078-6a1d0da9e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = {\n",
    "    'epochs': 200,\n",
    "    'batch_size' : 64,\n",
    "    'context' : 48,\n",
    "    'learning_rate' : 0.001,\n",
    "    'architecture' : 'very-low-cutoff'\n",
    "    # Add more as you need them - e.g dropout values, weight decay, scheduler parameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bf0a6-3b35-4b0e-97e3-3a2e992101a2",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a61495c-d324-4401-b3ac-b8100dbf5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 128, partition = \"train\"):\n",
    "        \"\"\"\n",
    "        :param data_path: the root path of phonemes\n",
    "        :param am_path: the path of am (.csv)\n",
    "        :param gender: female or male\n",
    "        :param phoneme_idx: the phoneme index\n",
    "        :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "        :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "        :param partition: train / val1 / val2 / test\n",
    "        \"\"\"\n",
    "\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        # get phoneme list\n",
    "        self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "        phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "        length = len(phoneme_list)\n",
    "        if partition == \"train\":\n",
    "            self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "        elif partition == \"val1\":\n",
    "            self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "        elif partition == \"val2\":\n",
    "            self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "        elif partition == \"test\":\n",
    "            self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "\n",
    "        self.length = len(self.phoneme_list)\n",
    "\n",
    "        # get_am data\n",
    "        am_data = pd.read_csv(am_path)\n",
    "        self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return spec\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        item_filename = self.phoneme_list[ind]\n",
    "        item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "        phoneme = np.load(item_full_path)\n",
    "\n",
    "        person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "        try:\n",
    "            target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "        except:\n",
    "            print(\"person id =\", person_id)\n",
    "            target_am = 0.\n",
    "\n",
    "        # padding\n",
    "        phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "        # apply mel transform\n",
    "        phoneme = self.spectro_gram(phoneme)\n",
    "\n",
    "        std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "        phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "\n",
    "        if len(phoneme[0]) < MAX_LEN:\n",
    "            phoneme = np.pad(phoneme, ((0, 0), (0, MAX_LEN - len(phoneme[0]))), 'symmetric')\n",
    "            phoneme = torch.from_numpy(phoneme)\n",
    "        else:\n",
    "            phoneme = phoneme[:, :MAX_LEN]\n",
    "        # phoneme = torch.from_numpy(phoneme)\n",
    "        ##################################################################\n",
    "        phoneme.unsqueeze_(0)\n",
    "        ##################################################################\n",
    "        target_am = torch.tensor(target_am).to(torch.float32)\n",
    "        \n",
    "        return phoneme, target_am\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870d26e7-ad98-479d-8fcf-f21613bfae08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "#     def __init__(self, data_path, am_path, gender = \"female\", phoneme_idx = 4, am_idx = 1, MAX_LEN = 44100 * 2, partition = \"train\"):\n",
    "#         \"\"\"\n",
    "#         :param data_path: the root path of phonemes\n",
    "#         :param am_path: the path of am (.csv)\n",
    "#         :param gender: female or male\n",
    "#         :param phoneme_idx: the phoneme index\n",
    "#         :param am_idx: the index of target AM, should be int within [1, 96]\n",
    "#         :param MAX_LEN: max length of voice seq, if less, pad, if more, slice\n",
    "#         :param partition: train / val1 / val2 / test\n",
    "#         \"\"\"\n",
    "\n",
    "#         self.MAX_LEN = MAX_LEN\n",
    "#         # get phoneme list\n",
    "#         self.target_phoneme_path = \"/\".join([data_path, gender, str(int(phoneme_idx))])\n",
    "#         phoneme_list = sorted(os.listdir(self.target_phoneme_path))\n",
    "#         length = len(phoneme_list)\n",
    "#         if partition == \"train\":\n",
    "#             self.phoneme_list = phoneme_list[:int(0.7 * length)]\n",
    "#         elif partition == \"val1\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.7 * length):int(0.8 * length)]\n",
    "#         elif partition == \"val2\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.8 * length):int(0.9 * length)]\n",
    "#         elif partition == \"test\":\n",
    "#             self.phoneme_list = phoneme_list[int(0.9 * length):]\n",
    "\n",
    "#         self.length = len(self.phoneme_list)\n",
    "\n",
    "#         # get_am data\n",
    "#         am_data = pd.read_csv(am_path)\n",
    "#         self.am_data = am_data[[\"ID\", str(am_idx)]]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.length\n",
    "\n",
    "#     def spectro_gram(self, sig, n_mels=64, n_fft=1024, hop_len=None):\n",
    "#         top_db = 80\n",
    "\n",
    "#         # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "#         spec = transforms.MelSpectrogram(44100, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "#         # Convert to decibels\n",
    "#         spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "#         return spec\n",
    "\n",
    "#     def padding(self, phoneme):\n",
    "#         if len(phoneme) < self.MAX_LEN:\n",
    "#             pad_begin_len = random.randint(0, self.MAX_LEN - len(phoneme))\n",
    "#             pad_end_len = self.MAX_LEN - len(phoneme) - pad_begin_len\n",
    "\n",
    "#             # Pad with 0s\n",
    "#             pad_begin = np.zeros(pad_begin_len)\n",
    "#             pad_end = np.zeros(pad_end_len)\n",
    "\n",
    "#             phoneme = np.concatenate((pad_begin, phoneme, pad_end), 0)\n",
    "#         else:\n",
    "#             phoneme = phoneme[:self.MAX_LEN]\n",
    "#         return phoneme\n",
    "\n",
    "#     def __getitem__(self, ind):\n",
    "#         item_filename = self.phoneme_list[ind]\n",
    "#         item_full_path = \"/\".join([self.target_phoneme_path, item_filename])\n",
    "#         phoneme = np.load(item_full_path)\n",
    "\n",
    "#         person_id = int(item_filename.split(\"_\")[0][1:7])\n",
    "#         try:\n",
    "#             target_am = self.am_data[self.am_data[\"ID\"] == person_id].values[0][-1]\n",
    "#         except:\n",
    "#             print(\"person id =\", person_id)\n",
    "#             target_am = 0.\n",
    "\n",
    "#         # padding\n",
    "#         phoneme = self.padding(phoneme)\n",
    "#         phoneme = torch.tensor(phoneme, dtype=torch.float) #.reshape(1, -1)\n",
    "#         # apply mel transform\n",
    "#         phoneme = self.spectro_gram(phoneme)\n",
    "        \n",
    "#         ################################### Normalization ######################################\n",
    "#         std, mean = torch.std_mean(phoneme, unbiased=False, dim=0)\n",
    "#         phoneme = (phoneme - mean) / (std + 1e-6)\n",
    "#         # print(phoneme)\n",
    "#         # ####################### convert phoneme from float32 to float64 ##################\n",
    "#         # phoneme = phoneme.to(torch.float64)\n",
    "#         # ##################################################################################\n",
    "\n",
    "#         target_am = torch.tensor(target_am)\n",
    "        \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         target_am = target_am.to(torch.float32)\n",
    "#         # print(target_am)\n",
    "#         ####################################################################################\n",
    "        \n",
    "#         # jia yi ge gui yi hua (phoneme)\n",
    "        \n",
    "#         return phoneme, target_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad957703-795b-42ee-b460-4e2bb8c7d9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 3067, batches = 48\n",
      "Validation dataset samples = 438, batches = 7\n",
      "Test dataset samples = 438, batches = 7\n"
     ]
    }
   ],
   "source": [
    "# default_root_path = \"./penstate_data/extract_phoneme\"\n",
    "default_root_path = \"./penstate_data/test\"\n",
    "gender = \"female_processed\"\n",
    "phoneme_idx = 10\n",
    "am_path = \"./penstate_data/AMs_unnormalized.csv\"\n",
    "# am_path = \"./penstate_data/AMs_final.csv\"\n",
    "\n",
    "am_idx = 13\n",
    "MAX_LEN = 13\n",
    "batch_size = 64\n",
    "batch_size = config['batch_size']\n",
    "train_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"train\")\n",
    "\n",
    "######################################################################################################################################\n",
    "val_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val1\")\n",
    "test_data = AudioDataset(data_path=default_root_path,\n",
    "                            am_path = am_path,\n",
    "                            gender = gender, phoneme_idx = phoneme_idx, am_idx = am_idx, MAX_LEN = MAX_LEN, partition=\"val2\")\n",
    "######################################################################################################################################\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, num_workers=0,\n",
    "                                               batch_size=batch_size, shuffle=True)\n",
    "\n",
    "######################################################################################################################################\n",
    "val_loader = torch.utils.data.DataLoader(val_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, num_workers=0,\n",
    "                                               batch_size=batch_size)\n",
    "######################################################################################################################################\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c74d99-578e-4710-b5c7-cd3783489de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 3067, batches = 48\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     phoneme, target_am = data\n",
    "#     print(phoneme.shape, target_am.shape)\n",
    "#     ##########################################\n",
    "#     # print(phoneme.dtype, target_am.dtype)\n",
    "#     ##########################################\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db9324-d5e9-4cc3-880d-fe3ed5d1b216",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96634bc-059e-4f49-9408-55d2113a5ab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 1: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df81998-fd34-4696-8c19-f6627e698954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CNNNetwork(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv2=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv3=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.conv4=nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=2),\n",
    "#             nn.BatchNorm2d(num_features=128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "#         self.flatten=nn.Flatten()\n",
    "#         self.linear1=nn.Linear(in_features=128*15,out_features=512)\n",
    "#         self.linear2=nn.Linear(in_features=512,out_features=128)\n",
    "#         self.linear3=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.linear4=nn.Linear(in_features=1024,out_features=256)\n",
    "#         # self.linear5=nn.Linear(in_features=256,out_features=128)\n",
    "#         # self.linear6=nn.Linear(in_features=128,out_features=1)\n",
    "#         # self.output=nn.Sigmoid()\n",
    "#         self.pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.output = nn.Tanh()\n",
    "    \n",
    "#     def forward(self,input_data):\n",
    "#         # add one dimension\n",
    "#         # input_data.unsqueeze_(1)\n",
    "#         x=self.conv1(input_data)\n",
    "#         x=self.conv2(x)\n",
    "#         x=self.conv3(x)\n",
    "#         x=self.conv4(x)\n",
    "        \n",
    "#         # x = self.pooling(x)\n",
    "#         # print(\"After conv: \", x.shape)\n",
    "#         x=self.flatten(x)\n",
    "#         # print(\"After flatten: \", x.shape)\n",
    "#         x=self.linear1(x)\n",
    "#         # print(\"After linear: \",x.shape)\n",
    "#         x=self.linear2(x)\n",
    "#         # x=self.linear3(x)\n",
    "#         # x=self.linear4(x)\n",
    "#         # x=self.linear5(x)\n",
    "        \n",
    "#         logits=self.linear3(x)\n",
    "#         output=self.output(logits)\n",
    "#         # print(output)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0b7afb-22cd-4583-807d-244775c7eb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CNNNetwork().to(device)\n",
    "# phoneme, AM = next(iter(train_loader))\n",
    "# # # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "# summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19e34e-3125-4cd1-a2f7-4195992d4f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: Prebuilt Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b42429-9bf8-470b-a3b9-a93816ada774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=None)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfee9771-9960-401c-8df9-ad59504ed9ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 32, 7]           3,136\n",
      "├─BatchNorm2d: 1-2                       [-1, 64, 32, 7]           128\n",
      "├─ReLU: 1-3                              [-1, 64, 32, 7]           --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 16, 4]           --\n",
      "├─Sequential: 1-5                        [-1, 256, 16, 4]          --\n",
      "|    └─Bottleneck: 2-1                   [-1, 256, 16, 4]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 16, 4]           4,096\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 16, 4]           36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 256, 16, 4]          16,384\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 256, 16, 4]          512\n",
      "|    |    └─Sequential: 3-9              [-1, 256, 16, 4]          16,896\n",
      "|    |    └─ReLU: 3-10                   [-1, 256, 16, 4]          --\n",
      "|    └─Bottleneck: 2-2                   [-1, 256, 16, 4]          --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 16, 4]           16,384\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-13                   [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-14                 [-1, 64, 16, 4]           36,864\n",
      "|    |    └─BatchNorm2d: 3-15            [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-16                   [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 256, 16, 4]          16,384\n",
      "|    |    └─BatchNorm2d: 3-18            [-1, 256, 16, 4]          512\n",
      "|    |    └─ReLU: 3-19                   [-1, 256, 16, 4]          --\n",
      "|    └─Bottleneck: 2-3                   [-1, 256, 16, 4]          --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 64, 16, 4]           16,384\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-22                   [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 64, 16, 4]           36,864\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 64, 16, 4]           128\n",
      "|    |    └─ReLU: 3-25                   [-1, 64, 16, 4]           --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 16, 4]          16,384\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 16, 4]          512\n",
      "|    |    └─ReLU: 3-28                   [-1, 256, 16, 4]          --\n",
      "├─Sequential: 1-6                        [-1, 512, 8, 2]           --\n",
      "|    └─Bottleneck: 2-4                   [-1, 512, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 128, 16, 4]          32,768\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 128, 16, 4]          256\n",
      "|    |    └─ReLU: 3-31                   [-1, 128, 16, 4]          --\n",
      "|    |    └─Conv2d: 3-32                 [-1, 128, 8, 2]           147,456\n",
      "|    |    └─BatchNorm2d: 3-33            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-34                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-35                 [-1, 512, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-36            [-1, 512, 8, 2]           1,024\n",
      "|    |    └─Sequential: 3-37             [-1, 512, 8, 2]           132,096\n",
      "|    |    └─ReLU: 3-38                   [-1, 512, 8, 2]           --\n",
      "|    └─Bottleneck: 2-5                   [-1, 512, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 128, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-41                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 128, 8, 2]           147,456\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-44                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-45                 [-1, 512, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-46            [-1, 512, 8, 2]           1,024\n",
      "|    |    └─ReLU: 3-47                   [-1, 512, 8, 2]           --\n",
      "|    └─Bottleneck: 2-6                   [-1, 512, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-48                 [-1, 128, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-49            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-50                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-51                 [-1, 128, 8, 2]           147,456\n",
      "|    |    └─BatchNorm2d: 3-52            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-53                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-54                 [-1, 512, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-55            [-1, 512, 8, 2]           1,024\n",
      "|    |    └─ReLU: 3-56                   [-1, 512, 8, 2]           --\n",
      "|    └─Bottleneck: 2-7                   [-1, 512, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-57                 [-1, 128, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-58            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-59                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-60                 [-1, 128, 8, 2]           147,456\n",
      "|    |    └─BatchNorm2d: 3-61            [-1, 128, 8, 2]           256\n",
      "|    |    └─ReLU: 3-62                   [-1, 128, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-63                 [-1, 512, 8, 2]           65,536\n",
      "|    |    └─BatchNorm2d: 3-64            [-1, 512, 8, 2]           1,024\n",
      "|    |    └─ReLU: 3-65                   [-1, 512, 8, 2]           --\n",
      "├─Sequential: 1-7                        [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-8                   [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-66                 [-1, 256, 8, 2]           131,072\n",
      "|    |    └─BatchNorm2d: 3-67            [-1, 256, 8, 2]           512\n",
      "|    |    └─ReLU: 3-68                   [-1, 256, 8, 2]           --\n",
      "|    |    └─Conv2d: 3-69                 [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-70            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-71                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-72                 [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-73            [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─Sequential: 3-74             [-1, 1024, 4, 1]          526,336\n",
      "|    |    └─ReLU: 3-75                   [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-9                   [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-76                 [-1, 256, 4, 1]           262,144\n",
      "|    |    └─BatchNorm2d: 3-77            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-78                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-79                 [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-80            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-81                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-82                 [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-83            [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─ReLU: 3-84                   [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-10                  [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-85                 [-1, 256, 4, 1]           262,144\n",
      "|    |    └─BatchNorm2d: 3-86            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-87                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-88                 [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-89            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-90                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-91                 [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-92            [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─ReLU: 3-93                   [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-11                  [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-94                 [-1, 256, 4, 1]           262,144\n",
      "|    |    └─BatchNorm2d: 3-95            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-96                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-97                 [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-98            [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-99                   [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-100                [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-101           [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─ReLU: 3-102                  [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-12                  [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-103                [-1, 256, 4, 1]           262,144\n",
      "|    |    └─BatchNorm2d: 3-104           [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-105                  [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-106                [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-107           [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-108                  [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-109                [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-110           [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─ReLU: 3-111                  [-1, 1024, 4, 1]          --\n",
      "|    └─Bottleneck: 2-13                  [-1, 1024, 4, 1]          --\n",
      "|    |    └─Conv2d: 3-112                [-1, 256, 4, 1]           262,144\n",
      "|    |    └─BatchNorm2d: 3-113           [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-114                  [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-115                [-1, 256, 4, 1]           589,824\n",
      "|    |    └─BatchNorm2d: 3-116           [-1, 256, 4, 1]           512\n",
      "|    |    └─ReLU: 3-117                  [-1, 256, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-118                [-1, 1024, 4, 1]          262,144\n",
      "|    |    └─BatchNorm2d: 3-119           [-1, 1024, 4, 1]          2,048\n",
      "|    |    └─ReLU: 3-120                  [-1, 1024, 4, 1]          --\n",
      "├─Sequential: 1-8                        [-1, 2048, 2, 1]          --\n",
      "|    └─Bottleneck: 2-14                  [-1, 2048, 2, 1]          --\n",
      "|    |    └─Conv2d: 3-121                [-1, 512, 4, 1]           524,288\n",
      "|    |    └─BatchNorm2d: 3-122           [-1, 512, 4, 1]           1,024\n",
      "|    |    └─ReLU: 3-123                  [-1, 512, 4, 1]           --\n",
      "|    |    └─Conv2d: 3-124                [-1, 512, 2, 1]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-125           [-1, 512, 2, 1]           1,024\n",
      "|    |    └─ReLU: 3-126                  [-1, 512, 2, 1]           --\n",
      "|    |    └─Conv2d: 3-127                [-1, 2048, 2, 1]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-128           [-1, 2048, 2, 1]          4,096\n",
      "|    |    └─Sequential: 3-129            [-1, 2048, 2, 1]          2,101,248\n",
      "|    |    └─ReLU: 3-130                  [-1, 2048, 2, 1]          --\n",
      "|    └─Bottleneck: 2-15                  [-1, 2048, 2, 1]          --\n",
      "|    |    └─Conv2d: 3-131                [-1, 512, 2, 1]           1,048,576\n",
      "|    |    └─BatchNorm2d: 3-132           [-1, 512, 2, 1]           1,024\n",
      "|    |    └─ReLU: 3-133                  [-1, 512, 2, 1]           --\n",
      "|    |    └─Conv2d: 3-134                [-1, 512, 2, 1]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-135           [-1, 512, 2, 1]           1,024\n",
      "|    |    └─ReLU: 3-136                  [-1, 512, 2, 1]           --\n",
      "|    |    └─Conv2d: 3-137                [-1, 2048, 2, 1]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-138           [-1, 2048, 2, 1]          4,096\n",
      "|    |    └─ReLU: 3-139                  [-1, 2048, 2, 1]          --\n",
      "|    └─Bottleneck: 2-16                  [-1, 2048, 2, 1]          --\n",
      "|    |    └─Conv2d: 3-140                [-1, 512, 2, 1]           1,048,576\n",
      "|    |    └─BatchNorm2d: 3-141           [-1, 512, 2, 1]           1,024\n",
      "|    |    └─ReLU: 3-142                  [-1, 512, 2, 1]           --\n",
      "|    |    └─Conv2d: 3-143                [-1, 512, 2, 1]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-144           [-1, 512, 2, 1]           1,024\n",
      "|    |    └─ReLU: 3-145                  [-1, 512, 2, 1]           --\n",
      "|    |    └─Conv2d: 3-146                [-1, 2048, 2, 1]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-147           [-1, 2048, 2, 1]          4,096\n",
      "|    |    └─ReLU: 3-148                  [-1, 2048, 2, 1]          --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [-1, 2048, 1, 1]          --\n",
      "├─Linear: 1-10                           [-1, 1]                   2,049\n",
      "==========================================================================================\n",
      "Total params: 23,503,809\n",
      "Trainable params: 23,503,809\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 145.87\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 3.59\n",
      "Params size (MB): 89.66\n",
      "Estimated Total Size (MB): 93.46\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 32, 7]           3,136\n",
       "├─BatchNorm2d: 1-2                       [-1, 64, 32, 7]           128\n",
       "├─ReLU: 1-3                              [-1, 64, 32, 7]           --\n",
       "├─MaxPool2d: 1-4                         [-1, 64, 16, 4]           --\n",
       "├─Sequential: 1-5                        [-1, 256, 16, 4]          --\n",
       "|    └─Bottleneck: 2-1                   [-1, 256, 16, 4]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 16, 4]           4,096\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 16, 4]           36,864\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 256, 16, 4]          16,384\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 256, 16, 4]          512\n",
       "|    |    └─Sequential: 3-9              [-1, 256, 16, 4]          16,896\n",
       "|    |    └─ReLU: 3-10                   [-1, 256, 16, 4]          --\n",
       "|    └─Bottleneck: 2-2                   [-1, 256, 16, 4]          --\n",
       "|    |    └─Conv2d: 3-11                 [-1, 64, 16, 4]           16,384\n",
       "|    |    └─BatchNorm2d: 3-12            [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-13                   [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-14                 [-1, 64, 16, 4]           36,864\n",
       "|    |    └─BatchNorm2d: 3-15            [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-16                   [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-17                 [-1, 256, 16, 4]          16,384\n",
       "|    |    └─BatchNorm2d: 3-18            [-1, 256, 16, 4]          512\n",
       "|    |    └─ReLU: 3-19                   [-1, 256, 16, 4]          --\n",
       "|    └─Bottleneck: 2-3                   [-1, 256, 16, 4]          --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 64, 16, 4]           16,384\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-22                   [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 64, 16, 4]           36,864\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 64, 16, 4]           128\n",
       "|    |    └─ReLU: 3-25                   [-1, 64, 16, 4]           --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 16, 4]          16,384\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 16, 4]          512\n",
       "|    |    └─ReLU: 3-28                   [-1, 256, 16, 4]          --\n",
       "├─Sequential: 1-6                        [-1, 512, 8, 2]           --\n",
       "|    └─Bottleneck: 2-4                   [-1, 512, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 128, 16, 4]          32,768\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 128, 16, 4]          256\n",
       "|    |    └─ReLU: 3-31                   [-1, 128, 16, 4]          --\n",
       "|    |    └─Conv2d: 3-32                 [-1, 128, 8, 2]           147,456\n",
       "|    |    └─BatchNorm2d: 3-33            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-34                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-35                 [-1, 512, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-36            [-1, 512, 8, 2]           1,024\n",
       "|    |    └─Sequential: 3-37             [-1, 512, 8, 2]           132,096\n",
       "|    |    └─ReLU: 3-38                   [-1, 512, 8, 2]           --\n",
       "|    └─Bottleneck: 2-5                   [-1, 512, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 128, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-41                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 128, 8, 2]           147,456\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-44                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-45                 [-1, 512, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-46            [-1, 512, 8, 2]           1,024\n",
       "|    |    └─ReLU: 3-47                   [-1, 512, 8, 2]           --\n",
       "|    └─Bottleneck: 2-6                   [-1, 512, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-48                 [-1, 128, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-49            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-50                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-51                 [-1, 128, 8, 2]           147,456\n",
       "|    |    └─BatchNorm2d: 3-52            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-53                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-54                 [-1, 512, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-55            [-1, 512, 8, 2]           1,024\n",
       "|    |    └─ReLU: 3-56                   [-1, 512, 8, 2]           --\n",
       "|    └─Bottleneck: 2-7                   [-1, 512, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-57                 [-1, 128, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-58            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-59                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-60                 [-1, 128, 8, 2]           147,456\n",
       "|    |    └─BatchNorm2d: 3-61            [-1, 128, 8, 2]           256\n",
       "|    |    └─ReLU: 3-62                   [-1, 128, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-63                 [-1, 512, 8, 2]           65,536\n",
       "|    |    └─BatchNorm2d: 3-64            [-1, 512, 8, 2]           1,024\n",
       "|    |    └─ReLU: 3-65                   [-1, 512, 8, 2]           --\n",
       "├─Sequential: 1-7                        [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-8                   [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-66                 [-1, 256, 8, 2]           131,072\n",
       "|    |    └─BatchNorm2d: 3-67            [-1, 256, 8, 2]           512\n",
       "|    |    └─ReLU: 3-68                   [-1, 256, 8, 2]           --\n",
       "|    |    └─Conv2d: 3-69                 [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-70            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-71                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-72                 [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-73            [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─Sequential: 3-74             [-1, 1024, 4, 1]          526,336\n",
       "|    |    └─ReLU: 3-75                   [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-9                   [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-76                 [-1, 256, 4, 1]           262,144\n",
       "|    |    └─BatchNorm2d: 3-77            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-78                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-79                 [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-80            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-81                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-82                 [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-83            [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─ReLU: 3-84                   [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-10                  [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-85                 [-1, 256, 4, 1]           262,144\n",
       "|    |    └─BatchNorm2d: 3-86            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-87                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-88                 [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-89            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-90                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-91                 [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-92            [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─ReLU: 3-93                   [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-11                  [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-94                 [-1, 256, 4, 1]           262,144\n",
       "|    |    └─BatchNorm2d: 3-95            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-96                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-97                 [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-98            [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-99                   [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-100                [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-101           [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─ReLU: 3-102                  [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-12                  [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-103                [-1, 256, 4, 1]           262,144\n",
       "|    |    └─BatchNorm2d: 3-104           [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-105                  [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-106                [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-107           [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-108                  [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-109                [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-110           [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─ReLU: 3-111                  [-1, 1024, 4, 1]          --\n",
       "|    └─Bottleneck: 2-13                  [-1, 1024, 4, 1]          --\n",
       "|    |    └─Conv2d: 3-112                [-1, 256, 4, 1]           262,144\n",
       "|    |    └─BatchNorm2d: 3-113           [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-114                  [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-115                [-1, 256, 4, 1]           589,824\n",
       "|    |    └─BatchNorm2d: 3-116           [-1, 256, 4, 1]           512\n",
       "|    |    └─ReLU: 3-117                  [-1, 256, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-118                [-1, 1024, 4, 1]          262,144\n",
       "|    |    └─BatchNorm2d: 3-119           [-1, 1024, 4, 1]          2,048\n",
       "|    |    └─ReLU: 3-120                  [-1, 1024, 4, 1]          --\n",
       "├─Sequential: 1-8                        [-1, 2048, 2, 1]          --\n",
       "|    └─Bottleneck: 2-14                  [-1, 2048, 2, 1]          --\n",
       "|    |    └─Conv2d: 3-121                [-1, 512, 4, 1]           524,288\n",
       "|    |    └─BatchNorm2d: 3-122           [-1, 512, 4, 1]           1,024\n",
       "|    |    └─ReLU: 3-123                  [-1, 512, 4, 1]           --\n",
       "|    |    └─Conv2d: 3-124                [-1, 512, 2, 1]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-125           [-1, 512, 2, 1]           1,024\n",
       "|    |    └─ReLU: 3-126                  [-1, 512, 2, 1]           --\n",
       "|    |    └─Conv2d: 3-127                [-1, 2048, 2, 1]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-128           [-1, 2048, 2, 1]          4,096\n",
       "|    |    └─Sequential: 3-129            [-1, 2048, 2, 1]          2,101,248\n",
       "|    |    └─ReLU: 3-130                  [-1, 2048, 2, 1]          --\n",
       "|    └─Bottleneck: 2-15                  [-1, 2048, 2, 1]          --\n",
       "|    |    └─Conv2d: 3-131                [-1, 512, 2, 1]           1,048,576\n",
       "|    |    └─BatchNorm2d: 3-132           [-1, 512, 2, 1]           1,024\n",
       "|    |    └─ReLU: 3-133                  [-1, 512, 2, 1]           --\n",
       "|    |    └─Conv2d: 3-134                [-1, 512, 2, 1]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-135           [-1, 512, 2, 1]           1,024\n",
       "|    |    └─ReLU: 3-136                  [-1, 512, 2, 1]           --\n",
       "|    |    └─Conv2d: 3-137                [-1, 2048, 2, 1]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-138           [-1, 2048, 2, 1]          4,096\n",
       "|    |    └─ReLU: 3-139                  [-1, 2048, 2, 1]          --\n",
       "|    └─Bottleneck: 2-16                  [-1, 2048, 2, 1]          --\n",
       "|    |    └─Conv2d: 3-140                [-1, 512, 2, 1]           1,048,576\n",
       "|    |    └─BatchNorm2d: 3-141           [-1, 512, 2, 1]           1,024\n",
       "|    |    └─ReLU: 3-142                  [-1, 512, 2, 1]           --\n",
       "|    |    └─Conv2d: 3-143                [-1, 512, 2, 1]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-144           [-1, 512, 2, 1]           1,024\n",
       "|    |    └─ReLU: 3-145                  [-1, 512, 2, 1]           --\n",
       "|    |    └─Conv2d: 3-146                [-1, 2048, 2, 1]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-147           [-1, 2048, 2, 1]          4,096\n",
       "|    |    └─ReLU: 3-148                  [-1, 2048, 2, 1]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [-1, 2048, 1, 1]          --\n",
       "├─Linear: 1-10                           [-1, 1]                   2,049\n",
       "==========================================================================================\n",
       "Total params: 23,503,809\n",
       "Trainable params: 23,503,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 145.87\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 3.59\n",
       "Params size (MB): 89.66\n",
       "Estimated Total Size (MB): 93.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "phoneme, AM = next(iter(train_loader))\n",
    "# # summary(model,(64, 259)) # After conv: torch.Size([2, 128, 5, 18])\n",
    "summary(model, phoneme.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff3c7e-600a-4f48-a73e-3477e6d08404",
   "metadata": {},
   "source": [
    "## Train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6978e0-43a9-4a1b-9f05-7fca1d25be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "563a8ca6-0732-4409-a74c-1e2ef43191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() #Defining Loss function \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate']) #Defining Optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.0001, last_epoch=-1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[35,40,45,50,60,65,70,90,110,150,170,180], gamma=0.5) # add learning rate scheduler\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * config['epochs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75674d65-bd4f-412b-8aa0-2d951cae0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 #Monitoring Loss\n",
    "    \n",
    "    #########################################################\n",
    "    # AM_true_list = []\n",
    "    # AM_pred_list = []\n",
    "    #########################################################\n",
    "    \n",
    "    for iter, (phoneme, AM) in enumerate(dataloader):\n",
    "\n",
    "        ### Move Data to Device (Ideally GPU)\n",
    "        phoneme = phoneme.to(device)\n",
    "        AM = AM.to(device)\n",
    "\n",
    "        ### Forward Propagation\n",
    "        preds_AM = model(phoneme)\n",
    "\n",
    "        ### Loss Calculation\n",
    "        # print(AM.shape)\n",
    "        preds_AM = torch.squeeze(preds_AM)\n",
    "        # print(preds_AM)\n",
    "        # print(preds_AM.shape)\n",
    "        loss = criterion(preds_AM, AM)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        #########################################################\n",
    "        ### Store Pred and True Labels\n",
    "        # AM_pred_list.extend(preds_AM.cpu().tolist())\n",
    "        # AM_true_list.extend(AM.cpu().tolist())\n",
    "        #########################################################\n",
    "\n",
    "        ### Initialize Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Backward Propagation\n",
    "        loss.backward()\n",
    "\n",
    "        ### Gradient Descent\n",
    "        optimizer.step()\n",
    "        if iter % 20 == 0:\n",
    "            print(\"iter =\", iter, \"loss =\",loss.item())\n",
    "    train_loss /= len(dataloader)\n",
    "    print(\"Learning rate = \", scheduler.get_last_lr()[0])\n",
    "    print(\"Train loss = \", train_loss)\n",
    "    \n",
    "    #########################################################\n",
    "    # print(AM_pred_list)\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    # accuracy = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    # print(\"Train MSE accuracy: \", accuracy)\n",
    "    #########################################################\n",
    "    \n",
    "    scheduler.step() # add schedule learning rate\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a1518e3-0b07-4b4d-a192-54e5bc0a7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "\n",
    "    model.eval() # set model in evaluation mode\n",
    "\n",
    "    AM_true_list = []\n",
    "    AM_pred_list = []\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        phoneme, AM = data\n",
    "        ### Move data to device (ideally GPU)\n",
    "        phoneme, AM = phoneme.to(device), AM.to(device) \n",
    "\n",
    "        with torch.inference_mode(): # makes sure that there are no gradients computed as we are not training the model now\n",
    "            ### Forward Propagation\n",
    "            ### Get Predictions\n",
    "            predicted_AM = model(phoneme)\n",
    "            # print(predicted_AM)\n",
    "        \n",
    "        ### Store Pred and True Labels\n",
    "        AM_pred_list.extend(predicted_AM.cpu().tolist())\n",
    "        AM_true_list.extend(AM.cpu().tolist())\n",
    "        \n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "    \n",
    "        del phoneme, AM, predicted_AM\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ###############################################################################################\n",
    "    # print(AM_pred_list[1000:3100])\n",
    "    # print(AM_true_list)\n",
    "    # print(len(AM_pred_list))\n",
    "    # print(len(AM_true_list))\n",
    "    ###############################################################################################\n",
    "    \n",
    "    print(\"Number of equals between two list: \", sum(a == b for a,b in zip(AM_pred_list, AM_true_list)))\n",
    "    \n",
    "    ### Calculate Accuracy\n",
    "    MSE = mean_squared_error(AM_pred_list, AM_true_list)\n",
    "    r2_score_acc = r2_score(AM_pred_list, AM_true_list)\n",
    "    MAE = mean_absolute_error(AM_pred_list, AM_true_list)\n",
    "    print(\"Validation r2_score: \", r2_score_acc)\n",
    "    print(\"Validation MAE: \", MAE)\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce9f12-c7c9-4328-b4e2-b921edd4747c",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90eda49-e81d-42a2-af9b-f6f18ef88248",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/200\n",
      "iter = 0 loss = 0.4193339943885803\n",
      "iter = 20 loss = 0.36251652240753174\n",
      "iter = 40 loss = 0.09004825353622437\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.7242336738078544\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.15568810907461184\n",
      "Validation MAE:  0.3799759668466044\n",
      "\tTrain Loss:  0.7242336738078544\n",
      "\tValidation MSE:  0.5236537400566456\n",
      "\n",
      "Epoch 2/200\n",
      "iter = 0 loss = 0.4117472469806671\n",
      "iter = 20 loss = 0.03549589961767197\n",
      "iter = 40 loss = 0.035278625786304474\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.07800759045251955\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.9326809469440513\n",
      "Validation MAE:  0.1840230912463442\n",
      "\tTrain Loss:  0.07800759045251955\n",
      "\tValidation MSE:  0.05206927247005615\n",
      "\n",
      "Epoch 3/200\n",
      "iter = 0 loss = 0.036115579307079315\n",
      "iter = 20 loss = 0.02039037086069584\n",
      "iter = 40 loss = 0.02137434110045433\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.021763287077192217\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.31369744604462513\n",
      "Validation MAE:  0.09654880123059839\n",
      "\tTrain Loss:  0.021763287077192217\n",
      "\tValidation MSE:  0.014917905129309149\n",
      "\n",
      "Epoch 4/200\n",
      "iter = 0 loss = 0.014447733759880066\n",
      "iter = 20 loss = 0.008983409032225609\n",
      "iter = 40 loss = 0.014123549684882164\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.012241047321973989\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.7744519056555761\n",
      "Validation MAE:  0.09446972724237399\n",
      "\tTrain Loss:  0.012241047321973989\n",
      "\tValidation MSE:  0.01380258268445973\n",
      "\n",
      "Epoch 5/200\n",
      "iter = 0 loss = 0.008753282949328423\n",
      "iter = 20 loss = 0.008522333577275276\n",
      "iter = 40 loss = 0.005590601358562708\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.008247403292140612\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.3800771713304538\n",
      "Validation MAE:  0.07412804683593854\n",
      "\tTrain Loss:  0.008247403292140612\n",
      "\tValidation MSE:  0.008290346754359754\n",
      "\n",
      "Epoch 6/200\n",
      "iter = 0 loss = 0.004671271424740553\n",
      "iter = 20 loss = 0.006032172590494156\n",
      "iter = 40 loss = 0.00420209439471364\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.006327411800157279\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.367524467076196\n",
      "Validation MAE:  0.113161471166295\n",
      "\tTrain Loss:  0.006327411800157279\n",
      "\tValidation MSE:  0.016865561532958585\n",
      "\n",
      "Epoch 7/200\n",
      "iter = 0 loss = 0.008984541520476341\n",
      "iter = 20 loss = 0.00492539256811142\n",
      "iter = 40 loss = 0.004402249585837126\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.005461584999769305\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.31276897751346366\n",
      "Validation MAE:  0.05920184410462096\n",
      "\tTrain Loss:  0.005461584999769305\n",
      "\tValidation MSE:  0.005499141717497599\n",
      "\n",
      "Epoch 8/200\n",
      "iter = 0 loss = 0.004188298713415861\n",
      "iter = 20 loss = 0.004607817158102989\n",
      "iter = 40 loss = 0.002733114641159773\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003623360064617979\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.7232999401332085\n",
      "Validation MAE:  0.06188626497235472\n",
      "\tTrain Loss:  0.003623360064617979\n",
      "\tValidation MSE:  0.0057953854752279205\n",
      "\n",
      "Epoch 9/200\n",
      "iter = 0 loss = 0.003003546269610524\n",
      "iter = 20 loss = 0.002670060144737363\n",
      "iter = 40 loss = 0.003632045118138194\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003161843111835575\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.3631922049294727\n",
      "Validation MAE:  0.050163314256766074\n",
      "\tTrain Loss:  0.003161843111835575\n",
      "\tValidation MSE:  0.003926375457239817\n",
      "\n",
      "Epoch 10/200\n",
      "iter = 0 loss = 0.0023185131140053272\n",
      "iter = 20 loss = 0.0024216033052653074\n",
      "iter = 40 loss = 0.0019407602958381176\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0026799282156086215\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.24155632416334738\n",
      "Validation MAE:  0.04446356719759501\n",
      "\tTrain Loss:  0.0026799282156086215\n",
      "\tValidation MSE:  0.002973619701980211\n",
      "\n",
      "Epoch 11/200\n",
      "iter = 0 loss = 0.0032141604460775852\n",
      "iter = 20 loss = 0.002226135926321149\n",
      "iter = 40 loss = 0.0014892476610839367\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0032354334374152436\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.2566243182181631\n",
      "Validation MAE:  0.04103053061793384\n",
      "\tTrain Loss:  0.0032354334374152436\n",
      "\tValidation MSE:  0.002580928968897193\n",
      "\n",
      "Epoch 12/200\n",
      "iter = 0 loss = 0.003415457671508193\n",
      "iter = 20 loss = 0.0017736454028636217\n",
      "iter = 40 loss = 0.0085222739726305\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003418129946415623\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.1675727769858897\n",
      "Validation MAE:  0.04806054084132251\n",
      "\tTrain Loss:  0.003418129946415623\n",
      "\tValidation MSE:  0.003472943093820824\n",
      "\n",
      "Epoch 13/200\n",
      "iter = 0 loss = 0.004813439212739468\n",
      "iter = 20 loss = 0.0016210312023758888\n",
      "iter = 40 loss = 0.0016336300177499652\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.00200009235535011\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2727207992236975\n",
      "Validation MAE:  0.050957652293655974\n",
      "\tTrain Loss:  0.00200009235535011\n",
      "\tValidation MSE:  0.003912765210536269\n",
      "\n",
      "Epoch 14/200\n",
      "iter = 0 loss = 0.0014301699120551348\n",
      "iter = 20 loss = 0.0033984356559813023\n",
      "iter = 40 loss = 0.0011109784245491028\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0021953188261250034\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.795339847801217\n",
      "Validation MAE:  0.04142807104271841\n",
      "\tTrain Loss:  0.0021953188261250034\n",
      "\tValidation MSE:  0.002666026683004403\n",
      "\n",
      "Epoch 15/200\n",
      "iter = 0 loss = 0.0014335722662508488\n",
      "iter = 20 loss = 0.001831323723308742\n",
      "iter = 40 loss = 0.0010073557496070862\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0016827458845606695\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.7788262664209493\n",
      "Validation MAE:  0.048831184671077554\n",
      "\tTrain Loss:  0.0016827458845606695\n",
      "\tValidation MSE:  0.003534903828362394\n",
      "\n",
      "Epoch 16/200\n",
      "iter = 0 loss = 0.0019561750814318657\n",
      "iter = 20 loss = 0.0007310552755370736\n",
      "iter = 40 loss = 0.0006823567091487348\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0016480067970405798\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.32969048133537604\n",
      "Validation MAE:  0.0334798047259518\n",
      "\tTrain Loss:  0.0016480067970405798\n",
      "\tValidation MSE:  0.0017816658726176667\n",
      "\n",
      "Epoch 17/200\n",
      "iter = 0 loss = 0.0013494412414729595\n",
      "iter = 20 loss = 0.0020833536982536316\n",
      "iter = 40 loss = 0.0008676949655637145\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0025781032406181716\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.167307641235201\n",
      "Validation MAE:  0.0477997377582881\n",
      "\tTrain Loss:  0.0025781032406181716\n",
      "\tValidation MSE:  0.0032405454797415616\n",
      "\n",
      "Epoch 18/200\n",
      "iter = 0 loss = 0.002426545601338148\n",
      "iter = 20 loss = 0.0018804779974743724\n",
      "iter = 40 loss = 0.001809324137866497\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0018228355450749707\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -7.570543636481057\n",
      "Validation MAE:  0.08552213816065767\n",
      "\tTrain Loss:  0.0018228355450749707\n",
      "\tValidation MSE:  0.008720907330629742\n",
      "\n",
      "Epoch 19/200\n",
      "iter = 0 loss = 0.007372098043560982\n",
      "iter = 20 loss = 0.005803604144603014\n",
      "iter = 40 loss = 0.0008252054685726762\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0064703462170048924\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -7.026804398185259\n",
      "Validation MAE:  0.08111294984953589\n",
      "\tTrain Loss:  0.0064703462170048924\n",
      "\tValidation MSE:  0.007881021349636516\n",
      "\n",
      "Epoch 20/200\n",
      "iter = 0 loss = 0.0074376012198626995\n",
      "iter = 20 loss = 0.022949498146772385\n",
      "iter = 40 loss = 0.010191149078309536\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.009486301084204266\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -3.4183896518512036\n",
      "Validation MAE:  0.05752451343623471\n",
      "\tTrain Loss:  0.009486301084204266\n",
      "\tValidation MSE:  0.004465687051843187\n",
      "\n",
      "Epoch 21/200\n",
      "iter = 0 loss = 0.0033182299230247736\n",
      "iter = 20 loss = 0.0016781927552074194\n",
      "iter = 40 loss = 0.005083717405796051\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003369222545491842\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -15.975022698064187\n",
      "Validation MAE:  0.11583006366679113\n",
      "\tTrain Loss:  0.003369222545491842\n",
      "\tValidation MSE:  0.014625124865575123\n",
      "\n",
      "Epoch 22/200\n",
      "iter = 0 loss = 0.0071328142657876015\n",
      "iter = 20 loss = 0.0068663135170936584\n",
      "iter = 40 loss = 0.001080088084563613\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0032297289265746563\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -5.96967835790296\n",
      "Validation MAE:  0.06616563727594402\n",
      "\tTrain Loss:  0.0032297289265746563\n",
      "\tValidation MSE:  0.0054281108830101675\n",
      "\n",
      "Epoch 23/200\n",
      "iter = 0 loss = 0.0023828677367419004\n",
      "iter = 20 loss = 0.0031632783357053995\n",
      "iter = 40 loss = 0.0030187098309397697\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003177385539553749\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -0.6971293990452185\n",
      "Validation MAE:  0.02660531207034577\n",
      "\tTrain Loss:  0.003177385539553749\n",
      "\tValidation MSE:  0.0011528996483955594\n",
      "\n",
      "Epoch 24/200\n",
      "iter = 0 loss = 0.0007088526035659015\n",
      "iter = 20 loss = 0.0031726572196930647\n",
      "iter = 40 loss = 0.0014185503823682666\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0038646353508132356\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2805781304682253\n",
      "Validation MAE:  0.0328423085550195\n",
      "\tTrain Loss:  0.0038646353508132356\n",
      "\tValidation MSE:  0.0016623692451975328\n",
      "\n",
      "Epoch 25/200\n",
      "iter = 0 loss = 0.0026261694729328156\n",
      "iter = 20 loss = 0.0013928140979260206\n",
      "iter = 40 loss = 0.001853350317105651\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.003628757580978951\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.9944001302914396\n",
      "Validation MAE:  0.046251226335627844\n",
      "\tTrain Loss:  0.003628757580978951\n",
      "\tValidation MSE:  0.0029967086361661517\n",
      "\n",
      "Epoch 26/200\n",
      "iter = 0 loss = 0.002578909043222666\n",
      "iter = 20 loss = 0.005272737704217434\n",
      "iter = 40 loss = 0.016342103481292725\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.007151325242981936\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -4.588100453093175\n",
      "Validation MAE:  0.055881094850905956\n",
      "\tTrain Loss:  0.007151325242981936\n",
      "\tValidation MSE:  0.004041415952115923\n",
      "\n",
      "Epoch 27/200\n",
      "iter = 0 loss = 0.002978007774800062\n",
      "iter = 20 loss = 0.02688112109899521\n",
      "iter = 40 loss = 0.003376599634066224\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.007102783870019873\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.4801233450743316\n",
      "Validation MAE:  0.0443299760080908\n",
      "\tTrain Loss:  0.007102783870019873\n",
      "\tValidation MSE:  0.002896500202676429\n",
      "\n",
      "Epoch 28/200\n",
      "iter = 0 loss = 0.00275628175586462\n",
      "iter = 20 loss = 0.008450533263385296\n",
      "iter = 40 loss = 0.0006577115273103118\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.004153977890382521\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2032054925064508\n",
      "Validation MAE:  0.0294732036383729\n",
      "\tTrain Loss:  0.004153977890382521\n",
      "\tValidation MSE:  0.0013447089856173987\n",
      "\n",
      "Epoch 29/200\n",
      "iter = 0 loss = 0.0009208965348079801\n",
      "iter = 20 loss = 0.0009154669824056327\n",
      "iter = 40 loss = 0.008234419859945774\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.005077991583675612\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -19.931186735440825\n",
      "Validation MAE:  0.10635854052082044\n",
      "\tTrain Loss:  0.005077991583675612\n",
      "\tValidation MSE:  0.01225163536966642\n",
      "\n",
      "Epoch 30/200\n",
      "iter = 0 loss = 0.008957548066973686\n",
      "iter = 20 loss = 0.00048697955207899213\n",
      "iter = 40 loss = 0.0004440371412783861\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.004325277725608127\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.0231799985980286\n",
      "Validation MAE:  0.03550098754771768\n",
      "\tTrain Loss:  0.004325277725608127\n",
      "\tValidation MSE:  0.0018754254125791362\n",
      "\n",
      "Epoch 31/200\n",
      "iter = 0 loss = 0.002229594625532627\n",
      "iter = 20 loss = 0.0017896234057843685\n",
      "iter = 40 loss = 0.0038126392755657434\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.004016234387260435\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -6.209689764141201\n",
      "Validation MAE:  0.05769486242233346\n",
      "\tTrain Loss:  0.004016234387260435\n",
      "\tValidation MSE:  0.004114290734972561\n",
      "\n",
      "Epoch 32/200\n",
      "iter = 0 loss = 0.0015799151733517647\n",
      "iter = 20 loss = 0.004447541665285826\n",
      "iter = 40 loss = 0.003933943808078766\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.00323772918030348\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.049763662945268\n",
      "Validation MAE:  0.03304633260045422\n",
      "\tTrain Loss:  0.00323772918030348\n",
      "\tValidation MSE:  0.0015989467416628403\n",
      "\n",
      "Epoch 33/200\n",
      "iter = 0 loss = 0.0010675053345039487\n",
      "iter = 20 loss = 0.0005008858279325068\n",
      "iter = 40 loss = 0.0003464971960056573\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0019413865150757677\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -4.831284992144981\n",
      "Validation MAE:  0.04740307952987549\n",
      "\tTrain Loss:  0.0019413865150757677\n",
      "\tValidation MSE:  0.0029492005297635615\n",
      "\n",
      "Epoch 34/200\n",
      "iter = 0 loss = 0.003234724048525095\n",
      "iter = 20 loss = 0.003135981969535351\n",
      "iter = 40 loss = 0.0006053391844034195\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0033455445530610937\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -26.70884503510753\n",
      "Validation MAE:  0.10906717453373077\n",
      "\tTrain Loss:  0.0033455445530610937\n",
      "\tValidation MSE:  0.01278376150131704\n",
      "\n",
      "Epoch 35/200\n",
      "iter = 0 loss = 0.009794619865715504\n",
      "iter = 20 loss = 0.002925229724496603\n",
      "iter = 40 loss = 0.000318457605317235\n",
      "Learning rate =  0.001\n",
      "Train loss =  0.0018151837230107049\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.0485256318188543\n",
      "Validation MAE:  0.02344380604894194\n",
      "\tTrain Loss:  0.0018151837230107049\n",
      "\tValidation MSE:  0.0009193552796792759\n",
      "\n",
      "Epoch 36/200\n",
      "iter = 0 loss = 0.00024642591597512364\n",
      "iter = 20 loss = 0.0004972051247023046\n",
      "iter = 40 loss = 0.0003887822385877371\n",
      "Learning rate =  0.0005\n",
      "Train loss =  0.0007129231438132896\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -3.9229015865471695\n",
      "Validation MAE:  0.03766105756095555\n",
      "\tTrain Loss:  0.0007129231438132896\n",
      "\tValidation MSE:  0.0019467135823994896\n",
      "\n",
      "Epoch 37/200\n",
      "iter = 0 loss = 0.0007505264366045594\n",
      "iter = 20 loss = 0.00023659307043999434\n",
      "iter = 40 loss = 0.0008795697358436882\n",
      "Learning rate =  0.0005\n",
      "Train loss =  0.000851969822482109\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -4.309947030226641\n",
      "Validation MAE:  0.03939000554552906\n",
      "\tTrain Loss:  0.000851969822482109\n",
      "\tValidation MSE:  0.0021078380179210374\n",
      "\n",
      "Epoch 38/200\n",
      "iter = 0 loss = 0.0012113206321373582\n",
      "iter = 20 loss = 0.00016915175365284085\n",
      "iter = 40 loss = 0.0029155148658901453\n",
      "Learning rate =  0.0005\n",
      "Train loss =  0.0007320796230487758\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -6.153733628143236\n",
      "Validation MAE:  0.04704769908293197\n",
      "\tTrain Loss:  0.0007320796230487758\n",
      "\tValidation MSE:  0.002890781477886923\n",
      "\n",
      "Epoch 39/200\n",
      "iter = 0 loss = 0.002659870544448495\n",
      "iter = 20 loss = 0.0001789590169209987\n",
      "iter = 40 loss = 0.00029167882166802883\n",
      "Learning rate =  0.0005\n",
      "Train loss =  0.0010551653055396553\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.0019441004342284\n",
      "Validation MAE:  0.02176967270025924\n",
      "\tTrain Loss:  0.0010551653055396553\n",
      "\tValidation MSE:  0.0008049148720274491\n",
      "\n",
      "Epoch 40/200\n",
      "iter = 0 loss = 0.00023392183356918395\n",
      "iter = 20 loss = 0.00025276152882725\n",
      "iter = 40 loss = 0.0011220548767596483\n",
      "Learning rate =  0.0005\n",
      "Train loss =  0.0006162518161545449\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -5.246579328727826\n",
      "Validation MAE:  0.043250018943390346\n",
      "\tTrain Loss:  0.0006162518161545449\n",
      "\tValidation MSE:  0.0024180802218852554\n",
      "\n",
      "Epoch 41/200\n",
      "iter = 0 loss = 0.0008211347740143538\n",
      "iter = 20 loss = 0.0008810943108983338\n",
      "iter = 40 loss = 0.0006555907893925905\n",
      "Learning rate =  0.00025\n",
      "Train loss =  0.0004590243888742407\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -2.08445479238929\n",
      "Validation MAE:  0.027829222279052213\n",
      "\tTrain Loss:  0.0004590243888742407\n",
      "\tValidation MSE:  0.0011892299482763016\n",
      "\n",
      "Epoch 42/200\n",
      "iter = 0 loss = 0.00045692577259615064\n",
      "iter = 20 loss = 0.00014604862371925265\n",
      "iter = 40 loss = 0.00027236249297857285\n",
      "Learning rate =  0.00025\n",
      "Train loss =  0.00023859613914585984\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.5020730282900052\n",
      "Validation MAE:  0.02364627629110258\n",
      "\tTrain Loss:  0.00023859613914585984\n",
      "\tValidation MSE:  0.0009152271468296816\n",
      "\n",
      "Epoch 43/200\n",
      "iter = 0 loss = 0.00016810039232950658\n",
      "iter = 20 loss = 0.0004700883582700044\n",
      "iter = 40 loss = 0.00012907790369354188\n",
      "Learning rate =  0.00025\n",
      "Train loss =  0.00036076102287552203\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.7021145297790397\n",
      "Validation MAE:  0.024867843887577318\n",
      "\tTrain Loss:  0.00036076102287552203\n",
      "\tValidation MSE:  0.001011629387891081\n",
      "\n",
      "Epoch 44/200\n",
      "iter = 0 loss = 0.0006275419727899134\n",
      "iter = 20 loss = 0.000268768984824419\n",
      "iter = 40 loss = 0.00036517682019621134\n",
      "Learning rate =  0.00025\n",
      "Train loss =  0.0003705424934802674\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.7630311826420346\n",
      "Validation MAE:  0.02494160796953663\n",
      "\tTrain Loss:  0.0003705424934802674\n",
      "\tValidation MSE:  0.0010101736373417125\n",
      "\n",
      "Epoch 45/200\n",
      "iter = 0 loss = 0.00011907456791959703\n",
      "iter = 20 loss = 0.0003240849473513663\n",
      "iter = 40 loss = 0.0003134086146019399\n",
      "Learning rate =  0.00025\n",
      "Train loss =  0.00025933002052624943\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -4.303389818006582\n",
      "Validation MAE:  0.038014491126961904\n",
      "\tTrain Loss:  0.00025933002052624943\n",
      "\tValidation MSE:  0.001962148215964291\n",
      "\n",
      "Epoch 46/200\n",
      "iter = 0 loss = 0.000974582158960402\n",
      "iter = 20 loss = 0.0005471556214615703\n",
      "iter = 40 loss = 0.00012217651237733662\n",
      "Learning rate =  0.000125\n",
      "Train loss =  0.00029026206008590333\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.6268159589119202\n",
      "Validation MAE:  0.02389626388680445\n",
      "\tTrain Loss:  0.00029026206008590333\n",
      "\tValidation MSE:  0.0009201643737235015\n",
      "\n",
      "Epoch 47/200\n",
      "iter = 0 loss = 0.0001652456703595817\n",
      "iter = 20 loss = 0.00010983232641592622\n",
      "iter = 40 loss = 0.00036455795634537935\n",
      "Learning rate =  0.000125\n",
      "Train loss =  0.0001710150252923389\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.1794210950658055\n",
      "Validation MAE:  0.02141803679945262\n",
      "\tTrain Loss:  0.0001710150252923389\n",
      "\tValidation MSE:  0.0007747820729654718\n",
      "\n",
      "Epoch 48/200\n",
      "iter = 0 loss = 0.00019719914416782558\n",
      "iter = 20 loss = 0.00011938731040572748\n",
      "iter = 40 loss = 0.00016269329353235662\n",
      "Learning rate =  0.000125\n",
      "Train loss =  0.0001795465486793546\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2535040953167176\n",
      "Validation MAE:  0.0218544440454544\n",
      "\tTrain Loss:  0.0001795465486793546\n",
      "\tValidation MSE:  0.000815674316989393\n",
      "\n",
      "Epoch 49/200\n",
      "iter = 0 loss = 0.00012863505980931222\n",
      "iter = 20 loss = 9.44339917623438e-05\n",
      "iter = 40 loss = 0.00011472220649011433\n",
      "Learning rate =  0.000125\n",
      "Train loss =  0.00019465938294160878\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.6975263792915207\n",
      "Validation MAE:  0.024305185362628604\n",
      "\tTrain Loss:  0.00019465938294160878\n",
      "\tValidation MSE:  0.000956096783251083\n",
      "\n",
      "Epoch 50/200\n",
      "iter = 0 loss = 0.00024568475782871246\n",
      "iter = 20 loss = 0.00028977138572372496\n",
      "iter = 40 loss = 0.00039242292405106127\n",
      "Learning rate =  0.000125\n",
      "Train loss =  0.0002377278885129878\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.397018931071079\n",
      "Validation MAE:  0.02251467619040241\n",
      "\tTrain Loss:  0.0002377278885129878\n",
      "\tValidation MSE:  0.0008463105408022832\n",
      "\n",
      "Epoch 51/200\n",
      "iter = 0 loss = 0.00014790109707973897\n",
      "iter = 20 loss = 0.00025853660190477967\n",
      "iter = 40 loss = 0.00032335222931578755\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00017924729930503722\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.1102932676647397\n",
      "Validation MAE:  0.020689191611390136\n",
      "\tTrain Loss:  0.00017924729930503722\n",
      "\tValidation MSE:  0.0007385226133459767\n",
      "\n",
      "Epoch 52/200\n",
      "iter = 0 loss = 0.00022406282369047403\n",
      "iter = 20 loss = 0.0002991666260641068\n",
      "iter = 40 loss = 0.00020253020920790732\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00015785874317468065\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2135695391514774\n",
      "Validation MAE:  0.020851227586672186\n",
      "\tTrain Loss:  0.00015785874317468065\n",
      "\tValidation MSE:  0.0007524762202567688\n",
      "\n",
      "Epoch 53/200\n",
      "iter = 0 loss = 0.00010193949856329709\n",
      "iter = 20 loss = 0.00013603163824882358\n",
      "iter = 40 loss = 0.00014198647113516927\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00014982354878156912\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.341835905778956\n",
      "Validation MAE:  0.021917770986687648\n",
      "\tTrain Loss:  0.00014982354878156912\n",
      "\tValidation MSE:  0.0008138391091347698\n",
      "\n",
      "Epoch 54/200\n",
      "iter = 0 loss = 0.0001265589235117659\n",
      "iter = 20 loss = 0.0001117320716730319\n",
      "iter = 40 loss = 0.00017978395044337958\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00012685693612487134\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.864409182013572\n",
      "Validation MAE:  0.0245267406582288\n",
      "\tTrain Loss:  0.00012685693612487134\n",
      "\tValidation MSE:  0.0009786300570844945\n",
      "\n",
      "Epoch 55/200\n",
      "iter = 0 loss = 0.00021611031843349338\n",
      "iter = 20 loss = 0.00010938401101157069\n",
      "iter = 40 loss = 0.00023659405997022986\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00022137745069509643\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.5753121399437324\n",
      "Validation MAE:  0.022754099339110666\n",
      "\tTrain Loss:  0.00022137745069509643\n",
      "\tValidation MSE:  0.0008514104037513301\n",
      "\n",
      "Epoch 56/200\n",
      "iter = 0 loss = 0.00032934045884758234\n",
      "iter = 20 loss = 0.00031607571872882545\n",
      "iter = 40 loss = 0.00014477453078143299\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00016717101743779494\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3473919259037408\n",
      "Validation MAE:  0.02198740173148238\n",
      "\tTrain Loss:  0.00016717101743779494\n",
      "\tValidation MSE:  0.0008143716687439267\n",
      "\n",
      "Epoch 57/200\n",
      "iter = 0 loss = 0.00020135557861067355\n",
      "iter = 20 loss = 0.0002581128210294992\n",
      "iter = 40 loss = 0.00016024761134758592\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00015523660492059813\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.0781503291262298\n",
      "Validation MAE:  0.020835752356542298\n",
      "\tTrain Loss:  0.00015523660492059813\n",
      "\tValidation MSE:  0.0007309217486538652\n",
      "\n",
      "Epoch 58/200\n",
      "iter = 0 loss = 0.0003868774510920048\n",
      "iter = 20 loss = 0.00013741801376454532\n",
      "iter = 40 loss = 0.00013959812349639833\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00020402663737210483\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.427302327488147\n",
      "Validation MAE:  0.022493185926245773\n",
      "\tTrain Loss:  0.00020402663737210483\n",
      "\tValidation MSE:  0.0008414449143707226\n",
      "\n",
      "Epoch 59/200\n",
      "iter = 0 loss = 0.0001305963669437915\n",
      "iter = 20 loss = 0.0001662311697145924\n",
      "iter = 40 loss = 0.00018432378419674933\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00015907739490709596\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.743993542699699\n",
      "Validation MAE:  0.02402647969113093\n",
      "\tTrain Loss:  0.00015907739490709596\n",
      "\tValidation MSE:  0.0009400310478112664\n",
      "\n",
      "Epoch 60/200\n",
      "iter = 0 loss = 0.0001710407668724656\n",
      "iter = 20 loss = 0.00011305926454951987\n",
      "iter = 40 loss = 0.00012459582649171352\n",
      "Learning rate =  6.25e-05\n",
      "Train loss =  0.00015494924703792398\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.5832461459661809\n",
      "Validation MAE:  0.02328494517770532\n",
      "\tTrain Loss:  0.00015494924703792398\n",
      "\tValidation MSE:  0.0008959778122154262\n",
      "\n",
      "Epoch 61/200\n",
      "iter = 0 loss = 0.00015077737043611705\n",
      "iter = 20 loss = 0.00017359414778184146\n",
      "iter = 40 loss = 0.00010681497224140912\n",
      "Learning rate =  3.125e-05\n",
      "Train loss =  0.00014067229494685307\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.6308892780648385\n",
      "Validation MAE:  0.023438747478946705\n",
      "\tTrain Loss:  0.00014067229494685307\n",
      "\tValidation MSE:  0.0008970752806658306\n",
      "\n",
      "Epoch 62/200\n",
      "iter = 0 loss = 0.00011217469000257552\n",
      "iter = 20 loss = 0.0003074920387007296\n",
      "iter = 40 loss = 6.583076901733875e-05\n",
      "Learning rate =  3.125e-05\n",
      "Train loss =  0.0001701749198825079\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.276102144081114\n",
      "Validation MAE:  0.02102428606656044\n",
      "\tTrain Loss:  0.0001701749198825079\n",
      "\tValidation MSE:  0.0007589885755835357\n",
      "\n",
      "Epoch 63/200\n",
      "iter = 0 loss = 6.897734419908375e-05\n",
      "iter = 20 loss = 9.614265582058579e-05\n",
      "iter = 40 loss = 0.00017085371655412018\n",
      "Learning rate =  3.125e-05\n",
      "Train loss =  0.00013396961670271898\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2188008351914275\n",
      "Validation MAE:  0.02112719552702011\n",
      "\tTrain Loss:  0.00013396961670271898\n",
      "\tValidation MSE:  0.0007637493513083919\n",
      "\n",
      "Epoch 64/200\n",
      "iter = 0 loss = 9.23801853787154e-05\n",
      "iter = 20 loss = 0.00014921871479600668\n",
      "iter = 40 loss = 0.00010761905286926776\n",
      "Learning rate =  3.125e-05\n",
      "Train loss =  0.00013465320807881653\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3198385233747203\n",
      "Validation MAE:  0.021798139905820697\n",
      "\tTrain Loss:  0.00013465320807881653\n",
      "\tValidation MSE:  0.0007944715314014559\n",
      "\n",
      "Epoch 65/200\n",
      "iter = 0 loss = 8.138480188790709e-05\n",
      "iter = 20 loss = 9.410257916897535e-05\n",
      "iter = 40 loss = 0.00020531186601147056\n",
      "Learning rate =  3.125e-05\n",
      "Train loss =  0.00012299153013373143\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.755564295409052\n",
      "Validation MAE:  0.02353929425483425\n",
      "\tTrain Loss:  0.00012299153013373143\n",
      "\tValidation MSE:  0.000912906542037997\n",
      "\n",
      "Epoch 66/200\n",
      "iter = 0 loss = 0.0001714151876512915\n",
      "iter = 20 loss = 0.00029824284138157964\n",
      "iter = 40 loss = 0.00013141470844857395\n",
      "Learning rate =  1.5625e-05\n",
      "Train loss =  0.0001337302502785557\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.4835167406293324\n",
      "Validation MAE:  0.022772814653235482\n",
      "\tTrain Loss:  0.0001337302502785557\n",
      "\tValidation MSE:  0.000872258704122507\n",
      "\n",
      "Epoch 67/200\n",
      "iter = 0 loss = 0.00016955978935584426\n",
      "iter = 20 loss = 9.375027730129659e-05\n",
      "iter = 40 loss = 9.484605106990784e-05\n",
      "Learning rate =  1.5625e-05\n",
      "Train loss =  0.000130278620114647\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.4397719988734865\n",
      "Validation MAE:  0.022094634297775896\n",
      "\tTrain Loss:  0.000130278620114647\n",
      "\tValidation MSE:  0.000822782729528695\n",
      "\n",
      "Epoch 68/200\n",
      "iter = 0 loss = 7.216981612145901e-05\n",
      "iter = 20 loss = 0.0001614419452380389\n",
      "iter = 40 loss = 7.337884744629264e-05\n",
      "Learning rate =  1.5625e-05\n",
      "Train loss =  0.00011113830381267083\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.416710054751117\n",
      "Validation MAE:  0.021726250716540368\n",
      "\tTrain Loss:  0.00011113830381267083\n",
      "\tValidation MSE:  0.0008068006166981029\n",
      "\n",
      "Epoch 69/200\n",
      "iter = 0 loss = 0.00011148931662319228\n",
      "iter = 20 loss = 8.834281470626593e-05\n",
      "iter = 40 loss = 6.342488632071763e-05\n",
      "Learning rate =  1.5625e-05\n",
      "Train loss =  0.00013468586939779925\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2429250220662422\n",
      "Validation MAE:  0.02115915919819923\n",
      "\tTrain Loss:  0.00013468586939779925\n",
      "\tValidation MSE:  0.0007628413531729418\n",
      "\n",
      "Epoch 70/200\n",
      "iter = 0 loss = 0.00010678657417884097\n",
      "iter = 20 loss = 0.00021109322551637888\n",
      "iter = 40 loss = 0.00011950217594858259\n",
      "Learning rate =  1.5625e-05\n",
      "Train loss =  0.00016981748861629362\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.6383044285490396\n",
      "Validation MAE:  0.023074635768045575\n",
      "\tTrain Loss:  0.00016981748861629362\n",
      "\tValidation MSE:  0.0008772031363856186\n",
      "\n",
      "Epoch 71/200\n",
      "iter = 0 loss = 0.00026951258769258857\n",
      "iter = 20 loss = 0.00010690382623579353\n",
      "iter = 40 loss = 0.00012193628936074674\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00013166772108282507\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3005260450605487\n",
      "Validation MAE:  0.021664788053460317\n",
      "\tTrain Loss:  0.00013166772108282507\n",
      "\tValidation MSE:  0.0007901850447459822\n",
      "\n",
      "Epoch 72/200\n",
      "iter = 0 loss = 0.0001423583598807454\n",
      "iter = 20 loss = 0.00012900006549898535\n",
      "iter = 40 loss = 7.661959534743801e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00010837074880024981\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.4041222308774515\n",
      "Validation MAE:  0.02157923211790111\n",
      "\tTrain Loss:  0.00010837074880024981\n",
      "\tValidation MSE:  0.000797790365620354\n",
      "\n",
      "Epoch 73/200\n",
      "iter = 0 loss = 0.0001086315605789423\n",
      "iter = 20 loss = 9.973618580261245e-05\n",
      "iter = 40 loss = 0.00032640830613672733\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00013123399427665086\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3802979127153323\n",
      "Validation MAE:  0.0217177980158427\n",
      "\tTrain Loss:  0.00013123399427665086\n",
      "\tValidation MSE:  0.0007996530774295877\n",
      "\n",
      "Epoch 74/200\n",
      "iter = 0 loss = 8.711072587175295e-05\n",
      "iter = 20 loss = 0.000140305986860767\n",
      "iter = 40 loss = 6.0920567193534225e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012749094571518071\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.223588328312267\n",
      "Validation MAE:  0.021026794224569243\n",
      "\tTrain Loss:  0.00012749094571518071\n",
      "\tValidation MSE:  0.0007500041810482382\n",
      "\n",
      "Epoch 75/200\n",
      "iter = 0 loss = 7.195425860118121e-05\n",
      "iter = 20 loss = 0.0001659111148910597\n",
      "iter = 40 loss = 0.00010493478475837037\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012899902261172733\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.372104774552986\n",
      "Validation MAE:  0.02152809881728534\n",
      "\tTrain Loss:  0.00012899902261172733\n",
      "\tValidation MSE:  0.0007843655752439594\n",
      "\n",
      "Epoch 76/200\n",
      "iter = 0 loss = 9.630980639485642e-05\n",
      "iter = 20 loss = 0.0001378460437990725\n",
      "iter = 40 loss = 0.00013495050370693207\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00011888179506058805\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.5530165015612156\n",
      "Validation MAE:  0.0227465210439952\n",
      "\tTrain Loss:  0.00011888179506058805\n",
      "\tValidation MSE:  0.0008530925135048505\n",
      "\n",
      "Epoch 77/200\n",
      "iter = 0 loss = 0.000285560789052397\n",
      "iter = 20 loss = 0.00011242512846365571\n",
      "iter = 40 loss = 8.295721636386588e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012504451804791947\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3328735181563727\n",
      "Validation MAE:  0.02171523263465324\n",
      "\tTrain Loss:  0.00012504451804791947\n",
      "\tValidation MSE:  0.0007971977716310025\n",
      "\n",
      "Epoch 78/200\n",
      "iter = 0 loss = 9.755315841175616e-05\n",
      "iter = 20 loss = 7.85152442404069e-05\n",
      "iter = 40 loss = 9.685350232757628e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00010991440967700328\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.1755449050237172\n",
      "Validation MAE:  0.02083597635025303\n",
      "\tTrain Loss:  0.00010991440967700328\n",
      "\tValidation MSE:  0.0007374913786282787\n",
      "\n",
      "Epoch 79/200\n",
      "iter = 0 loss = 9.907002095133066e-05\n",
      "iter = 20 loss = 0.00021979660959914327\n",
      "iter = 40 loss = 8.371131116291508e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.0001284552607406416\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.4424010045959301\n",
      "Validation MAE:  0.02223816139785122\n",
      "\tTrain Loss:  0.0001284552607406416\n",
      "\tValidation MSE:  0.0008308995227116179\n",
      "\n",
      "Epoch 80/200\n",
      "iter = 0 loss = 0.0001429036055924371\n",
      "iter = 20 loss = 0.00011551575880730525\n",
      "iter = 40 loss = 0.00016708829207345843\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00010398477297712816\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3391410263163452\n",
      "Validation MAE:  0.021397753325227187\n",
      "\tTrain Loss:  0.00010398477297712816\n",
      "\tValidation MSE:  0.00078156527260923\n",
      "\n",
      "Epoch 81/200\n",
      "iter = 0 loss = 0.00013554944598581642\n",
      "iter = 20 loss = 7.942235970403999e-05\n",
      "iter = 40 loss = 9.963355114450678e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00011969836426336163\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.4975855755542469\n",
      "Validation MAE:  0.022318387480631266\n",
      "\tTrain Loss:  0.00011969836426336163\n",
      "\tValidation MSE:  0.0008320004419939469\n",
      "\n",
      "Epoch 82/200\n",
      "iter = 0 loss = 0.00011560480197658762\n",
      "iter = 20 loss = 8.944641012931243e-05\n",
      "iter = 40 loss = 9.142143244389445e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012348833843134344\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3453252320762599\n",
      "Validation MAE:  0.02130928812505992\n",
      "\tTrain Loss:  0.00012348833843134344\n",
      "\tValidation MSE:  0.0007712265998491952\n",
      "\n",
      "Epoch 83/200\n",
      "iter = 0 loss = 0.00010315632971469313\n",
      "iter = 20 loss = 8.281790360342711e-05\n",
      "iter = 40 loss = 0.00012390133633743972\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.0001145816005797921\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2535369657414441\n",
      "Validation MAE:  0.020703981456146936\n",
      "\tTrain Loss:  0.0001145816005797921\n",
      "\tValidation MSE:  0.0007392437579618737\n",
      "\n",
      "Epoch 84/200\n",
      "iter = 0 loss = 0.00015160217299126089\n",
      "iter = 20 loss = 9.076129936147481e-05\n",
      "iter = 40 loss = 8.594116661697626e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00013192655660532182\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.287087482803953\n",
      "Validation MAE:  0.02138495628964411\n",
      "\tTrain Loss:  0.00013192655660532182\n",
      "\tValidation MSE:  0.0007836976231583111\n",
      "\n",
      "Epoch 85/200\n",
      "iter = 0 loss = 0.00010136497439816594\n",
      "iter = 20 loss = 6.666907574981451e-05\n",
      "iter = 40 loss = 0.00021178025053814054\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012018299230476259\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2507934592709993\n",
      "Validation MAE:  0.02074718094307538\n",
      "\tTrain Loss:  0.00012018299230476259\n",
      "\tValidation MSE:  0.0007441393596922983\n",
      "\n",
      "Epoch 86/200\n",
      "iter = 0 loss = 9.63185157161206e-05\n",
      "iter = 20 loss = 9.424528252566233e-05\n",
      "iter = 40 loss = 7.008144166320562e-05\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00011340259599516382\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3995224746001673\n",
      "Validation MAE:  0.02174609831479042\n",
      "\tTrain Loss:  0.00011340259599516382\n",
      "\tValidation MSE:  0.0007943339417193607\n",
      "\n",
      "Epoch 87/200\n",
      "iter = 0 loss = 0.00014636223204433918\n",
      "iter = 20 loss = 9.976926958188415e-05\n",
      "iter = 40 loss = 0.00010019848559750244\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00012014042037359711\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2344458409092116\n",
      "Validation MAE:  0.020903882778942857\n",
      "\tTrain Loss:  0.00012014042037359711\n",
      "\tValidation MSE:  0.0007473618798646217\n",
      "\n",
      "Epoch 88/200\n",
      "iter = 0 loss = 8.559454727219418e-05\n",
      "iter = 20 loss = 0.00012809000327251852\n",
      "iter = 40 loss = 0.00013035853044129908\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.0001233084992691147\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.2743480110534673\n",
      "Validation MAE:  0.021375201472408695\n",
      "\tTrain Loss:  0.0001233084992691147\n",
      "\tValidation MSE:  0.0007761309293616442\n",
      "\n",
      "Epoch 89/200\n",
      "iter = 0 loss = 0.00017635829863138497\n",
      "iter = 20 loss = 0.00024108908837661147\n",
      "iter = 40 loss = 0.00013616681098937988\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.0001378390809350094\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.28343624698014\n",
      "Validation MAE:  0.021147608893102708\n",
      "\tTrain Loss:  0.0001378390809350094\n",
      "\tValidation MSE:  0.0007725952837238191\n",
      "\n",
      "Epoch 90/200\n",
      "iter = 0 loss = 9.660638170316815e-05\n",
      "iter = 20 loss = 7.277212716871873e-05\n",
      "iter = 40 loss = 0.0001271540968446061\n",
      "Learning rate =  7.8125e-06\n",
      "Train loss =  0.00014473172025949074\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.6961435236421911\n",
      "Validation MAE:  0.02335665990772857\n",
      "\tTrain Loss:  0.00014473172025949074\n",
      "\tValidation MSE:  0.0008994803653606288\n",
      "\n",
      "Epoch 91/200\n",
      "iter = 0 loss = 0.00020202979794703424\n",
      "iter = 20 loss = 9.548432717565447e-05\n",
      "iter = 40 loss = 0.00010665816080290824\n",
      "Learning rate =  3.90625e-06\n",
      "Train loss =  0.00011218370279190519\n",
      "Number of equals between two list:  0\n",
      "Validation r2_score:  -1.3720800738390877\n",
      "Validation MAE:  0.021675632764759672\n",
      "\tTrain Loss:  0.00011218370279190519\n",
      "\tValidation MSE:  0.0007980546998852619\n",
      "\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m----> 9\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     MSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, val_loader)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m     38\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m### Gradient Descent\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter =\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28miter\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss =\u001b[39m\u001b[38;5;124m\"\u001b[39m,loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_project/lib/python3.9/site-packages/torch/optim/adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 263\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    266\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs to train and evaluate your model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_mse = 0.0 ### Monitor best accuracy in your run\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    MSE = eval(model, val_loader)\n",
    "\n",
    "    print(\"\\tTrain Loss: \", train_loss)\n",
    "    print(\"\\tValidation MSE: \", MSE)\n",
    "\n",
    "    ### Save checkpoint if accuracy is better than your current best\n",
    "    if MSE <= best_mse:\n",
    "    ### Save checkpoint with information you want\n",
    "        torch.save({'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': train_loss,\n",
    "              'learning rate': scheduler.get_last_lr()[0],\n",
    "              'mse': MSE}, \n",
    "        './model_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785492a-0e14-4148-8878-20ad6b73e85a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcdd9a-731e-45b8-abd8-7d7e43c8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "  ### What you call for model to perform inference?\n",
    "    model.eval()\n",
    "\n",
    "  ### List to store predicted phonemes of test data\n",
    "    test_predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "  ### Which mode do you need to avoid gradients?\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for i, data in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            phoneme, groundtruth_AM = data\n",
    "            ### Move data to device (ideally GPU)\n",
    "            phoneme, groundtruth_AM = phoneme.to(device), groundtruth_AM.to(device)         \n",
    "          \n",
    "            predicted_AM = model(phoneme)\n",
    "            predicted_AM.squeeze_()\n",
    "            # print(predicted_AM.shape)\n",
    "            # print(groundtruth_AM.shape)\n",
    "\n",
    "          ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
    "            test_predictions.extend(predicted_AM.cpu().tolist())\n",
    "            ground_truth.extend(groundtruth_AM.cpu())\n",
    "    \n",
    "    # print(len(test_predictions))\n",
    "    return test_predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a867d0-7ad4-4856-8675-980cacf391a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, ground_truth = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505f8f3-6e26-44f5-964c-610aeae42b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create CSV file with predictions\n",
    "with open(\"./phoneme%s\"%phoneme_idx +  \"_AM%s.csv\"%am_idx, \"w+\") as f:\n",
    "    f.write(\"person, label, prediction\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(\"{},{},{}\\n\".format(i, ground_truth[i], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77424a6-3f16-45d2-a290-a6e90508035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fd8331e-ad70-4eb5-a67b-9f11cb329bcc",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_project",
   "language": "python",
   "name": "torch_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
